{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Sage Sanctum Agent SDK","text":"<p>SDK for building agents that run within the Sage Sanctum secure multi-agent execution platform.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>SPIFFE Authentication \u2014 Automatic JWT SVID management for agent identity</li> <li>Transaction Tokens (TraT) \u2014 IETF-standard authorization for scoped transactions</li> <li>LLM Gateway Integration \u2014 Route LLM calls through authenticated, policy-enforced gateways</li> <li>Multi-Provider Support \u2014 OpenAI, Anthropic, and Google via unified interface</li> <li>SARIF Output \u2014 Standard static analysis output format for GitHub Code Scanning</li> <li>Testing Utilities \u2014 Mock gateway, LLM, and TraT clients for unit testing</li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>from sage_sanctum import AgentContext, AgentRunner, SageSanctumAgent, AgentResult\nfrom sage_sanctum.io.inputs import AgentInput, RepositoryInput\nfrom sage_sanctum.io.outputs import SarifOutput, Finding, Location\nfrom sage_sanctum.llm.model_category import ModelCategory\n\n\nclass MySecurityAgent(SageSanctumAgent):\n    @property\n    def name(self) -&gt; str:\n        return \"my-security-agent\"\n\n    @property\n    def version(self) -&gt; str:\n        return \"0.1.0\"\n\n    async def run(self, agent_input: AgentInput) -&gt; AgentResult:\n        llm = self.context.create_llm_client(ModelCategory.ANALYSIS)\n        response = llm.invoke([...])\n\n        return AgentResult(\n            output=SarifOutput(\n                tool_name=self.name,\n                tool_version=self.version,\n                findings=[...],\n            ),\n            exit_code=0,\n        )\n\n\nif __name__ == \"__main__\":\n    import sys\n    sys.exit(AgentRunner(MySecurityAgent).run())\n</code></pre>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install sage-sanctum-sdk\n</code></pre>"},{"location":"#architecture-overview","title":"Architecture Overview","text":"<p>Agents run in isolated containers with no direct network access. All external communication flows through authenticated gateways:</p> <pre><code>graph LR\n    A[Agent Pod] --&gt; B[Agent SDK]\n    B --&gt; C[SPIFFE JWT]\n    B --&gt; D[Transaction Token]\n    B --&gt; E[Gateway Client]\n    E --&gt; F[Unix Socket]\n    F --&gt; G[LLM Gateway]\n    G --&gt; H[OpenAI]\n    G --&gt; I[Anthropic]\n    G --&gt; J[Google]</code></pre>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li>Installation \u2014 Set up the SDK in your project</li> <li>Quickstart \u2014 Build your first agent step by step</li> <li>Architecture \u2014 Understand the security model</li> <li>API Reference \u2014 Full API documentation</li> </ul>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#public-api-surface","title":"Public API Surface","text":"<p>The top-level <code>sage_sanctum</code> package re-exports the most commonly used classes:</p> <pre><code>from sage_sanctum import (\n    AgentContext,\n    AgentInput,\n    AgentOutput,\n    AgentResult,\n    AgentRunner,\n    Finding,\n    Location,\n    ModelCategory,\n    ModelRef,\n    RepositoryInput,\n    SageSanctumAgent,\n    SageSanctumError,\n    SarifOutput,\n    TokenUsage,\n)\n</code></pre>"},{"location":"api/#package-structure","title":"Package Structure","text":"Module Description <code>sage_sanctum.agent</code> Agent base class and runner <code>sage_sanctum.context</code> Central agent context <code>sage_sanctum.errors</code> Error hierarchy with exit codes <code>sage_sanctum.auth</code> SPIFFE and Transaction Token authentication <code>sage_sanctum.gateway</code> LLM gateway client and HTTP transport <code>sage_sanctum.io</code> Agent input and output types <code>sage_sanctum.llm</code> Model categories, references, and selection <code>sage_sanctum.mcp</code> MCP tool client (placeholder) <code>sage_sanctum.testing</code> Mocks and fixtures for unit testing"},{"location":"api/agent/","title":"sage_sanctum.agent","text":"<p>Agent base class and lifecycle runner.</p>"},{"location":"api/agent/#sage_sanctum.agent","title":"<code>sage_sanctum.agent</code>","text":"<p>SageSanctumAgent base class and AgentRunner.</p>"},{"location":"api/agent/#sage_sanctum.agent.AgentResult","title":"<code>AgentResult</code>  <code>dataclass</code>","text":"<p>Result of an agent run.</p> <p>Returned by <code>SageSanctumAgent.run()</code> and processed by <code>AgentRunner</code> for output writing and exit code propagation.</p> <p>Attributes:</p> Name Type Description <code>output</code> <code>AgentOutput | None</code> <p>Agent output (e.g. <code>SarifOutput</code>). Written to disk by the runner.</p> <code>exit_code</code> <code>int</code> <p>Process exit code. <code>0</code> indicates success.</p> <code>error</code> <code>str</code> <p>Human-readable error message, if the run failed.</p> <code>duration_seconds</code> <code>float</code> <p>Wall-clock execution time (set by <code>AgentRunner</code>).</p> <code>metadata</code> <code>dict[str, Any]</code> <p>Arbitrary key-value pairs for telemetry or debugging.</p> Source code in <code>src/sage_sanctum/agent.py</code> <pre><code>@dataclass\nclass AgentResult:\n    \"\"\"Result of an agent run.\n\n    Returned by ``SageSanctumAgent.run()`` and processed by ``AgentRunner``\n    for output writing and exit code propagation.\n\n    Attributes:\n        output: Agent output (e.g. ``SarifOutput``). Written to disk by the runner.\n        exit_code: Process exit code. ``0`` indicates success.\n        error: Human-readable error message, if the run failed.\n        duration_seconds: Wall-clock execution time (set by ``AgentRunner``).\n        metadata: Arbitrary key-value pairs for telemetry or debugging.\n    \"\"\"\n\n    output: AgentOutput | None = None\n    exit_code: int = 0\n    error: str = \"\"\n    duration_seconds: float = 0.0\n    metadata: dict[str, Any] = field(default_factory=dict)\n</code></pre>"},{"location":"api/agent/#sage_sanctum.agent.SageSanctumAgent","title":"<code>SageSanctumAgent</code>","text":"<p>               Bases: <code>ABC</code>, <code>Generic[InputT]</code></p> <p>Base class for Sage Sanctum agents.</p> <p>Subclasses implement three members: <code>name</code>, <code>version</code>, and the async <code>run()</code> method. The SDK handles authentication, context initialization, and output writing.</p> <p>Set <code>requires_gateway = False</code> on subclasses that manage their own LLM access (e.g. wrapping an external CLI tool). The runner will skip gateway/SPIFFE setup and use <code>AgentContext.for_external_llm()</code> instead.</p> Example <pre><code>class MyAgent(SageSanctumAgent):\n    @property\n    def name(self) -&gt; str:\n        return \"my-agent\"\n\n    @property\n    def version(self) -&gt; str:\n        return \"1.0.0\"\n\n    async def run(self, agent_input: AgentInput) -&gt; AgentResult:\n        llm = self.context.create_llm_client(ModelCategory.ANALYSIS)\n        ...\n        return AgentResult(exit_code=0)\n</code></pre> <p>Attributes:</p> Name Type Description <code>context</code> <p>The runtime context providing LLM clients, I/O, and metadata.</p> <code>requires_gateway</code> <code>bool</code> <p>Whether the agent needs the LLM gateway. Defaults to <code>True</code>.</p> Source code in <code>src/sage_sanctum/agent.py</code> <pre><code>class SageSanctumAgent(ABC, Generic[InputT]):\n    \"\"\"Base class for Sage Sanctum agents.\n\n    Subclasses implement three members: ``name``, ``version``, and the async\n    ``run()`` method. The SDK handles authentication, context initialization,\n    and output writing.\n\n    Set ``requires_gateway = False`` on subclasses that manage their own\n    LLM access (e.g. wrapping an external CLI tool). The runner will skip\n    gateway/SPIFFE setup and use ``AgentContext.for_external_llm()`` instead.\n\n    Example:\n        ```python\n        class MyAgent(SageSanctumAgent):\n            @property\n            def name(self) -&gt; str:\n                return \"my-agent\"\n\n            @property\n            def version(self) -&gt; str:\n                return \"1.0.0\"\n\n            async def run(self, agent_input: AgentInput) -&gt; AgentResult:\n                llm = self.context.create_llm_client(ModelCategory.ANALYSIS)\n                ...\n                return AgentResult(exit_code=0)\n        ```\n\n    Attributes:\n        context: The runtime context providing LLM clients, I/O, and metadata.\n        requires_gateway: Whether the agent needs the LLM gateway. Defaults to ``True``.\n    \"\"\"\n\n    requires_gateway: bool = True\n\n    def __init__(\n        self,\n        context: AgentContext,\n        *,\n        _shutdown_event: asyncio.Event | None = None,\n    ) -&gt; None:\n        self.context = context\n        self._shutdown_event: asyncio.Event = _shutdown_event or asyncio.Event()\n\n    @property\n    def shutdown_requested(self) -&gt; bool:\n        \"\"\"Whether a shutdown signal has been received.\"\"\"\n        return self._shutdown_event.is_set()\n\n    async def wait_for_shutdown(self) -&gt; None:\n        \"\"\"Wait until a shutdown signal is received.\n\n        Useful for racing against a subprocess: whichever completes first\n        (the subprocess or shutdown) wins.\n        \"\"\"\n        await self._shutdown_event.wait()\n\n    @property\n    @abstractmethod\n    def name(self) -&gt; str:\n        \"\"\"Agent name (e.g., 'sage-security-scanner').\"\"\"\n\n    @property\n    @abstractmethod\n    def version(self) -&gt; str:\n        \"\"\"Agent version.\"\"\"\n\n    @abstractmethod\n    async def run(self, agent_input: InputT) -&gt; AgentResult:\n        \"\"\"Execute the agent's main logic.\n\n        Args:\n            agent_input: The validated input for this run.\n\n        Returns:\n            AgentResult with output and metadata.\n        \"\"\"\n</code></pre>"},{"location":"api/agent/#sage_sanctum.agent.SageSanctumAgent.shutdown_requested","title":"<code>shutdown_requested: bool</code>  <code>property</code>","text":"<p>Whether a shutdown signal has been received.</p>"},{"location":"api/agent/#sage_sanctum.agent.SageSanctumAgent.name","title":"<code>name: str</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Agent name (e.g., 'sage-security-scanner').</p>"},{"location":"api/agent/#sage_sanctum.agent.SageSanctumAgent.version","title":"<code>version: str</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Agent version.</p>"},{"location":"api/agent/#sage_sanctum.agent.SageSanctumAgent.wait_for_shutdown","title":"<code>wait_for_shutdown() -&gt; None</code>  <code>async</code>","text":"<p>Wait until a shutdown signal is received.</p> <p>Useful for racing against a subprocess: whichever completes first (the subprocess or shutdown) wins.</p> Source code in <code>src/sage_sanctum/agent.py</code> <pre><code>async def wait_for_shutdown(self) -&gt; None:\n    \"\"\"Wait until a shutdown signal is received.\n\n    Useful for racing against a subprocess: whichever completes first\n    (the subprocess or shutdown) wins.\n    \"\"\"\n    await self._shutdown_event.wait()\n</code></pre>"},{"location":"api/agent/#sage_sanctum.agent.SageSanctumAgent.run","title":"<code>run(agent_input: InputT) -&gt; AgentResult</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Execute the agent's main logic.</p> <p>Parameters:</p> Name Type Description Default <code>agent_input</code> <code>InputT</code> <p>The validated input for this run.</p> required <p>Returns:</p> Type Description <code>AgentResult</code> <p>AgentResult with output and metadata.</p> Source code in <code>src/sage_sanctum/agent.py</code> <pre><code>@abstractmethod\nasync def run(self, agent_input: InputT) -&gt; AgentResult:\n    \"\"\"Execute the agent's main logic.\n\n    Args:\n        agent_input: The validated input for this run.\n\n    Returns:\n        AgentResult with output and metadata.\n    \"\"\"\n</code></pre>"},{"location":"api/agent/#sage_sanctum.agent.AgentRunner","title":"<code>AgentRunner</code>","text":"<p>Runs a SageSanctumAgent with proper lifecycle management.</p> <p>Handles: - Event loop creation - Signal handling (SIGTERM, SIGINT) - Context initialization from environment - Error \u2192 exit code mapping - Output writing</p> Source code in <code>src/sage_sanctum/agent.py</code> <pre><code>class AgentRunner:\n    \"\"\"Runs a SageSanctumAgent with proper lifecycle management.\n\n    Handles:\n    - Event loop creation\n    - Signal handling (SIGTERM, SIGINT)\n    - Context initialization from environment\n    - Error \u2192 exit code mapping\n    - Output writing\n    \"\"\"\n\n    def __init__(self, agent_class: type[SageSanctumAgent]) -&gt; None:\n        \"\"\"Initialize the runner.\n\n        Args:\n            agent_class: The agent class to instantiate and run. Must be a\n                subclass of ``SageSanctumAgent``.\n        \"\"\"\n        self._agent_class = agent_class\n        self._shutdown_event: asyncio.Event | None = None\n\n    def run(self) -&gt; int:\n        \"\"\"Run the agent synchronously.\n\n        Creates an asyncio event loop, initializes the agent context from\n        environment variables, executes the agent, writes output, and returns\n        the process exit code.\n\n        Returns:\n            Process exit code (``0`` for success, error-specific codes for\n            ``SageSanctumError`` subclasses, ``1`` for unexpected errors,\n            ``130`` for ``KeyboardInterrupt``).\n        \"\"\"\n        configure_logging()\n        try:\n            return asyncio.run(self._run_async())\n        except KeyboardInterrupt:\n            logger.info(\"agent_interrupted\")\n            return 130  # Standard SIGINT exit code\n        except SageSanctumError as e:\n            logger.error(\"agent_error\", error=str(e), exit_code=e.exit_code)\n            return e.exit_code\n        except Exception as e:\n            logger.error(\"unexpected_error\", error=str(e), exc_info=True)\n            return 1\n\n    async def _run_async(self) -&gt; int:\n        \"\"\"Async agent lifecycle.\"\"\"\n        self._shutdown_event = asyncio.Event()\n\n        # Install signal handlers\n        loop = asyncio.get_running_loop()\n        for sig in (signal.SIGTERM, signal.SIGINT):\n            loop.add_signal_handler(sig, self._handle_signal, sig)\n\n        start_time = time.monotonic()\n\n        # Initialize context\n        logger.info(\"initializing_context\")\n        if self._agent_class.requires_gateway:\n            context = await AgentContext.from_environment_async()\n        else:\n            context = AgentContext.for_external_llm()\n\n        # Create agent with the shared shutdown event\n        agent = self._agent_class(context, _shutdown_event=self._shutdown_event)\n        logger.info(\n            \"agent_starting\",\n            agent=agent.name,\n            version=agent.version,\n            run_id=context.run_id,\n        )\n\n        # Load input\n        agent_input = context.load_input()\n\n        # Run agent with cooperative cancellation via shutdown event\n        agent_task = asyncio.create_task(agent.run(agent_input))\n        shutdown_task = asyncio.create_task(self._shutdown_event.wait())\n\n        done, pending = await asyncio.wait(\n            {agent_task, shutdown_task},\n            return_when=asyncio.FIRST_COMPLETED,\n        )\n\n        if shutdown_task in done:\n            # Shutdown was requested \u2014 cancel the agent task and exit\n            agent_task.cancel()\n            try:\n                await agent_task\n            except asyncio.CancelledError:\n                pass\n            logger.info(\"agent_cancelled\")\n            return 130\n\n        # Agent completed normally \u2014 clean up shutdown waiter\n        shutdown_task.cancel()\n        result = agent_task.result()\n\n        duration = time.monotonic() - start_time\n        result.duration_seconds = duration\n\n        # Write output\n        if result.output:\n            files = context.write_output(result.output)\n            logger.info(\"output_written\", files=files)\n\n        logger.info(\n            \"agent_completed\",\n            agent=agent.name,\n            duration=duration,\n            exit_code=result.exit_code,\n        )\n\n        return result.exit_code\n\n    def _handle_signal(self, sig: signal.Signals) -&gt; None:\n        \"\"\"Handle shutdown signals gracefully.\"\"\"\n        logger.info(\"shutdown_signal_received\", signal=sig.name)\n        if self._shutdown_event:\n            self._shutdown_event.set()\n</code></pre>"},{"location":"api/agent/#sage_sanctum.agent.AgentRunner.__init__","title":"<code>__init__(agent_class: type[SageSanctumAgent]) -&gt; None</code>","text":"<p>Initialize the runner.</p> <p>Parameters:</p> Name Type Description Default <code>agent_class</code> <code>type[SageSanctumAgent]</code> <p>The agent class to instantiate and run. Must be a subclass of <code>SageSanctumAgent</code>.</p> required Source code in <code>src/sage_sanctum/agent.py</code> <pre><code>def __init__(self, agent_class: type[SageSanctumAgent]) -&gt; None:\n    \"\"\"Initialize the runner.\n\n    Args:\n        agent_class: The agent class to instantiate and run. Must be a\n            subclass of ``SageSanctumAgent``.\n    \"\"\"\n    self._agent_class = agent_class\n    self._shutdown_event: asyncio.Event | None = None\n</code></pre>"},{"location":"api/agent/#sage_sanctum.agent.AgentRunner.run","title":"<code>run() -&gt; int</code>","text":"<p>Run the agent synchronously.</p> <p>Creates an asyncio event loop, initializes the agent context from environment variables, executes the agent, writes output, and returns the process exit code.</p> <p>Returns:</p> Type Description <code>int</code> <p>Process exit code (<code>0</code> for success, error-specific codes for</p> <code>int</code> <p><code>SageSanctumError</code> subclasses, <code>1</code> for unexpected errors,</p> <code>int</code> <p><code>130</code> for <code>KeyboardInterrupt</code>).</p> Source code in <code>src/sage_sanctum/agent.py</code> <pre><code>def run(self) -&gt; int:\n    \"\"\"Run the agent synchronously.\n\n    Creates an asyncio event loop, initializes the agent context from\n    environment variables, executes the agent, writes output, and returns\n    the process exit code.\n\n    Returns:\n        Process exit code (``0`` for success, error-specific codes for\n        ``SageSanctumError`` subclasses, ``1`` for unexpected errors,\n        ``130`` for ``KeyboardInterrupt``).\n    \"\"\"\n    configure_logging()\n    try:\n        return asyncio.run(self._run_async())\n    except KeyboardInterrupt:\n        logger.info(\"agent_interrupted\")\n        return 130  # Standard SIGINT exit code\n    except SageSanctumError as e:\n        logger.error(\"agent_error\", error=str(e), exit_code=e.exit_code)\n        return e.exit_code\n    except Exception as e:\n        logger.error(\"unexpected_error\", error=str(e), exc_info=True)\n        return 1\n</code></pre>"},{"location":"api/context/","title":"sage_sanctum.context","text":"<p>Central agent context providing access to LLM clients, model selection, and I/O.</p>"},{"location":"api/context/#sage_sanctum.context","title":"<code>sage_sanctum.context</code>","text":"<p>AgentContext: central context object for agent execution.</p>"},{"location":"api/context/#sage_sanctum.context.AgentContext","title":"<code>AgentContext</code>  <code>dataclass</code>","text":"<p>Central context for agent execution.</p> <p>Provides access to run metadata, LLM clients, model selection, and I/O. Created automatically by <code>AgentRunner</code> or manually via factory methods.</p> <p>Attributes:</p> Name Type Description <code>run_id</code> <code>str</code> <p>Unique identifier for this agent run.</p> <code>org_id</code> <code>str</code> <p>Organization identifier.</p> <code>work_dir</code> <code>Path</code> <p>Working directory for temporary files.</p> <code>output_dir</code> <code>Path</code> <p>Directory where agent output is written.</p> <code>gateway_client</code> <code>GatewayClient | None</code> <p>Client for LLM gateway access (SPIFFE or direct).</p> <code>model_selector</code> <code>ModelSelector | None</code> <p>Resolves <code>ModelCategory</code> to concrete <code>ModelRef</code>.</p> <code>logger</code> <code>BoundLogger</code> <p>Logger instance for the agent.</p> Example <pre><code># Production (via AgentRunner \u2014 automatic):\ncontext = AgentContext.from_environment()\n\n# Local development:\ncontext = AgentContext.for_local_development(\n    work_dir=\"/tmp/work\",\n    output_dir=\"/tmp/output\",\n    model=\"openai:gpt-4o\",\n)\n</code></pre> Source code in <code>src/sage_sanctum/context.py</code> <pre><code>@dataclass\nclass AgentContext:\n    \"\"\"Central context for agent execution.\n\n    Provides access to run metadata, LLM clients, model selection, and I/O.\n    Created automatically by ``AgentRunner`` or manually via factory methods.\n\n    Attributes:\n        run_id: Unique identifier for this agent run.\n        org_id: Organization identifier.\n        work_dir: Working directory for temporary files.\n        output_dir: Directory where agent output is written.\n        gateway_client: Client for LLM gateway access (SPIFFE or direct).\n        model_selector: Resolves ``ModelCategory`` to concrete ``ModelRef``.\n        logger: Logger instance for the agent.\n\n    Example:\n        ```python\n        # Production (via AgentRunner \u2014 automatic):\n        context = AgentContext.from_environment()\n\n        # Local development:\n        context = AgentContext.for_local_development(\n            work_dir=\"/tmp/work\",\n            output_dir=\"/tmp/output\",\n            model=\"openai:gpt-4o\",\n        )\n        ```\n    \"\"\"\n\n    run_id: str\n    org_id: str\n    work_dir: Path\n    output_dir: Path\n    gateway_client: GatewayClient | None = None\n    model_selector: ModelSelector | None = None\n    logger: structlog.stdlib.BoundLogger = field(default_factory=lambda: get_logger(\"sage_sanctum\"))\n\n    def create_llm_client(self, category: ModelCategory) -&gt; BaseChatModel:\n        \"\"\"Create an LLM client for the specified model category.\n\n        Resolves the model from the selector, then creates an appropriate\n        LLM client (``GatewayChatModel`` in gateway mode, ``ChatLiteLLM``\n        in direct mode).\n\n        Args:\n            category: The model category (e.g. ``ModelCategory.ANALYSIS``).\n\n        Returns:\n            A LangChain ``BaseChatModel`` ready for ``invoke()`` calls.\n\n        Raises:\n            ConfigurationError: If gateway_client or model_selector is not configured.\n            ModelNotAvailableError: If no model is configured for the category.\n        \"\"\"\n        if self.gateway_client is None or self.model_selector is None:\n            raise ConfigurationError(\n                \"create_llm_client() requires gateway_client and model_selector. \"\n                \"Use AgentContext.from_environment() or for_local_development() instead of for_external_llm().\"\n            )\n        model_ref = self.model_selector.select(category)\n        logger.debug(\"creating_llm_client\", category=category.value, model_ref=str(model_ref))\n        return create_llm_for_gateway(\n            model_ref=model_ref,\n            gateway_client=self.gateway_client,\n        )\n\n    def create_embeddings_client(\n        self,\n        model: str = \"text-embedding-3-small\",\n        provider: str = \"openai\",\n    ) -&gt; \"Embeddings\":\n        \"\"\"Create an embeddings client routed through the gateway.\n\n        In gateway mode, returns a ``GatewayEmbeddings`` instance that\n        communicates over UDS with SPIFFE + TraT auth. In direct mode,\n        returns ``OpenAIEmbeddings`` with env-var API keys.\n\n        Args:\n            model: Embedding model name. Defaults to ``\"text-embedding-3-small\"``.\n            provider: Provider name for the ``X-Provider`` header. Defaults to ``\"openai\"``.\n\n        Returns:\n            A LangChain ``Embeddings`` instance.\n\n        Raises:\n            ConfigurationError: If gateway_client is not configured.\n        \"\"\"\n        if self.gateway_client is None:\n            raise ConfigurationError(\n                \"create_embeddings_client() requires gateway_client. \"\n                \"Use AgentContext.from_environment() or for_local_development() instead of for_external_llm().\"\n            )\n        logger.debug(\"creating_embeddings_client\", model=model, provider=provider)\n        return create_embeddings_for_gateway(\n            model=model,\n            gateway_client=self.gateway_client,\n            provider=provider,\n        )\n\n    def check_gateway_health(self) -&gt; bool:\n        \"\"\"Check if the LLM gateway is reachable.\n\n        Sends ``GET /health`` via the gateway's connection (UDS or TCP).\n        Returns ``False`` in direct mode since there is no gateway.\n\n        Returns:\n            ``True`` if the gateway responds with 200, ``False`` otherwise\n            (including when no gateway client is configured).\n        \"\"\"\n        if self.gateway_client is None:\n            return False\n        if not self.gateway_client.is_gateway_mode:\n            return False\n\n        from .gateway.http import GatewayHttpClient\n\n        endpoint = self.gateway_client.get_endpoint(\"openai\")\n        if endpoint.startswith(\"unix://\"):\n            socket_path = endpoint[len(\"unix://\"):]\n            client = GatewayHttpClient(socket_path=socket_path)\n        else:\n            from urllib.parse import urlparse\n\n            parsed = urlparse(endpoint)\n            client = GatewayHttpClient(\n                host=parsed.hostname or \"localhost\",\n                port=parsed.port or 8080,\n            )\n        return client.health_check()\n\n    def load_input(self) -&gt; RepositoryInput:\n        \"\"\"Load agent input from environment.\n\n        Returns:\n            RepositoryInput from REPO_PATH env var.\n        \"\"\"\n        repo_input = RepositoryInput.from_environment()\n        repo_input.validate()\n        return repo_input\n\n    def write_output(self, output: AgentOutput) -&gt; list[str]:\n        \"\"\"Write agent output to the output directory.\n\n        Returns:\n            List of filenames written.\n        \"\"\"\n        return output.write(self.output_dir)\n\n    @classmethod\n    def from_environment(cls) -&gt; AgentContext:\n        \"\"\"Create context from environment variables (synchronous).\n\n        Expected env vars:\n        - RUN_ID: Run identifier (required)\n        - ORG_ID: Organization identifier (required)\n        - WORK_DIR: Working directory (default: /work)\n        - OUTPUT_PATH: Output directory (default: /output)\n        - SPIFFE_JWT_PATH: Path to SPIFFE JWT file\n        - TRAT_FILE: Path to TraT file\n        - AUTH_SIDECAR_SOCKET: Path to auth sidecar Unix socket\n        - LLM_GATEWAY_SOCKET: Path to LLM gateway Unix socket\n        - SAGE_SANCTUM_ALLOW_DIRECT: Set to '1' for direct provider access\n        \"\"\"\n        run_id = os.environ.get(\"RUN_ID\", \"\")\n        org_id = os.environ.get(\"ORG_ID\", \"\")\n\n        if not run_id:\n            raise ConfigurationError(\"RUN_ID environment variable not set\")\n        if not org_id:\n            raise ConfigurationError(\"ORG_ID environment variable not set\")\n\n        work_dir = Path(os.environ.get(\"WORK_DIR\", \"/work\"))\n        output_dir = Path(os.environ.get(\"OUTPUT_PATH\", \"/output\"))\n\n        # Build gateway client\n        gateway_client = cls._create_gateway_client()\n\n        # Build model selector from TraT or environment\n        model_selector = cls._create_model_selector(gateway_client)\n\n        return cls(\n            run_id=run_id,\n            org_id=org_id,\n            work_dir=work_dir,\n            output_dir=output_dir,\n            gateway_client=gateway_client,\n            model_selector=model_selector,\n        )\n\n    @classmethod\n    async def from_environment_async(cls) -&gt; AgentContext:\n        \"\"\"Async version of from_environment. Currently identical.\"\"\"\n        return cls.from_environment()\n\n    @classmethod\n    def for_local_development(\n        cls,\n        work_dir: str | Path = \".\",\n        output_dir: str | Path = \"./output\",\n        model: str = \"gpt-4o\",\n    ) -&gt; AgentContext:\n        \"\"\"Create context for local development with direct API keys.\n\n        Bypasses the gateway and calls LLM providers directly using API keys\n        from environment variables. Sets ``SAGE_SANCTUM_ALLOW_DIRECT=1``\n        automatically.\n\n        Args:\n            work_dir: Working directory for temporary files.\n            output_dir: Directory for agent output.\n            model: Model reference string (e.g. ``\"openai:gpt-4o\"``). Used\n                for all categories via ``StaticModelSelector``.\n\n        Returns:\n            A fully configured ``AgentContext`` in direct mode.\n        \"\"\"\n        os.environ.setdefault(\"SAGE_SANCTUM_ALLOW_DIRECT\", \"1\")\n\n        return cls(\n            run_id=\"local\",\n            org_id=\"local\",\n            work_dir=Path(work_dir),\n            output_dir=Path(output_dir),\n            gateway_client=DirectProviderClient(),\n            model_selector=StaticModelSelector(model),\n        )\n\n    @classmethod\n    def for_external_llm(cls) -&gt; AgentContext:\n        \"\"\"Create a minimal context for agents that manage their own LLM access.\n\n        Only reads ``RUN_ID``, ``ORG_ID``, ``WORK_DIR``, and ``OUTPUT_PATH``\n        from the environment. Skips all SPIFFE, TraT, and gateway setup.\n\n        The resulting context has ``gateway_client=None`` and\n        ``model_selector=None``. Calling ``create_llm_client()``,\n        ``create_embeddings_client()``, or ``check_gateway_health()``\n        will raise ``ConfigurationError``.\n\n        Returns:\n            An ``AgentContext`` suitable for external-LLM agents.\n        \"\"\"\n        run_id = os.environ.get(\"RUN_ID\", \"\")\n        org_id = os.environ.get(\"ORG_ID\", \"\")\n\n        if not run_id:\n            raise ConfigurationError(\"RUN_ID environment variable not set\")\n        if not org_id:\n            raise ConfigurationError(\"ORG_ID environment variable not set\")\n\n        work_dir = Path(os.environ.get(\"WORK_DIR\", \"/work\"))\n        output_dir = Path(os.environ.get(\"OUTPUT_PATH\", \"/output\"))\n\n        return cls(\n            run_id=run_id,\n            org_id=org_id,\n            work_dir=work_dir,\n            output_dir=output_dir,\n        )\n\n    @classmethod\n    def _create_gateway_client(cls) -&gt; GatewayClient:\n        \"\"\"Create the appropriate gateway client based on environment.\"\"\"\n        # Check for direct mode first\n        if os.environ.get(\"SAGE_SANCTUM_ALLOW_DIRECT\"):\n            return DirectProviderClient()\n\n        # Production mode: SPIFFE + TraT\n        jwt_path = os.environ.get(\"SPIFFE_JWT_PATH\")\n        if not jwt_path:\n            raise ConfigurationError(\n                \"SPIFFE_JWT_PATH not set. Set SAGE_SANCTUM_ALLOW_DIRECT=1 for local dev.\"\n            )\n\n        jwt_source = JWTSource(jwt_path)\n\n        trat_file = os.environ.get(\"TRAT_FILE\")\n        sidecar_socket = os.environ.get(\"AUTH_SIDECAR_SOCKET\")\n        trat_client = TransactionTokenClient(\n            trat_file=trat_file,\n            sidecar_socket=sidecar_socket,\n        )\n\n        gateway_socket = os.environ.get(\"LLM_GATEWAY_SOCKET\")\n\n        return SpiffeGatewayClient(\n            jwt_source=jwt_source,\n            trat_client=trat_client,\n            gateway_socket=gateway_socket,\n        )\n\n    @classmethod\n    def _create_model_selector(cls, gateway_client: GatewayClient) -&gt; ModelSelector:\n        \"\"\"Create model selector from TraT or fallback to env var.\"\"\"\n        trat = gateway_client.get_trat()\n        if trat and trat.tctx.allowed_models.has_any():\n            # Use TraT's allowed_models\n            return ModelSelector(trat.tctx.allowed_models.to_dict())\n\n        # Fallback to static selector from env\n        model = (\n            os.environ.get(\"SAGE_MODEL\")\n            or os.environ.get(\"OPENAI_MODEL\")\n            or \"gpt-4o\"\n        )\n        return StaticModelSelector(model)\n</code></pre>"},{"location":"api/context/#sage_sanctum.context.AgentContext.create_llm_client","title":"<code>create_llm_client(category: ModelCategory) -&gt; BaseChatModel</code>","text":"<p>Create an LLM client for the specified model category.</p> <p>Resolves the model from the selector, then creates an appropriate LLM client (<code>GatewayChatModel</code> in gateway mode, <code>ChatLiteLLM</code> in direct mode).</p> <p>Parameters:</p> Name Type Description Default <code>category</code> <code>ModelCategory</code> <p>The model category (e.g. <code>ModelCategory.ANALYSIS</code>).</p> required <p>Returns:</p> Type Description <code>BaseChatModel</code> <p>A LangChain <code>BaseChatModel</code> ready for <code>invoke()</code> calls.</p> <p>Raises:</p> Type Description <code>ConfigurationError</code> <p>If gateway_client or model_selector is not configured.</p> <code>ModelNotAvailableError</code> <p>If no model is configured for the category.</p> Source code in <code>src/sage_sanctum/context.py</code> <pre><code>def create_llm_client(self, category: ModelCategory) -&gt; BaseChatModel:\n    \"\"\"Create an LLM client for the specified model category.\n\n    Resolves the model from the selector, then creates an appropriate\n    LLM client (``GatewayChatModel`` in gateway mode, ``ChatLiteLLM``\n    in direct mode).\n\n    Args:\n        category: The model category (e.g. ``ModelCategory.ANALYSIS``).\n\n    Returns:\n        A LangChain ``BaseChatModel`` ready for ``invoke()`` calls.\n\n    Raises:\n        ConfigurationError: If gateway_client or model_selector is not configured.\n        ModelNotAvailableError: If no model is configured for the category.\n    \"\"\"\n    if self.gateway_client is None or self.model_selector is None:\n        raise ConfigurationError(\n            \"create_llm_client() requires gateway_client and model_selector. \"\n            \"Use AgentContext.from_environment() or for_local_development() instead of for_external_llm().\"\n        )\n    model_ref = self.model_selector.select(category)\n    logger.debug(\"creating_llm_client\", category=category.value, model_ref=str(model_ref))\n    return create_llm_for_gateway(\n        model_ref=model_ref,\n        gateway_client=self.gateway_client,\n    )\n</code></pre>"},{"location":"api/context/#sage_sanctum.context.AgentContext.create_embeddings_client","title":"<code>create_embeddings_client(model: str = 'text-embedding-3-small', provider: str = 'openai') -&gt; 'Embeddings'</code>","text":"<p>Create an embeddings client routed through the gateway.</p> <p>In gateway mode, returns a <code>GatewayEmbeddings</code> instance that communicates over UDS with SPIFFE + TraT auth. In direct mode, returns <code>OpenAIEmbeddings</code> with env-var API keys.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>Embedding model name. Defaults to <code>\"text-embedding-3-small\"</code>.</p> <code>'text-embedding-3-small'</code> <code>provider</code> <code>str</code> <p>Provider name for the <code>X-Provider</code> header. Defaults to <code>\"openai\"</code>.</p> <code>'openai'</code> <p>Returns:</p> Type Description <code>'Embeddings'</code> <p>A LangChain <code>Embeddings</code> instance.</p> <p>Raises:</p> Type Description <code>ConfigurationError</code> <p>If gateway_client is not configured.</p> Source code in <code>src/sage_sanctum/context.py</code> <pre><code>def create_embeddings_client(\n    self,\n    model: str = \"text-embedding-3-small\",\n    provider: str = \"openai\",\n) -&gt; \"Embeddings\":\n    \"\"\"Create an embeddings client routed through the gateway.\n\n    In gateway mode, returns a ``GatewayEmbeddings`` instance that\n    communicates over UDS with SPIFFE + TraT auth. In direct mode,\n    returns ``OpenAIEmbeddings`` with env-var API keys.\n\n    Args:\n        model: Embedding model name. Defaults to ``\"text-embedding-3-small\"``.\n        provider: Provider name for the ``X-Provider`` header. Defaults to ``\"openai\"``.\n\n    Returns:\n        A LangChain ``Embeddings`` instance.\n\n    Raises:\n        ConfigurationError: If gateway_client is not configured.\n    \"\"\"\n    if self.gateway_client is None:\n        raise ConfigurationError(\n            \"create_embeddings_client() requires gateway_client. \"\n            \"Use AgentContext.from_environment() or for_local_development() instead of for_external_llm().\"\n        )\n    logger.debug(\"creating_embeddings_client\", model=model, provider=provider)\n    return create_embeddings_for_gateway(\n        model=model,\n        gateway_client=self.gateway_client,\n        provider=provider,\n    )\n</code></pre>"},{"location":"api/context/#sage_sanctum.context.AgentContext.check_gateway_health","title":"<code>check_gateway_health() -&gt; bool</code>","text":"<p>Check if the LLM gateway is reachable.</p> <p>Sends <code>GET /health</code> via the gateway's connection (UDS or TCP). Returns <code>False</code> in direct mode since there is no gateway.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the gateway responds with 200, <code>False</code> otherwise</p> <code>bool</code> <p>(including when no gateway client is configured).</p> Source code in <code>src/sage_sanctum/context.py</code> <pre><code>def check_gateway_health(self) -&gt; bool:\n    \"\"\"Check if the LLM gateway is reachable.\n\n    Sends ``GET /health`` via the gateway's connection (UDS or TCP).\n    Returns ``False`` in direct mode since there is no gateway.\n\n    Returns:\n        ``True`` if the gateway responds with 200, ``False`` otherwise\n        (including when no gateway client is configured).\n    \"\"\"\n    if self.gateway_client is None:\n        return False\n    if not self.gateway_client.is_gateway_mode:\n        return False\n\n    from .gateway.http import GatewayHttpClient\n\n    endpoint = self.gateway_client.get_endpoint(\"openai\")\n    if endpoint.startswith(\"unix://\"):\n        socket_path = endpoint[len(\"unix://\"):]\n        client = GatewayHttpClient(socket_path=socket_path)\n    else:\n        from urllib.parse import urlparse\n\n        parsed = urlparse(endpoint)\n        client = GatewayHttpClient(\n            host=parsed.hostname or \"localhost\",\n            port=parsed.port or 8080,\n        )\n    return client.health_check()\n</code></pre>"},{"location":"api/context/#sage_sanctum.context.AgentContext.load_input","title":"<code>load_input() -&gt; RepositoryInput</code>","text":"<p>Load agent input from environment.</p> <p>Returns:</p> Type Description <code>RepositoryInput</code> <p>RepositoryInput from REPO_PATH env var.</p> Source code in <code>src/sage_sanctum/context.py</code> <pre><code>def load_input(self) -&gt; RepositoryInput:\n    \"\"\"Load agent input from environment.\n\n    Returns:\n        RepositoryInput from REPO_PATH env var.\n    \"\"\"\n    repo_input = RepositoryInput.from_environment()\n    repo_input.validate()\n    return repo_input\n</code></pre>"},{"location":"api/context/#sage_sanctum.context.AgentContext.write_output","title":"<code>write_output(output: AgentOutput) -&gt; list[str]</code>","text":"<p>Write agent output to the output directory.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of filenames written.</p> Source code in <code>src/sage_sanctum/context.py</code> <pre><code>def write_output(self, output: AgentOutput) -&gt; list[str]:\n    \"\"\"Write agent output to the output directory.\n\n    Returns:\n        List of filenames written.\n    \"\"\"\n    return output.write(self.output_dir)\n</code></pre>"},{"location":"api/context/#sage_sanctum.context.AgentContext.from_environment","title":"<code>from_environment() -&gt; AgentContext</code>  <code>classmethod</code>","text":"<p>Create context from environment variables (synchronous).</p> <p>Expected env vars: - RUN_ID: Run identifier (required) - ORG_ID: Organization identifier (required) - WORK_DIR: Working directory (default: /work) - OUTPUT_PATH: Output directory (default: /output) - SPIFFE_JWT_PATH: Path to SPIFFE JWT file - TRAT_FILE: Path to TraT file - AUTH_SIDECAR_SOCKET: Path to auth sidecar Unix socket - LLM_GATEWAY_SOCKET: Path to LLM gateway Unix socket - SAGE_SANCTUM_ALLOW_DIRECT: Set to '1' for direct provider access</p> Source code in <code>src/sage_sanctum/context.py</code> <pre><code>@classmethod\ndef from_environment(cls) -&gt; AgentContext:\n    \"\"\"Create context from environment variables (synchronous).\n\n    Expected env vars:\n    - RUN_ID: Run identifier (required)\n    - ORG_ID: Organization identifier (required)\n    - WORK_DIR: Working directory (default: /work)\n    - OUTPUT_PATH: Output directory (default: /output)\n    - SPIFFE_JWT_PATH: Path to SPIFFE JWT file\n    - TRAT_FILE: Path to TraT file\n    - AUTH_SIDECAR_SOCKET: Path to auth sidecar Unix socket\n    - LLM_GATEWAY_SOCKET: Path to LLM gateway Unix socket\n    - SAGE_SANCTUM_ALLOW_DIRECT: Set to '1' for direct provider access\n    \"\"\"\n    run_id = os.environ.get(\"RUN_ID\", \"\")\n    org_id = os.environ.get(\"ORG_ID\", \"\")\n\n    if not run_id:\n        raise ConfigurationError(\"RUN_ID environment variable not set\")\n    if not org_id:\n        raise ConfigurationError(\"ORG_ID environment variable not set\")\n\n    work_dir = Path(os.environ.get(\"WORK_DIR\", \"/work\"))\n    output_dir = Path(os.environ.get(\"OUTPUT_PATH\", \"/output\"))\n\n    # Build gateway client\n    gateway_client = cls._create_gateway_client()\n\n    # Build model selector from TraT or environment\n    model_selector = cls._create_model_selector(gateway_client)\n\n    return cls(\n        run_id=run_id,\n        org_id=org_id,\n        work_dir=work_dir,\n        output_dir=output_dir,\n        gateway_client=gateway_client,\n        model_selector=model_selector,\n    )\n</code></pre>"},{"location":"api/context/#sage_sanctum.context.AgentContext.from_environment_async","title":"<code>from_environment_async() -&gt; AgentContext</code>  <code>async</code> <code>classmethod</code>","text":"<p>Async version of from_environment. Currently identical.</p> Source code in <code>src/sage_sanctum/context.py</code> <pre><code>@classmethod\nasync def from_environment_async(cls) -&gt; AgentContext:\n    \"\"\"Async version of from_environment. Currently identical.\"\"\"\n    return cls.from_environment()\n</code></pre>"},{"location":"api/context/#sage_sanctum.context.AgentContext.for_local_development","title":"<code>for_local_development(work_dir: str | Path = '.', output_dir: str | Path = './output', model: str = 'gpt-4o') -&gt; AgentContext</code>  <code>classmethod</code>","text":"<p>Create context for local development with direct API keys.</p> <p>Bypasses the gateway and calls LLM providers directly using API keys from environment variables. Sets <code>SAGE_SANCTUM_ALLOW_DIRECT=1</code> automatically.</p> <p>Parameters:</p> Name Type Description Default <code>work_dir</code> <code>str | Path</code> <p>Working directory for temporary files.</p> <code>'.'</code> <code>output_dir</code> <code>str | Path</code> <p>Directory for agent output.</p> <code>'./output'</code> <code>model</code> <code>str</code> <p>Model reference string (e.g. <code>\"openai:gpt-4o\"</code>). Used for all categories via <code>StaticModelSelector</code>.</p> <code>'gpt-4o'</code> <p>Returns:</p> Type Description <code>AgentContext</code> <p>A fully configured <code>AgentContext</code> in direct mode.</p> Source code in <code>src/sage_sanctum/context.py</code> <pre><code>@classmethod\ndef for_local_development(\n    cls,\n    work_dir: str | Path = \".\",\n    output_dir: str | Path = \"./output\",\n    model: str = \"gpt-4o\",\n) -&gt; AgentContext:\n    \"\"\"Create context for local development with direct API keys.\n\n    Bypasses the gateway and calls LLM providers directly using API keys\n    from environment variables. Sets ``SAGE_SANCTUM_ALLOW_DIRECT=1``\n    automatically.\n\n    Args:\n        work_dir: Working directory for temporary files.\n        output_dir: Directory for agent output.\n        model: Model reference string (e.g. ``\"openai:gpt-4o\"``). Used\n            for all categories via ``StaticModelSelector``.\n\n    Returns:\n        A fully configured ``AgentContext`` in direct mode.\n    \"\"\"\n    os.environ.setdefault(\"SAGE_SANCTUM_ALLOW_DIRECT\", \"1\")\n\n    return cls(\n        run_id=\"local\",\n        org_id=\"local\",\n        work_dir=Path(work_dir),\n        output_dir=Path(output_dir),\n        gateway_client=DirectProviderClient(),\n        model_selector=StaticModelSelector(model),\n    )\n</code></pre>"},{"location":"api/context/#sage_sanctum.context.AgentContext.for_external_llm","title":"<code>for_external_llm() -&gt; AgentContext</code>  <code>classmethod</code>","text":"<p>Create a minimal context for agents that manage their own LLM access.</p> <p>Only reads <code>RUN_ID</code>, <code>ORG_ID</code>, <code>WORK_DIR</code>, and <code>OUTPUT_PATH</code> from the environment. Skips all SPIFFE, TraT, and gateway setup.</p> <p>The resulting context has <code>gateway_client=None</code> and <code>model_selector=None</code>. Calling <code>create_llm_client()</code>, <code>create_embeddings_client()</code>, or <code>check_gateway_health()</code> will raise <code>ConfigurationError</code>.</p> <p>Returns:</p> Type Description <code>AgentContext</code> <p>An <code>AgentContext</code> suitable for external-LLM agents.</p> Source code in <code>src/sage_sanctum/context.py</code> <pre><code>@classmethod\ndef for_external_llm(cls) -&gt; AgentContext:\n    \"\"\"Create a minimal context for agents that manage their own LLM access.\n\n    Only reads ``RUN_ID``, ``ORG_ID``, ``WORK_DIR``, and ``OUTPUT_PATH``\n    from the environment. Skips all SPIFFE, TraT, and gateway setup.\n\n    The resulting context has ``gateway_client=None`` and\n    ``model_selector=None``. Calling ``create_llm_client()``,\n    ``create_embeddings_client()``, or ``check_gateway_health()``\n    will raise ``ConfigurationError``.\n\n    Returns:\n        An ``AgentContext`` suitable for external-LLM agents.\n    \"\"\"\n    run_id = os.environ.get(\"RUN_ID\", \"\")\n    org_id = os.environ.get(\"ORG_ID\", \"\")\n\n    if not run_id:\n        raise ConfigurationError(\"RUN_ID environment variable not set\")\n    if not org_id:\n        raise ConfigurationError(\"ORG_ID environment variable not set\")\n\n    work_dir = Path(os.environ.get(\"WORK_DIR\", \"/work\"))\n    output_dir = Path(os.environ.get(\"OUTPUT_PATH\", \"/output\"))\n\n    return cls(\n        run_id=run_id,\n        org_id=org_id,\n        work_dir=work_dir,\n        output_dir=output_dir,\n    )\n</code></pre>"},{"location":"api/errors/","title":"sage_sanctum.errors","text":"<p>Error hierarchy with structured exit codes for process-level signaling.</p>"},{"location":"api/errors/#sage_sanctum.errors","title":"<code>sage_sanctum.errors</code>","text":"<p>Error hierarchy for Sage Sanctum Agent SDK.</p> <p>Exit code ranges: - 10-19: Authentication errors - 20-29: Authorization errors - 30-39: Gateway errors - 40-49: Validation errors - 50-59: Output errors - 60-69: Model errors - 70-79: External tool errors</p>"},{"location":"api/errors/#sage_sanctum.errors.SageSanctumError","title":"<code>SageSanctumError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base error for all Sage Sanctum SDK errors.</p> <p>Every subclass defines a class-level <code>exit_code</code> so the <code>AgentRunner</code> can map exceptions to process exit codes automatically.</p> <p>Attributes:</p> Name Type Description <code>exit_code</code> <code>int</code> <p>Process exit code returned when this error propagates to <code>AgentRunner</code>. Defaults to <code>1</code>.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error description.</p> required <code>exit_code</code> <code>int | None</code> <p>Override the class-level exit code for this instance.</p> <code>None</code> Source code in <code>src/sage_sanctum/errors.py</code> <pre><code>class SageSanctumError(Exception):\n    \"\"\"Base error for all Sage Sanctum SDK errors.\n\n    Every subclass defines a class-level ``exit_code`` so the ``AgentRunner``\n    can map exceptions to process exit codes automatically.\n\n    Attributes:\n        exit_code: Process exit code returned when this error propagates\n            to ``AgentRunner``. Defaults to ``1``.\n\n    Args:\n        message: Human-readable error description.\n        exit_code: Override the class-level exit code for this instance.\n    \"\"\"\n\n    exit_code: int = 1\n\n    def __init__(self, message: str, exit_code: int | None = None):\n        super().__init__(message)\n        if exit_code is not None:\n            self.exit_code = exit_code\n</code></pre>"},{"location":"api/errors/#sage_sanctum.errors.AuthError","title":"<code>AuthError</code>","text":"<p>               Bases: <code>SageSanctumError</code></p> <p>Base authentication error (exit codes 10\u201319).</p> <p>Raised when agent identity or token acquisition fails.</p> Source code in <code>src/sage_sanctum/errors.py</code> <pre><code>class AuthError(SageSanctumError):\n    \"\"\"Base authentication error (exit codes 10\u201319).\n\n    Raised when agent identity or token acquisition fails.\n    \"\"\"\n\n    exit_code = 10\n</code></pre>"},{"location":"api/errors/#sage_sanctum.errors.SpiffeAuthError","title":"<code>SpiffeAuthError</code>","text":"<p>               Bases: <code>AuthError</code></p> <p>SPIFFE JWT acquisition or validation failed.</p> <p>Raised when the JWT SVID file cannot be read, is empty, or contains a malformed token.</p> Source code in <code>src/sage_sanctum/errors.py</code> <pre><code>class SpiffeAuthError(AuthError):\n    \"\"\"SPIFFE JWT acquisition or validation failed.\n\n    Raised when the JWT SVID file cannot be read, is empty, or contains\n    a malformed token.\n    \"\"\"\n\n    exit_code = 11\n</code></pre>"},{"location":"api/errors/#sage_sanctum.errors.TraTAcquisitionError","title":"<code>TraTAcquisitionError</code>","text":"<p>               Bases: <code>AuthError</code></p> <p>Failed to acquire a Transaction Token.</p> <p>Raised when the TraT file or auth sidecar is unavailable, or the token is malformed.</p> Source code in <code>src/sage_sanctum/errors.py</code> <pre><code>class TraTAcquisitionError(AuthError):\n    \"\"\"Failed to acquire a Transaction Token.\n\n    Raised when the TraT file or auth sidecar is unavailable, or the\n    token is malformed.\n    \"\"\"\n\n    exit_code = 12\n</code></pre>"},{"location":"api/errors/#sage_sanctum.errors.TraTExpiredError","title":"<code>TraTExpiredError</code>","text":"<p>               Bases: <code>AuthError</code></p> <p>Transaction Token has expired.</p> <p>Raised by <code>TransactionToken.check_not_expired()</code> when the <code>exp</code> claim is in the past.</p> Source code in <code>src/sage_sanctum/errors.py</code> <pre><code>class TraTExpiredError(AuthError):\n    \"\"\"Transaction Token has expired.\n\n    Raised by ``TransactionToken.check_not_expired()`` when the ``exp``\n    claim is in the past.\n    \"\"\"\n\n    exit_code = 13\n</code></pre>"},{"location":"api/errors/#sage_sanctum.errors.ForbiddenError","title":"<code>ForbiddenError</code>","text":"<p>               Bases: <code>SageSanctumError</code></p> <p>Action not authorized (exit codes 20\u201329).</p> <p>Raised when the agent attempts an operation it is not permitted to perform.</p> Source code in <code>src/sage_sanctum/errors.py</code> <pre><code>class ForbiddenError(SageSanctumError):\n    \"\"\"Action not authorized (exit codes 20\u201329).\n\n    Raised when the agent attempts an operation it is not permitted to perform.\n    \"\"\"\n\n    exit_code = 20\n</code></pre>"},{"location":"api/errors/#sage_sanctum.errors.ModelNotAuthorizedError","title":"<code>ModelNotAuthorizedError</code>","text":"<p>               Bases: <code>ForbiddenError</code></p> <p>Requested model is not in the TraT <code>allowed_models</code> list.</p> <p>Raised by <code>ModelSelector.validate_model()</code> when the model is not permitted for the given category.</p> Source code in <code>src/sage_sanctum/errors.py</code> <pre><code>class ModelNotAuthorizedError(ForbiddenError):\n    \"\"\"Requested model is not in the TraT ``allowed_models`` list.\n\n    Raised by ``ModelSelector.validate_model()`` when the model is not\n    permitted for the given category.\n    \"\"\"\n\n    exit_code = 21\n</code></pre>"},{"location":"api/errors/#sage_sanctum.errors.ScopeNotAuthorizedError","title":"<code>ScopeNotAuthorizedError</code>","text":"<p>               Bases: <code>ForbiddenError</code></p> <p>Requested scope is not authorized in the Transaction Token.</p> Source code in <code>src/sage_sanctum/errors.py</code> <pre><code>class ScopeNotAuthorizedError(ForbiddenError):\n    \"\"\"Requested scope is not authorized in the Transaction Token.\"\"\"\n\n    exit_code = 22\n</code></pre>"},{"location":"api/errors/#sage_sanctum.errors.GatewayError","title":"<code>GatewayError</code>","text":"<p>               Bases: <code>SageSanctumError</code></p> <p>Base gateway communication error (exit codes 30\u201339).</p> <p>Raised when communication with the LLM or MCP gateway fails.</p> Source code in <code>src/sage_sanctum/errors.py</code> <pre><code>class GatewayError(SageSanctumError):\n    \"\"\"Base gateway communication error (exit codes 30\u201339).\n\n    Raised when communication with the LLM or MCP gateway fails.\n    \"\"\"\n\n    exit_code = 30\n</code></pre>"},{"location":"api/errors/#sage_sanctum.errors.RateLimitError","title":"<code>RateLimitError</code>","text":"<p>               Bases: <code>GatewayError</code></p> <p>Rate limit exceeded at the gateway or upstream provider.</p> Source code in <code>src/sage_sanctum/errors.py</code> <pre><code>class RateLimitError(GatewayError):\n    \"\"\"Rate limit exceeded at the gateway or upstream provider.\"\"\"\n\n    exit_code = 31\n</code></pre>"},{"location":"api/errors/#sage_sanctum.errors.GatewayUnavailableError","title":"<code>GatewayUnavailableError</code>","text":"<p>               Bases: <code>GatewayError</code></p> <p>Gateway is unreachable (connection refused, socket not found, etc.).</p> Source code in <code>src/sage_sanctum/errors.py</code> <pre><code>class GatewayUnavailableError(GatewayError):\n    \"\"\"Gateway is unreachable (connection refused, socket not found, etc.).\"\"\"\n\n    exit_code = 32\n</code></pre>"},{"location":"api/errors/#sage_sanctum.errors.ValidationError","title":"<code>ValidationError</code>","text":"<p>               Bases: <code>SageSanctumError</code></p> <p>Base validation error (exit codes 40\u201349).</p> <p>Raised when input, path, or configuration validation fails.</p> Source code in <code>src/sage_sanctum/errors.py</code> <pre><code>class ValidationError(SageSanctumError):\n    \"\"\"Base validation error (exit codes 40\u201349).\n\n    Raised when input, path, or configuration validation fails.\n    \"\"\"\n\n    exit_code = 40\n</code></pre>"},{"location":"api/errors/#sage_sanctum.errors.InputValidationError","title":"<code>InputValidationError</code>","text":"<p>               Bases: <code>ValidationError</code></p> <p>Agent input validation failed.</p> <p>Raised when <code>RepositoryInput.validate()</code> detects a missing or invalid repository path.</p> Source code in <code>src/sage_sanctum/errors.py</code> <pre><code>class InputValidationError(ValidationError):\n    \"\"\"Agent input validation failed.\n\n    Raised when ``RepositoryInput.validate()`` detects a missing or\n    invalid repository path.\n    \"\"\"\n\n    exit_code = 41\n</code></pre>"},{"location":"api/errors/#sage_sanctum.errors.PathTraversalError","title":"<code>PathTraversalError</code>","text":"<p>               Bases: <code>ValidationError</code></p> <p>Path traversal attempt detected in a file path (<code>..</code> components).</p> Source code in <code>src/sage_sanctum/errors.py</code> <pre><code>class PathTraversalError(ValidationError):\n    \"\"\"Path traversal attempt detected in a file path (``..`` components).\"\"\"\n\n    exit_code = 42\n</code></pre>"},{"location":"api/errors/#sage_sanctum.errors.ConfigurationError","title":"<code>ConfigurationError</code>","text":"<p>               Bases: <code>ValidationError</code></p> <p>Missing or invalid SDK configuration.</p> <p>Raised when required environment variables are missing or mutually exclusive options conflict.</p> Source code in <code>src/sage_sanctum/errors.py</code> <pre><code>class ConfigurationError(ValidationError):\n    \"\"\"Missing or invalid SDK configuration.\n\n    Raised when required environment variables are missing or mutually\n    exclusive options conflict.\n    \"\"\"\n\n    exit_code = 43\n</code></pre>"},{"location":"api/errors/#sage_sanctum.errors.OutputError","title":"<code>OutputError</code>","text":"<p>               Bases: <code>SageSanctumError</code></p> <p>Base output error (exit codes 50\u201359).</p> <p>Raised when agent output cannot be written or is invalid.</p> Source code in <code>src/sage_sanctum/errors.py</code> <pre><code>class OutputError(SageSanctumError):\n    \"\"\"Base output error (exit codes 50\u201359).\n\n    Raised when agent output cannot be written or is invalid.\n    \"\"\"\n\n    exit_code = 50\n</code></pre>"},{"location":"api/errors/#sage_sanctum.errors.OutputWriteError","title":"<code>OutputWriteError</code>","text":"<p>               Bases: <code>OutputError</code></p> <p>Failed to write output files to the output directory.</p> Source code in <code>src/sage_sanctum/errors.py</code> <pre><code>class OutputWriteError(OutputError):\n    \"\"\"Failed to write output files to the output directory.\"\"\"\n\n    exit_code = 51\n</code></pre>"},{"location":"api/errors/#sage_sanctum.errors.SarifValidationError","title":"<code>SarifValidationError</code>","text":"<p>               Bases: <code>OutputError</code></p> <p>SARIF output failed schema validation.</p> Source code in <code>src/sage_sanctum/errors.py</code> <pre><code>class SarifValidationError(OutputError):\n    \"\"\"SARIF output failed schema validation.\"\"\"\n\n    exit_code = 52\n</code></pre>"},{"location":"api/errors/#sage_sanctum.errors.ModelError","title":"<code>ModelError</code>","text":"<p>               Bases: <code>SageSanctumError</code></p> <p>Base model error (exit codes 60\u201369).</p> <p>Raised when model selection or reference parsing fails.</p> Source code in <code>src/sage_sanctum/errors.py</code> <pre><code>class ModelError(SageSanctumError):\n    \"\"\"Base model error (exit codes 60\u201369).\n\n    Raised when model selection or reference parsing fails.\n    \"\"\"\n\n    exit_code = 60\n</code></pre>"},{"location":"api/errors/#sage_sanctum.errors.ModelNotAvailableError","title":"<code>ModelNotAvailableError</code>","text":"<p>               Bases: <code>ModelError</code></p> <p>No model is configured for the requested category.</p> <p>Raised by <code>ModelSelector.select()</code> when the TraT <code>allowed_models</code> list is empty for a given <code>ModelCategory</code>.</p> Source code in <code>src/sage_sanctum/errors.py</code> <pre><code>class ModelNotAvailableError(ModelError):\n    \"\"\"No model is configured for the requested category.\n\n    Raised by ``ModelSelector.select()`` when the TraT ``allowed_models``\n    list is empty for a given ``ModelCategory``.\n    \"\"\"\n\n    exit_code = 61\n</code></pre>"},{"location":"api/errors/#sage_sanctum.errors.ModelRefParseError","title":"<code>ModelRefParseError</code>","text":"<p>               Bases: <code>ModelError</code></p> <p>Failed to parse a model reference string.</p> <p>Raised by <code>ModelRef.parse()</code> when the input is empty or malformed.</p> Source code in <code>src/sage_sanctum/errors.py</code> <pre><code>class ModelRefParseError(ModelError):\n    \"\"\"Failed to parse a model reference string.\n\n    Raised by ``ModelRef.parse()`` when the input is empty or malformed.\n    \"\"\"\n\n    exit_code = 62\n</code></pre>"},{"location":"api/errors/#sage_sanctum.errors.ExternalToolError","title":"<code>ExternalToolError</code>","text":"<p>               Bases: <code>SageSanctumError</code></p> <p>Base external tool error (exit codes 70\u201379).</p> <p>Raised when an external subprocess or tool used by the agent fails.</p> Source code in <code>src/sage_sanctum/errors.py</code> <pre><code>class ExternalToolError(SageSanctumError):\n    \"\"\"Base external tool error (exit codes 70\u201379).\n\n    Raised when an external subprocess or tool used by the agent fails.\n    \"\"\"\n\n    exit_code = 70\n</code></pre>"},{"location":"api/errors/#sage_sanctum.errors.SubprocessError","title":"<code>SubprocessError</code>","text":"<p>               Bases: <code>ExternalToolError</code></p> <p>External subprocess exited with a non-zero return code.</p> <p>Attributes:</p> Name Type Description <code>returncode</code> <p>The process exit code.</p> <code>stderr</code> <p>Captured stderr output (may be truncated).</p> Source code in <code>src/sage_sanctum/errors.py</code> <pre><code>class SubprocessError(ExternalToolError):\n    \"\"\"External subprocess exited with a non-zero return code.\n\n    Attributes:\n        returncode: The process exit code.\n        stderr: Captured stderr output (may be truncated).\n    \"\"\"\n\n    exit_code = 71\n\n    def __init__(\n        self,\n        message: str,\n        *,\n        returncode: int = 1,\n        stderr: str = \"\",\n        exit_code: int | None = None,\n    ):\n        super().__init__(message, exit_code=exit_code)\n        self.returncode = returncode\n        self.stderr = stderr\n</code></pre>"},{"location":"api/errors/#sage_sanctum.errors.SubprocessTimeoutError","title":"<code>SubprocessTimeoutError</code>","text":"<p>               Bases: <code>ExternalToolError</code></p> <p>External subprocess exceeded its time limit.</p> Source code in <code>src/sage_sanctum/errors.py</code> <pre><code>class SubprocessTimeoutError(ExternalToolError):\n    \"\"\"External subprocess exceeded its time limit.\"\"\"\n\n    exit_code = 72\n</code></pre>"},{"location":"api/errors/#sage_sanctum.errors.OutputParseError","title":"<code>OutputParseError</code>","text":"<p>               Bases: <code>ExternalToolError</code></p> <p>Failed to parse output from an external tool.</p> Source code in <code>src/sage_sanctum/errors.py</code> <pre><code>class OutputParseError(ExternalToolError):\n    \"\"\"Failed to parse output from an external tool.\"\"\"\n\n    exit_code = 73\n</code></pre>"},{"location":"api/auth/","title":"sage_sanctum.auth","text":"<p>Authentication module providing SPIFFE identity and Transaction Token authorization.</p>"},{"location":"api/auth/#modules","title":"Modules","text":"Module Description <code>spiffe</code> SPIFFE JWT source with caching and refresh <code>trat</code> Transaction Token client and parsed models <code>credentials</code> Combined gateway credentials"},{"location":"api/auth/credentials/","title":"sage_sanctum.auth.credentials","text":"<p>Combined gateway credentials for SPIFFE + TraT authentication.</p>"},{"location":"api/auth/credentials/#sage_sanctum.auth.credentials","title":"<code>sage_sanctum.auth.credentials</code>","text":"<p>Gateway credentials: combined SPIFFE JWT + TraT for gateway authentication.</p>"},{"location":"api/auth/credentials/#sage_sanctum.auth.credentials.GatewayCredentials","title":"<code>GatewayCredentials</code>  <code>dataclass</code>","text":"<p>Combined credentials for authenticating to LLM/MCP gateways.</p> <p>The gateway validates both tokens on every request:</p> <ul> <li>SPIFFE JWT proves the agent's identity.</li> <li>TraT authorizes the specific transaction.</li> </ul> <p>Attributes:</p> Name Type Description <code>spiffe_jwt</code> <code>str</code> <p>SPIFFE JWT SVID for agent identity (<code>Authorization</code> header).</p> <code>trat</code> <code>str</code> <p>Transaction Token JWT for authorization (<code>Txn-Token</code> header).</p> Source code in <code>src/sage_sanctum/auth/credentials.py</code> <pre><code>@dataclass(frozen=True)\nclass GatewayCredentials:\n    \"\"\"Combined credentials for authenticating to LLM/MCP gateways.\n\n    The gateway validates both tokens on every request:\n\n    - **SPIFFE JWT** proves the agent's identity.\n    - **TraT** authorizes the specific transaction.\n\n    Attributes:\n        spiffe_jwt: SPIFFE JWT SVID for agent identity (``Authorization`` header).\n        trat: Transaction Token JWT for authorization (``Txn-Token`` header).\n    \"\"\"\n\n    spiffe_jwt: str\n    trat: str\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return masked representation to prevent credential leakage in logs.\"\"\"\n        return (\n            f\"GatewayCredentials(\"\n            f\"spiffe_jwt='{self.spiffe_jwt[:8]}...' \"\n            f\"trat='{self.trat[:8]}...')\"\n        )\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return masked string representation.\"\"\"\n        return self.__repr__()\n\n    def auth_headers(self) -&gt; dict[str, str]:\n        \"\"\"Return HTTP headers for gateway authentication.\n\n        Returns:\n            Dictionary with ``Authorization`` (Bearer) and ``Txn-Token`` headers.\n        \"\"\"\n        return {\n            \"Authorization\": f\"Bearer {self.spiffe_jwt}\",\n            \"Txn-Token\": self.trat,\n        }\n</code></pre>"},{"location":"api/auth/credentials/#sage_sanctum.auth.credentials.GatewayCredentials.__repr__","title":"<code>__repr__() -&gt; str</code>","text":"<p>Return masked representation to prevent credential leakage in logs.</p> Source code in <code>src/sage_sanctum/auth/credentials.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return masked representation to prevent credential leakage in logs.\"\"\"\n    return (\n        f\"GatewayCredentials(\"\n        f\"spiffe_jwt='{self.spiffe_jwt[:8]}...' \"\n        f\"trat='{self.trat[:8]}...')\"\n    )\n</code></pre>"},{"location":"api/auth/credentials/#sage_sanctum.auth.credentials.GatewayCredentials.__str__","title":"<code>__str__() -&gt; str</code>","text":"<p>Return masked string representation.</p> Source code in <code>src/sage_sanctum/auth/credentials.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return masked string representation.\"\"\"\n    return self.__repr__()\n</code></pre>"},{"location":"api/auth/credentials/#sage_sanctum.auth.credentials.GatewayCredentials.auth_headers","title":"<code>auth_headers() -&gt; dict[str, str]</code>","text":"<p>Return HTTP headers for gateway authentication.</p> <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Dictionary with <code>Authorization</code> (Bearer) and <code>Txn-Token</code> headers.</p> Source code in <code>src/sage_sanctum/auth/credentials.py</code> <pre><code>def auth_headers(self) -&gt; dict[str, str]:\n    \"\"\"Return HTTP headers for gateway authentication.\n\n    Returns:\n        Dictionary with ``Authorization`` (Bearer) and ``Txn-Token`` headers.\n    \"\"\"\n    return {\n        \"Authorization\": f\"Bearer {self.spiffe_jwt}\",\n        \"Txn-Token\": self.trat,\n    }\n</code></pre>"},{"location":"api/auth/spiffe/","title":"sage_sanctum.auth.spiffe","text":"<p>SPIFFE JWT source with automatic caching and refresh.</p>"},{"location":"api/auth/spiffe/#sage_sanctum.auth.spiffe","title":"<code>sage_sanctum.auth.spiffe</code>","text":"<p>SPIFFE JWT Source: read, cache, and refresh SPIFFE JWTs from file.</p>"},{"location":"api/auth/spiffe/#sage_sanctum.auth.spiffe.JWTSource","title":"<code>JWTSource</code>","text":"<p>Reads and caches SPIFFE JWTs from a file path.</p> <p>The SPIRE agent writes the JWT SVID to a well-known file path. This class reads it, caches it in memory, and automatically refreshes 5 minutes before expiry (<code>_REFRESH_BUFFER_SECONDS</code>).</p> <p>Parameters:</p> Name Type Description Default <code>jwt_path</code> <code>str | Path</code> <p>Filesystem path to the SPIFFE JWT SVID file.</p> required <p>Attributes:</p> Name Type Description <code>path</code> <code>Path</code> <p>Resolved <code>Path</code> to the JWT file.</p> Source code in <code>src/sage_sanctum/auth/spiffe.py</code> <pre><code>class JWTSource:\n    \"\"\"Reads and caches SPIFFE JWTs from a file path.\n\n    The SPIRE agent writes the JWT SVID to a well-known file path. This class\n    reads it, caches it in memory, and automatically refreshes 5 minutes before\n    expiry (``_REFRESH_BUFFER_SECONDS``).\n\n    Args:\n        jwt_path: Filesystem path to the SPIFFE JWT SVID file.\n\n    Attributes:\n        path: Resolved ``Path`` to the JWT file.\n    \"\"\"\n\n    def __init__(self, jwt_path: str | Path) -&gt; None:\n        self._path = Path(jwt_path)\n        self._cached_token: str | None = None\n        self._cached_expiry: float = 0.0\n\n    @property\n    def path(self) -&gt; Path:\n        \"\"\"Filesystem path to the JWT file.\"\"\"\n        return self._path\n\n    def get_token(self) -&gt; str:\n        \"\"\"Get a valid SPIFFE JWT, refreshing from file if needed.\n\n        Returns the cached token if it is still valid (with a 5-minute buffer\n        before expiry). Otherwise, reads a fresh token from the file.\n\n        Returns:\n            Raw JWT string suitable for the ``Authorization: Bearer`` header.\n\n        Raises:\n            SpiffeAuthError: If the JWT file cannot be read or is invalid.\n        \"\"\"\n        now = time.time()\n\n        # Return cached token if still valid (with buffer)\n        if self._cached_token and now &lt; (self._cached_expiry - _REFRESH_BUFFER_SECONDS):\n            return self._cached_token\n\n        # Read fresh token from file\n        return self._refresh()\n\n    def _refresh(self) -&gt; str:\n        \"\"\"Read JWT from file and update cache.\n\n        Raises:\n            SpiffeAuthError: If the file is missing, empty, malformed, or\n                the JWT has already expired.\n        \"\"\"\n        if not self._path.exists():\n            raise SpiffeAuthError(f\"SPIFFE JWT file not found: {self._path}\")\n\n        try:\n            token = self._path.read_text().strip()\n        except OSError as e:\n            raise SpiffeAuthError(f\"Failed to read SPIFFE JWT from {self._path}: {e}\") from e\n\n        if not token:\n            raise SpiffeAuthError(f\"SPIFFE JWT file is empty: {self._path}\")\n\n        # Decode payload to get expiry (no signature verification)\n        payload = _decode_jwt_payload(token)\n        exp = payload.get(\"exp\")\n        if exp is None:\n            raise SpiffeAuthError(\"SPIFFE JWT missing 'exp' claim\")\n\n        exp_float = float(exp)\n\n        # Reject already-expired JWTs \u2014 the file is static (written by init\n        # container) and re-reading it won't yield a fresh token.\n        if time.time() &gt;= exp_float:\n            raise SpiffeAuthError(\n                f\"SPIFFE JWT from {self._path} has expired \"\n                f\"(exp={exp_float:.0f}, now={time.time():.0f}). \"\n                \"The init container JWT is no longer valid.\"\n            )\n\n        self._cached_token = token\n        self._cached_expiry = exp_float\n\n        logger.debug(\n            \"spiffe_jwt_refreshed\",\n            path=str(self._path),\n            expiry=str(self._cached_expiry),\n        )\n        return token\n\n    def is_expired(self) -&gt; bool:\n        \"\"\"Check if the cached token is expired or about to expire.\n\n        Returns:\n            ``True`` if no token is cached, or it will expire within\n            ``_REFRESH_BUFFER_SECONDS`` (300 s).\n        \"\"\"\n        if not self._cached_token:\n            return True\n        return time.time() &gt;= (self._cached_expiry - _REFRESH_BUFFER_SECONDS)\n\n    def invalidate(self) -&gt; None:\n        \"\"\"Clear the cached token, forcing a refresh on next access.\"\"\"\n        self._cached_token = None\n        self._cached_expiry = 0.0\n</code></pre>"},{"location":"api/auth/spiffe/#sage_sanctum.auth.spiffe.JWTSource.path","title":"<code>path: Path</code>  <code>property</code>","text":"<p>Filesystem path to the JWT file.</p>"},{"location":"api/auth/spiffe/#sage_sanctum.auth.spiffe.JWTSource.get_token","title":"<code>get_token() -&gt; str</code>","text":"<p>Get a valid SPIFFE JWT, refreshing from file if needed.</p> <p>Returns the cached token if it is still valid (with a 5-minute buffer before expiry). Otherwise, reads a fresh token from the file.</p> <p>Returns:</p> Type Description <code>str</code> <p>Raw JWT string suitable for the <code>Authorization: Bearer</code> header.</p> <p>Raises:</p> Type Description <code>SpiffeAuthError</code> <p>If the JWT file cannot be read or is invalid.</p> Source code in <code>src/sage_sanctum/auth/spiffe.py</code> <pre><code>def get_token(self) -&gt; str:\n    \"\"\"Get a valid SPIFFE JWT, refreshing from file if needed.\n\n    Returns the cached token if it is still valid (with a 5-minute buffer\n    before expiry). Otherwise, reads a fresh token from the file.\n\n    Returns:\n        Raw JWT string suitable for the ``Authorization: Bearer`` header.\n\n    Raises:\n        SpiffeAuthError: If the JWT file cannot be read or is invalid.\n    \"\"\"\n    now = time.time()\n\n    # Return cached token if still valid (with buffer)\n    if self._cached_token and now &lt; (self._cached_expiry - _REFRESH_BUFFER_SECONDS):\n        return self._cached_token\n\n    # Read fresh token from file\n    return self._refresh()\n</code></pre>"},{"location":"api/auth/spiffe/#sage_sanctum.auth.spiffe.JWTSource.is_expired","title":"<code>is_expired() -&gt; bool</code>","text":"<p>Check if the cached token is expired or about to expire.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if no token is cached, or it will expire within</p> <code>bool</code> <p><code>_REFRESH_BUFFER_SECONDS</code> (300 s).</p> Source code in <code>src/sage_sanctum/auth/spiffe.py</code> <pre><code>def is_expired(self) -&gt; bool:\n    \"\"\"Check if the cached token is expired or about to expire.\n\n    Returns:\n        ``True`` if no token is cached, or it will expire within\n        ``_REFRESH_BUFFER_SECONDS`` (300 s).\n    \"\"\"\n    if not self._cached_token:\n        return True\n    return time.time() &gt;= (self._cached_expiry - _REFRESH_BUFFER_SECONDS)\n</code></pre>"},{"location":"api/auth/spiffe/#sage_sanctum.auth.spiffe.JWTSource.invalidate","title":"<code>invalidate() -&gt; None</code>","text":"<p>Clear the cached token, forcing a refresh on next access.</p> Source code in <code>src/sage_sanctum/auth/spiffe.py</code> <pre><code>def invalidate(self) -&gt; None:\n    \"\"\"Clear the cached token, forcing a refresh on next access.\"\"\"\n    self._cached_token = None\n    self._cached_expiry = 0.0\n</code></pre>"},{"location":"api/auth/trat/","title":"sage_sanctum.auth.trat","text":"<p>Transaction Token client and parsed token models.</p>"},{"location":"api/auth/trat/#sage_sanctum.auth.trat","title":"<code>sage_sanctum.auth.trat</code>","text":"<p>Transaction Token (TraT) client and data models.</p> <p>Reads TraTs from file (TRAT_FILE) or auth sidecar socket (AUTH_SIDECAR_SOCKET). TraTs are IETF-standard JWTs (draft-ietf-oauth-transaction-tokens) that authorize a specific transaction within the Sage Sanctum platform.</p>"},{"location":"api/auth/trat/#sage_sanctum.auth.trat.RequesterContext","title":"<code>RequesterContext</code>  <code>dataclass</code>","text":"<p>Audit metadata from the TraT <code>rctx</code> claim.</p> <p>Describes what triggered the agent run and who initiated it.</p> <p>Attributes:</p> Name Type Description <code>trigger</code> <code>str</code> <p>Event type that triggered the run (e.g. <code>\"pull_request\"</code>).</p> <code>pr_number</code> <code>int | None</code> <p>Pull request number, if the trigger was a PR event.</p> <code>actor</code> <code>str</code> <p>User or bot that initiated the run (e.g. <code>\"dependabot[bot]\"</code>).</p> <code>source_ip</code> <code>str</code> <p>IP address of the triggering event source.</p> Source code in <code>src/sage_sanctum/auth/trat.py</code> <pre><code>@dataclass(frozen=True)\nclass RequesterContext:\n    \"\"\"Audit metadata from the TraT ``rctx`` claim.\n\n    Describes what triggered the agent run and who initiated it.\n\n    Attributes:\n        trigger: Event type that triggered the run (e.g. ``\"pull_request\"``).\n        pr_number: Pull request number, if the trigger was a PR event.\n        actor: User or bot that initiated the run (e.g. ``\"dependabot[bot]\"``).\n        source_ip: IP address of the triggering event source.\n    \"\"\"\n\n    trigger: str = \"\"\n    pr_number: int | None = None\n    actor: str = \"\"\n    source_ip: str = \"\"\n\n    @classmethod\n    def from_dict(cls, data: dict) -&gt; RequesterContext:\n        \"\"\"Create from a decoded JWT ``rctx`` claim dictionary.\"\"\"\n        return cls(\n            trigger=data.get(\"trigger\", \"\"),\n            pr_number=data.get(\"pr_number\"),\n            actor=data.get(\"actor\", \"\"),\n            source_ip=data.get(\"source_ip\", \"\"),\n        )\n</code></pre>"},{"location":"api/auth/trat/#sage_sanctum.auth.trat.RequesterContext.from_dict","title":"<code>from_dict(data: dict) -&gt; RequesterContext</code>  <code>classmethod</code>","text":"<p>Create from a decoded JWT <code>rctx</code> claim dictionary.</p> Source code in <code>src/sage_sanctum/auth/trat.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict) -&gt; RequesterContext:\n    \"\"\"Create from a decoded JWT ``rctx`` claim dictionary.\"\"\"\n    return cls(\n        trigger=data.get(\"trigger\", \"\"),\n        pr_number=data.get(\"pr_number\"),\n        actor=data.get(\"actor\", \"\"),\n        source_ip=data.get(\"source_ip\", \"\"),\n    )\n</code></pre>"},{"location":"api/auth/trat/#sage_sanctum.auth.trat.AllowedModels","title":"<code>AllowedModels</code>  <code>dataclass</code>","text":"<p>Model allowlists per category from <code>tctx.allowed_models</code>.</p> <p>Each field contains a list of <code>provider:model</code> reference strings that the agent is authorized to use for that category.</p> <p>Attributes:</p> Name Type Description <code>triage</code> <code>list[str]</code> <p>Models allowed for quick triage/classification tasks.</p> <code>analysis</code> <code>list[str]</code> <p>Models allowed for detailed analysis.</p> <code>reasoning</code> <code>list[str]</code> <p>Models allowed for complex reasoning.</p> <code>embeddings</code> <code>list[str]</code> <p>Models allowed for embedding generation.</p> Source code in <code>src/sage_sanctum/auth/trat.py</code> <pre><code>@dataclass(frozen=True)\nclass AllowedModels:\n    \"\"\"Model allowlists per category from ``tctx.allowed_models``.\n\n    Each field contains a list of ``provider:model`` reference strings\n    that the agent is authorized to use for that category.\n\n    Attributes:\n        triage: Models allowed for quick triage/classification tasks.\n        analysis: Models allowed for detailed analysis.\n        reasoning: Models allowed for complex reasoning.\n        embeddings: Models allowed for embedding generation.\n    \"\"\"\n\n    triage: list[str] = field(default_factory=list)\n    analysis: list[str] = field(default_factory=list)\n    reasoning: list[str] = field(default_factory=list)\n    embeddings: list[str] = field(default_factory=list)\n\n    @classmethod\n    def from_dict(cls, data: dict) -&gt; AllowedModels:\n        \"\"\"Create from a decoded ``tctx.allowed_models`` dictionary.\"\"\"\n        return cls(\n            triage=data.get(\"triage\", []),\n            analysis=data.get(\"analysis\", []),\n            reasoning=data.get(\"reasoning\", []),\n            embeddings=data.get(\"embeddings\", []),\n        )\n\n    def has_any(self) -&gt; bool:\n        \"\"\"Return ``True`` if any category has at least one model.\"\"\"\n        return bool(self.triage or self.analysis or self.reasoning or self.embeddings)\n\n    def to_dict(self) -&gt; dict[str, list[str]]:\n        \"\"\"Serialize to a plain dictionary keyed by category name.\"\"\"\n        return {\n            \"triage\": self.triage,\n            \"analysis\": self.analysis,\n            \"reasoning\": self.reasoning,\n            \"embeddings\": self.embeddings,\n        }\n</code></pre>"},{"location":"api/auth/trat/#sage_sanctum.auth.trat.AllowedModels.from_dict","title":"<code>from_dict(data: dict) -&gt; AllowedModels</code>  <code>classmethod</code>","text":"<p>Create from a decoded <code>tctx.allowed_models</code> dictionary.</p> Source code in <code>src/sage_sanctum/auth/trat.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict) -&gt; AllowedModels:\n    \"\"\"Create from a decoded ``tctx.allowed_models`` dictionary.\"\"\"\n    return cls(\n        triage=data.get(\"triage\", []),\n        analysis=data.get(\"analysis\", []),\n        reasoning=data.get(\"reasoning\", []),\n        embeddings=data.get(\"embeddings\", []),\n    )\n</code></pre>"},{"location":"api/auth/trat/#sage_sanctum.auth.trat.AllowedModels.has_any","title":"<code>has_any() -&gt; bool</code>","text":"<p>Return <code>True</code> if any category has at least one model.</p> Source code in <code>src/sage_sanctum/auth/trat.py</code> <pre><code>def has_any(self) -&gt; bool:\n    \"\"\"Return ``True`` if any category has at least one model.\"\"\"\n    return bool(self.triage or self.analysis or self.reasoning or self.embeddings)\n</code></pre>"},{"location":"api/auth/trat/#sage_sanctum.auth.trat.AllowedModels.to_dict","title":"<code>to_dict() -&gt; dict[str, list[str]]</code>","text":"<p>Serialize to a plain dictionary keyed by category name.</p> Source code in <code>src/sage_sanctum/auth/trat.py</code> <pre><code>def to_dict(self) -&gt; dict[str, list[str]]:\n    \"\"\"Serialize to a plain dictionary keyed by category name.\"\"\"\n    return {\n        \"triage\": self.triage,\n        \"analysis\": self.analysis,\n        \"reasoning\": self.reasoning,\n        \"embeddings\": self.embeddings,\n    }\n</code></pre>"},{"location":"api/auth/trat/#sage_sanctum.auth.trat.TransactionContext","title":"<code>TransactionContext</code>  <code>dataclass</code>","text":"<p>Immutable run parameters from the TraT <code>tctx</code> claim.</p> <p>Carries the full authorization envelope for a single agent run.</p> <p>Attributes:</p> Name Type Description <code>run_id</code> <code>str</code> <p>Unique identifier for this run.</p> <code>org_id</code> <code>str</code> <p>Organization that owns the repository being scanned.</p> <code>repo_url</code> <code>str</code> <p>HTTPS URL of the repository.</p> <code>agent_type</code> <code>str</code> <p>Agent type identifier (e.g. <code>\"sage-scanner\"</code>).</p> <code>agent_mode</code> <code>str</code> <p>Execution mode (e.g. <code>\"standard\"</code>, <code>\"deep\"</code>).</p> <code>allowed_models</code> <code>AllowedModels</code> <p>Per-category model allowlists.</p> <code>allowed_providers</code> <code>list[str]</code> <p>Provider names the agent may use (e.g. <code>[\"openai\"]</code>).</p> <code>allowed_tools</code> <code>dict[str, list[str]]</code> <p>MCP tools the agent may invoke, keyed by server name.</p> Source code in <code>src/sage_sanctum/auth/trat.py</code> <pre><code>@dataclass(frozen=True)\nclass TransactionContext:\n    \"\"\"Immutable run parameters from the TraT ``tctx`` claim.\n\n    Carries the full authorization envelope for a single agent run.\n\n    Attributes:\n        run_id: Unique identifier for this run.\n        org_id: Organization that owns the repository being scanned.\n        repo_url: HTTPS URL of the repository.\n        agent_type: Agent type identifier (e.g. ``\"sage-scanner\"``).\n        agent_mode: Execution mode (e.g. ``\"standard\"``, ``\"deep\"``).\n        allowed_models: Per-category model allowlists.\n        allowed_providers: Provider names the agent may use (e.g. ``[\"openai\"]``).\n        allowed_tools: MCP tools the agent may invoke, keyed by server name.\n    \"\"\"\n\n    run_id: str = \"\"\n    org_id: str = \"\"\n    repo_url: str = \"\"\n    agent_type: str = \"\"\n    agent_mode: str = \"\"\n    allowed_models: AllowedModels = field(default_factory=AllowedModels)\n    allowed_providers: list[str] = field(default_factory=list)\n    allowed_tools: dict[str, list[str]] = field(default_factory=dict)\n\n    @classmethod\n    def from_dict(cls, data: dict) -&gt; TransactionContext:\n        \"\"\"Create from a decoded JWT ``tctx`` claim dictionary.\"\"\"\n        allowed_models_data = data.get(\"allowed_models\", {})\n        return cls(\n            run_id=data.get(\"run_id\", \"\"),\n            org_id=data.get(\"org_id\", \"\"),\n            repo_url=data.get(\"repo_url\", \"\"),\n            agent_type=data.get(\"agent_type\", \"\"),\n            agent_mode=data.get(\"agent_mode\", \"\"),\n            allowed_models=AllowedModels.from_dict(allowed_models_data),\n            allowed_providers=data.get(\"allowed_providers\", []),\n            allowed_tools=data.get(\"allowed_tools\", {}),\n        )\n</code></pre>"},{"location":"api/auth/trat/#sage_sanctum.auth.trat.TransactionContext.from_dict","title":"<code>from_dict(data: dict) -&gt; TransactionContext</code>  <code>classmethod</code>","text":"<p>Create from a decoded JWT <code>tctx</code> claim dictionary.</p> Source code in <code>src/sage_sanctum/auth/trat.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict) -&gt; TransactionContext:\n    \"\"\"Create from a decoded JWT ``tctx`` claim dictionary.\"\"\"\n    allowed_models_data = data.get(\"allowed_models\", {})\n    return cls(\n        run_id=data.get(\"run_id\", \"\"),\n        org_id=data.get(\"org_id\", \"\"),\n        repo_url=data.get(\"repo_url\", \"\"),\n        agent_type=data.get(\"agent_type\", \"\"),\n        agent_mode=data.get(\"agent_mode\", \"\"),\n        allowed_models=AllowedModels.from_dict(allowed_models_data),\n        allowed_providers=data.get(\"allowed_providers\", []),\n        allowed_tools=data.get(\"allowed_tools\", {}),\n    )\n</code></pre>"},{"location":"api/auth/trat/#sage_sanctum.auth.trat.TransactionToken","title":"<code>TransactionToken</code>  <code>dataclass</code>","text":"<p>Parsed Transaction Token (TraT) with all claims.</p> <p>An IETF-standard JWT (<code>draft-ietf-oauth-transaction-tokens</code>) that authorizes a specific transaction within the Sage Sanctum platform.</p> <p>Attributes:</p> Name Type Description <code>raw</code> <code>str</code> <p>The original JWT string (for forwarding to the gateway).</p> <code>txn</code> <code>str</code> <p>Transaction ID \u2014 unique identifier for this token.</p> <code>sub</code> <code>str</code> <p>Subject \u2014 the agent's SPIFFE ID.</p> <code>scope</code> <code>str</code> <p>Space-separated OAuth scopes (e.g. <code>\"scan.execute scan.upload\"</code>).</p> <code>req_wl</code> <code>str</code> <p>Request allowlist \u2014 SPIFFE ID of the requester.</p> <code>iat</code> <code>float</code> <p>Issued-at timestamp (Unix epoch seconds).</p> <code>exp</code> <code>float</code> <p>Expiration timestamp (Unix epoch seconds).</p> <code>aud</code> <code>str</code> <p>Audience claim.</p> <code>iss</code> <code>str</code> <p>Issuer claim.</p> <code>tctx</code> <code>TransactionContext</code> <p>Transaction context with run parameters and model allowlists.</p> <code>rctx</code> <code>RequesterContext</code> <p>Requester context with audit metadata.</p> Source code in <code>src/sage_sanctum/auth/trat.py</code> <pre><code>@dataclass(frozen=True)\nclass TransactionToken:\n    \"\"\"Parsed Transaction Token (TraT) with all claims.\n\n    An IETF-standard JWT (``draft-ietf-oauth-transaction-tokens``) that\n    authorizes a specific transaction within the Sage Sanctum platform.\n\n    Attributes:\n        raw: The original JWT string (for forwarding to the gateway).\n        txn: Transaction ID \u2014 unique identifier for this token.\n        sub: Subject \u2014 the agent's SPIFFE ID.\n        scope: Space-separated OAuth scopes (e.g. ``\"scan.execute scan.upload\"``).\n        req_wl: Request allowlist \u2014 SPIFFE ID of the requester.\n        iat: Issued-at timestamp (Unix epoch seconds).\n        exp: Expiration timestamp (Unix epoch seconds).\n        aud: Audience claim.\n        iss: Issuer claim.\n        tctx: Transaction context with run parameters and model allowlists.\n        rctx: Requester context with audit metadata.\n    \"\"\"\n\n    raw: str\n    txn: str\n    sub: str\n    scope: str\n    req_wl: str\n    iat: float\n    exp: float\n    aud: str = \"\"\n    iss: str = \"\"\n    tctx: TransactionContext = field(default_factory=TransactionContext)\n    rctx: RequesterContext = field(default_factory=RequesterContext)\n\n    @classmethod\n    def from_jwt(cls, token: str) -&gt; TransactionToken:\n        \"\"\"Parse a TraT JWT (without signature verification).\n\n        Signature verification is done by the gateway, not the agent.\n\n        Raises:\n            TraTAcquisitionError: If the token is malformed or missing required claims.\n        \"\"\"\n        try:\n            payload = _decode_jwt_payload(token)\n        except Exception as e:\n            raise TraTAcquisitionError(f\"Failed to parse TraT: {e}\") from e\n\n        # Required claims\n        txn = payload.get(\"txn\", \"\")\n        if not txn:\n            raise TraTAcquisitionError(\"TraT missing required 'txn' claim\")\n\n        return cls(\n            raw=token,\n            txn=txn,\n            sub=payload.get(\"sub\", \"\"),\n            scope=payload.get(\"scope\", \"\"),\n            req_wl=payload.get(\"req_wl\", \"\"),\n            iat=float(payload.get(\"iat\", 0)),\n            exp=float(payload.get(\"exp\", 0)),\n            aud=payload.get(\"aud\", \"\"),\n            iss=payload.get(\"iss\", \"\"),\n            tctx=TransactionContext.from_dict(payload.get(\"tctx\", {})),\n            rctx=RequesterContext.from_dict(payload.get(\"rctx\", {})),\n        )\n\n    @property\n    def is_expired(self) -&gt; bool:\n        \"\"\"Whether the token's ``exp`` claim is in the past.\"\"\"\n        return time.time() &gt;= self.exp\n\n    def check_not_expired(self) -&gt; None:\n        \"\"\"Raise if token is expired.\n\n        Raises:\n            TraTExpiredError: If the token has expired.\n        \"\"\"\n        if self.is_expired:\n            raise TraTExpiredError(\n                f\"Transaction Token expired at {self.exp} \"\n                f\"(current time: {time.time():.0f})\"\n            )\n</code></pre>"},{"location":"api/auth/trat/#sage_sanctum.auth.trat.TransactionToken.is_expired","title":"<code>is_expired: bool</code>  <code>property</code>","text":"<p>Whether the token's <code>exp</code> claim is in the past.</p>"},{"location":"api/auth/trat/#sage_sanctum.auth.trat.TransactionToken.from_jwt","title":"<code>from_jwt(token: str) -&gt; TransactionToken</code>  <code>classmethod</code>","text":"<p>Parse a TraT JWT (without signature verification).</p> <p>Signature verification is done by the gateway, not the agent.</p> <p>Raises:</p> Type Description <code>TraTAcquisitionError</code> <p>If the token is malformed or missing required claims.</p> Source code in <code>src/sage_sanctum/auth/trat.py</code> <pre><code>@classmethod\ndef from_jwt(cls, token: str) -&gt; TransactionToken:\n    \"\"\"Parse a TraT JWT (without signature verification).\n\n    Signature verification is done by the gateway, not the agent.\n\n    Raises:\n        TraTAcquisitionError: If the token is malformed or missing required claims.\n    \"\"\"\n    try:\n        payload = _decode_jwt_payload(token)\n    except Exception as e:\n        raise TraTAcquisitionError(f\"Failed to parse TraT: {e}\") from e\n\n    # Required claims\n    txn = payload.get(\"txn\", \"\")\n    if not txn:\n        raise TraTAcquisitionError(\"TraT missing required 'txn' claim\")\n\n    return cls(\n        raw=token,\n        txn=txn,\n        sub=payload.get(\"sub\", \"\"),\n        scope=payload.get(\"scope\", \"\"),\n        req_wl=payload.get(\"req_wl\", \"\"),\n        iat=float(payload.get(\"iat\", 0)),\n        exp=float(payload.get(\"exp\", 0)),\n        aud=payload.get(\"aud\", \"\"),\n        iss=payload.get(\"iss\", \"\"),\n        tctx=TransactionContext.from_dict(payload.get(\"tctx\", {})),\n        rctx=RequesterContext.from_dict(payload.get(\"rctx\", {})),\n    )\n</code></pre>"},{"location":"api/auth/trat/#sage_sanctum.auth.trat.TransactionToken.check_not_expired","title":"<code>check_not_expired() -&gt; None</code>","text":"<p>Raise if token is expired.</p> <p>Raises:</p> Type Description <code>TraTExpiredError</code> <p>If the token has expired.</p> Source code in <code>src/sage_sanctum/auth/trat.py</code> <pre><code>def check_not_expired(self) -&gt; None:\n    \"\"\"Raise if token is expired.\n\n    Raises:\n        TraTExpiredError: If the token has expired.\n    \"\"\"\n    if self.is_expired:\n        raise TraTExpiredError(\n            f\"Transaction Token expired at {self.exp} \"\n            f\"(current time: {time.time():.0f})\"\n        )\n</code></pre>"},{"location":"api/auth/trat/#sage_sanctum.auth.trat.TransactionTokenClient","title":"<code>TransactionTokenClient</code>","text":"<p>Reads TraTs from file or auth sidecar socket.</p> <p>In production, the auth sidecar acquires and refreshes TraTs. The agent reads them from a well-known file path or queries the sidecar socket.</p> Source code in <code>src/sage_sanctum/auth/trat.py</code> <pre><code>class TransactionTokenClient:\n    \"\"\"Reads TraTs from file or auth sidecar socket.\n\n    In production, the auth sidecar acquires and refreshes TraTs. The agent\n    reads them from a well-known file path or queries the sidecar socket.\n    \"\"\"\n\n    def __init__(\n        self,\n        trat_file: str | Path | None = None,\n        sidecar_socket: str | Path | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize the TraT client.\n\n        Args:\n            trat_file: Filesystem path to a file containing a TraT JWT.\n                Tried first when both sources are configured.\n            sidecar_socket: Unix socket path for the auth sidecar's\n                ``GET /trat`` endpoint. Used as fallback.\n        \"\"\"\n        self._trat_file = Path(trat_file) if trat_file else None\n        self._sidecar_socket = Path(sidecar_socket) if sidecar_socket else None\n        self._cached: TransactionToken | None = None\n\n    def get_token(self) -&gt; TransactionToken:\n        \"\"\"Get the current Transaction Token.\n\n        Returns the cached token if it has not expired. Otherwise, acquires\n        a fresh token (file first, then sidecar socket).\n\n        Returns:\n            A valid, non-expired ``TransactionToken``.\n\n        Raises:\n            TraTAcquisitionError: If the TraT cannot be acquired from any source.\n            TraTExpiredError: If the acquired TraT is already expired.\n        \"\"\"\n        # Return cached if still valid\n        if self._cached and not self._cached.is_expired:\n            return self._cached\n\n        token = self._acquire()\n        token.check_not_expired()\n        self._cached = token\n        return token\n\n    def _acquire(self) -&gt; TransactionToken:\n        \"\"\"Acquire TraT from file (preferred) with sidecar fallback.\n\n        When both sources are configured, tries the file first. If the\n        file-based token is expired, falls back to the sidecar which can\n        fetch a fresh token from the orchestrator TTS.\n        \"\"\"\n        # Try file first\n        if self._trat_file:\n            token = self._read_from_file()\n            if not token.is_expired:\n                return token\n            # File token expired \u2014 try sidecar as fallback\n            if self._sidecar_socket:\n                logger.info(\"trat_expired_fallback\", exp=token.exp)\n                return self._read_from_sidecar()\n            # No sidecar available \u2014 return expired token so caller gets\n            # a clear TraTExpiredError from check_not_expired()\n            return token\n\n        # Try sidecar socket\n        if self._sidecar_socket:\n            return self._read_from_sidecar()\n\n        raise TraTAcquisitionError(\n            \"No TraT source configured. Set TRAT_FILE or AUTH_SIDECAR_SOCKET.\"\n        )\n\n    def _read_from_file(self) -&gt; TransactionToken:\n        \"\"\"Read TraT JWT from file.\"\"\"\n        if not self._trat_file or not self._trat_file.exists():\n            raise TraTAcquisitionError(\n                f\"TraT file not found: {self._trat_file}\"\n            )\n\n        try:\n            raw = self._trat_file.read_text().strip()\n        except OSError as e:\n            raise TraTAcquisitionError(\n                f\"Failed to read TraT from {self._trat_file}: {e}\"\n            ) from e\n\n        if not raw:\n            raise TraTAcquisitionError(f\"TraT file is empty: {self._trat_file}\")\n\n        return TransactionToken.from_jwt(raw)\n\n    def _read_from_sidecar(self) -&gt; TransactionToken:\n        \"\"\"Read TraT from auth sidecar socket.\n\n        The auth sidecar exposes a simple HTTP API over a Unix socket:\n        GET /trat -&gt; JWT string\n        \"\"\"\n        if not self._sidecar_socket or not self._sidecar_socket.exists():\n            raise TraTAcquisitionError(\n                f\"Auth sidecar socket not found: {self._sidecar_socket}\"\n            )\n\n        from ..gateway.http import GatewayHttpClient\n\n        client = GatewayHttpClient(socket_path=self._sidecar_socket)\n        try:\n            response = client.request(\"GET\", \"/trat\")\n            if response.status != 200:\n                raise TraTAcquisitionError(\n                    f\"Auth sidecar returned status {response.status}: {response.data}\"\n                )\n            raw = response.data.strip()\n            return TransactionToken.from_jwt(raw)\n        except TraTAcquisitionError:\n            raise\n        except Exception as e:\n            raise TraTAcquisitionError(\n                f\"Failed to read TraT from sidecar: {e}\"\n            ) from e\n\n    def invalidate(self) -&gt; None:\n        \"\"\"Clear cached token.\"\"\"\n        self._cached = None\n</code></pre>"},{"location":"api/auth/trat/#sage_sanctum.auth.trat.TransactionTokenClient.__init__","title":"<code>__init__(trat_file: str | Path | None = None, sidecar_socket: str | Path | None = None) -&gt; None</code>","text":"<p>Initialize the TraT client.</p> <p>Parameters:</p> Name Type Description Default <code>trat_file</code> <code>str | Path | None</code> <p>Filesystem path to a file containing a TraT JWT. Tried first when both sources are configured.</p> <code>None</code> <code>sidecar_socket</code> <code>str | Path | None</code> <p>Unix socket path for the auth sidecar's <code>GET /trat</code> endpoint. Used as fallback.</p> <code>None</code> Source code in <code>src/sage_sanctum/auth/trat.py</code> <pre><code>def __init__(\n    self,\n    trat_file: str | Path | None = None,\n    sidecar_socket: str | Path | None = None,\n) -&gt; None:\n    \"\"\"Initialize the TraT client.\n\n    Args:\n        trat_file: Filesystem path to a file containing a TraT JWT.\n            Tried first when both sources are configured.\n        sidecar_socket: Unix socket path for the auth sidecar's\n            ``GET /trat`` endpoint. Used as fallback.\n    \"\"\"\n    self._trat_file = Path(trat_file) if trat_file else None\n    self._sidecar_socket = Path(sidecar_socket) if sidecar_socket else None\n    self._cached: TransactionToken | None = None\n</code></pre>"},{"location":"api/auth/trat/#sage_sanctum.auth.trat.TransactionTokenClient.get_token","title":"<code>get_token() -&gt; TransactionToken</code>","text":"<p>Get the current Transaction Token.</p> <p>Returns the cached token if it has not expired. Otherwise, acquires a fresh token (file first, then sidecar socket).</p> <p>Returns:</p> Type Description <code>TransactionToken</code> <p>A valid, non-expired <code>TransactionToken</code>.</p> <p>Raises:</p> Type Description <code>TraTAcquisitionError</code> <p>If the TraT cannot be acquired from any source.</p> <code>TraTExpiredError</code> <p>If the acquired TraT is already expired.</p> Source code in <code>src/sage_sanctum/auth/trat.py</code> <pre><code>def get_token(self) -&gt; TransactionToken:\n    \"\"\"Get the current Transaction Token.\n\n    Returns the cached token if it has not expired. Otherwise, acquires\n    a fresh token (file first, then sidecar socket).\n\n    Returns:\n        A valid, non-expired ``TransactionToken``.\n\n    Raises:\n        TraTAcquisitionError: If the TraT cannot be acquired from any source.\n        TraTExpiredError: If the acquired TraT is already expired.\n    \"\"\"\n    # Return cached if still valid\n    if self._cached and not self._cached.is_expired:\n        return self._cached\n\n    token = self._acquire()\n    token.check_not_expired()\n    self._cached = token\n    return token\n</code></pre>"},{"location":"api/auth/trat/#sage_sanctum.auth.trat.TransactionTokenClient.invalidate","title":"<code>invalidate() -&gt; None</code>","text":"<p>Clear cached token.</p> Source code in <code>src/sage_sanctum/auth/trat.py</code> <pre><code>def invalidate(self) -&gt; None:\n    \"\"\"Clear cached token.\"\"\"\n    self._cached = None\n</code></pre>"},{"location":"api/gateway/","title":"sage_sanctum.gateway","text":"<p>LLM gateway client implementations and HTTP transport.</p>"},{"location":"api/gateway/#modules","title":"Modules","text":"Module Description <code>client</code> Gateway client abstract base and implementations <code>http</code> HTTP client for Unix socket and TCP communication"},{"location":"api/gateway/client/","title":"sage_sanctum.gateway.client","text":"<p>Gateway client abstract base class with <code>SpiffeGatewayClient</code> (production) and <code>DirectProviderClient</code> (local development) implementations.</p>"},{"location":"api/gateway/client/#sage_sanctum.gateway.client","title":"<code>sage_sanctum.gateway.client</code>","text":"<p>Gateway client implementations for LLM access.</p> <p>Two modes: - SpiffeGatewayClient: Production client using SPIFFE + TraT via Unix sockets - DirectProviderClient: Local dev client using direct API keys</p>"},{"location":"api/gateway/client/#sage_sanctum.gateway.client.GatewayClient","title":"<code>GatewayClient</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for accessing LLM providers via the gateway.</p> <p>Two concrete implementations:</p> <ul> <li><code>SpiffeGatewayClient</code> \u2014 production, routes through Unix socket with   SPIFFE + TraT authentication.</li> <li><code>DirectProviderClient</code> \u2014 local development, calls providers directly   with API keys.</li> </ul> Source code in <code>src/sage_sanctum/gateway/client.py</code> <pre><code>class GatewayClient(ABC):\n    \"\"\"Abstract base class for accessing LLM providers via the gateway.\n\n    Two concrete implementations:\n\n    - ``SpiffeGatewayClient`` \u2014 production, routes through Unix socket with\n      SPIFFE + TraT authentication.\n    - ``DirectProviderClient`` \u2014 local development, calls providers directly\n      with API keys.\n    \"\"\"\n\n    @abstractmethod\n    def get_credentials(self) -&gt; GatewayCredentials:\n        \"\"\"Get current gateway credentials.\n\n        Raises:\n            AuthError: If credentials cannot be acquired.\n        \"\"\"\n\n    @abstractmethod\n    def get_endpoint(self, provider: str) -&gt; str:\n        \"\"\"Get the gateway endpoint URL for a specific provider.\n\n        Args:\n            provider: Provider name (e.g., 'openai', 'anthropic', 'google')\n\n        Returns:\n            Base URL for the provider endpoint.\n        \"\"\"\n\n    @property\n    @abstractmethod\n    def is_gateway_mode(self) -&gt; bool:\n        \"\"\"Whether this client routes through the gateway.\"\"\"\n\n    def get_trat(self) -&gt; TransactionToken | None:\n        \"\"\"Get the current Transaction Token, if available.\"\"\"\n        return None\n</code></pre>"},{"location":"api/gateway/client/#sage_sanctum.gateway.client.GatewayClient.is_gateway_mode","title":"<code>is_gateway_mode: bool</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Whether this client routes through the gateway.</p>"},{"location":"api/gateway/client/#sage_sanctum.gateway.client.GatewayClient.get_credentials","title":"<code>get_credentials() -&gt; GatewayCredentials</code>  <code>abstractmethod</code>","text":"<p>Get current gateway credentials.</p> <p>Raises:</p> Type Description <code>AuthError</code> <p>If credentials cannot be acquired.</p> Source code in <code>src/sage_sanctum/gateway/client.py</code> <pre><code>@abstractmethod\ndef get_credentials(self) -&gt; GatewayCredentials:\n    \"\"\"Get current gateway credentials.\n\n    Raises:\n        AuthError: If credentials cannot be acquired.\n    \"\"\"\n</code></pre>"},{"location":"api/gateway/client/#sage_sanctum.gateway.client.GatewayClient.get_endpoint","title":"<code>get_endpoint(provider: str) -&gt; str</code>  <code>abstractmethod</code>","text":"<p>Get the gateway endpoint URL for a specific provider.</p> <p>Parameters:</p> Name Type Description Default <code>provider</code> <code>str</code> <p>Provider name (e.g., 'openai', 'anthropic', 'google')</p> required <p>Returns:</p> Type Description <code>str</code> <p>Base URL for the provider endpoint.</p> Source code in <code>src/sage_sanctum/gateway/client.py</code> <pre><code>@abstractmethod\ndef get_endpoint(self, provider: str) -&gt; str:\n    \"\"\"Get the gateway endpoint URL for a specific provider.\n\n    Args:\n        provider: Provider name (e.g., 'openai', 'anthropic', 'google')\n\n    Returns:\n        Base URL for the provider endpoint.\n    \"\"\"\n</code></pre>"},{"location":"api/gateway/client/#sage_sanctum.gateway.client.GatewayClient.get_trat","title":"<code>get_trat() -&gt; TransactionToken | None</code>","text":"<p>Get the current Transaction Token, if available.</p> Source code in <code>src/sage_sanctum/gateway/client.py</code> <pre><code>def get_trat(self) -&gt; TransactionToken | None:\n    \"\"\"Get the current Transaction Token, if available.\"\"\"\n    return None\n</code></pre>"},{"location":"api/gateway/client/#sage_sanctum.gateway.client.SpiffeGatewayClient","title":"<code>SpiffeGatewayClient</code>","text":"<p>               Bases: <code>GatewayClient</code></p> <p>Production gateway client using SPIFFE identity and Transaction Tokens.</p> <p>Connects to the LLM gateway via Unix socket with SPIFFE JWT + TraT auth.</p> Source code in <code>src/sage_sanctum/gateway/client.py</code> <pre><code>class SpiffeGatewayClient(GatewayClient):\n    \"\"\"Production gateway client using SPIFFE identity and Transaction Tokens.\n\n    Connects to the LLM gateway via Unix socket with SPIFFE JWT + TraT auth.\n    \"\"\"\n\n    def __init__(\n        self,\n        jwt_source: JWTSource,\n        trat_client: TransactionTokenClient,\n        gateway_socket: str | Path | None = None,\n    ) -&gt; None:\n        \"\"\"Initialize the production gateway client.\n\n        Args:\n            jwt_source: SPIFFE JWT source for agent identity.\n            trat_client: Transaction Token client for authorization.\n            gateway_socket: Unix socket path to the LLM gateway.\n                Falls back to environment-based endpoints if not set.\n        \"\"\"\n        self._jwt_source = jwt_source\n        self._trat_client = trat_client\n        self._gateway_socket = Path(gateway_socket) if gateway_socket else None\n\n    def get_credentials(self) -&gt; GatewayCredentials:\n        \"\"\"Fetch fresh SPIFFE JWT and TraT, bundled as gateway credentials.\"\"\"\n        jwt = self._jwt_source.get_token()\n        trat = self._trat_client.get_token()\n        return GatewayCredentials(spiffe_jwt=jwt, trat=trat.raw)\n\n    def get_endpoint(self, provider: str) -&gt; str:\n        \"\"\"Return the Unix socket-based endpoint.\n\n        In gateway mode, all providers are accessed through the same socket.\n        The provider is specified via X-Provider header.\n        \"\"\"\n        if self._gateway_socket:\n            # For Unix socket, we return a special URL that the HTTP client understands\n            return f\"unix://{self._gateway_socket}\"\n        # Fallback to env-var based endpoints\n        endpoints = {\n            \"openai\": os.environ.get(\"OPENAI_BASE_URL\", \"http://gateway:8080/v1\"),\n            \"anthropic\": os.environ.get(\"ANTHROPIC_BASE_URL\", \"http://gateway:8080/anthropic\"),\n            \"google\": os.environ.get(\"GOOGLE_BASE_URL\", \"http://gateway:8080/google\"),\n        }\n        return endpoints.get(provider, endpoints[\"openai\"])\n\n    @property\n    def is_gateway_mode(self) -&gt; bool:\n        return True\n\n    def get_trat(self) -&gt; TransactionToken | None:\n        try:\n            return self._trat_client.get_token()\n        except Exception:\n            return None\n</code></pre>"},{"location":"api/gateway/client/#sage_sanctum.gateway.client.SpiffeGatewayClient.__init__","title":"<code>__init__(jwt_source: JWTSource, trat_client: TransactionTokenClient, gateway_socket: str | Path | None = None) -&gt; None</code>","text":"<p>Initialize the production gateway client.</p> <p>Parameters:</p> Name Type Description Default <code>jwt_source</code> <code>JWTSource</code> <p>SPIFFE JWT source for agent identity.</p> required <code>trat_client</code> <code>TransactionTokenClient</code> <p>Transaction Token client for authorization.</p> required <code>gateway_socket</code> <code>str | Path | None</code> <p>Unix socket path to the LLM gateway. Falls back to environment-based endpoints if not set.</p> <code>None</code> Source code in <code>src/sage_sanctum/gateway/client.py</code> <pre><code>def __init__(\n    self,\n    jwt_source: JWTSource,\n    trat_client: TransactionTokenClient,\n    gateway_socket: str | Path | None = None,\n) -&gt; None:\n    \"\"\"Initialize the production gateway client.\n\n    Args:\n        jwt_source: SPIFFE JWT source for agent identity.\n        trat_client: Transaction Token client for authorization.\n        gateway_socket: Unix socket path to the LLM gateway.\n            Falls back to environment-based endpoints if not set.\n    \"\"\"\n    self._jwt_source = jwt_source\n    self._trat_client = trat_client\n    self._gateway_socket = Path(gateway_socket) if gateway_socket else None\n</code></pre>"},{"location":"api/gateway/client/#sage_sanctum.gateway.client.SpiffeGatewayClient.get_credentials","title":"<code>get_credentials() -&gt; GatewayCredentials</code>","text":"<p>Fetch fresh SPIFFE JWT and TraT, bundled as gateway credentials.</p> Source code in <code>src/sage_sanctum/gateway/client.py</code> <pre><code>def get_credentials(self) -&gt; GatewayCredentials:\n    \"\"\"Fetch fresh SPIFFE JWT and TraT, bundled as gateway credentials.\"\"\"\n    jwt = self._jwt_source.get_token()\n    trat = self._trat_client.get_token()\n    return GatewayCredentials(spiffe_jwt=jwt, trat=trat.raw)\n</code></pre>"},{"location":"api/gateway/client/#sage_sanctum.gateway.client.SpiffeGatewayClient.get_endpoint","title":"<code>get_endpoint(provider: str) -&gt; str</code>","text":"<p>Return the Unix socket-based endpoint.</p> <p>In gateway mode, all providers are accessed through the same socket. The provider is specified via X-Provider header.</p> Source code in <code>src/sage_sanctum/gateway/client.py</code> <pre><code>def get_endpoint(self, provider: str) -&gt; str:\n    \"\"\"Return the Unix socket-based endpoint.\n\n    In gateway mode, all providers are accessed through the same socket.\n    The provider is specified via X-Provider header.\n    \"\"\"\n    if self._gateway_socket:\n        # For Unix socket, we return a special URL that the HTTP client understands\n        return f\"unix://{self._gateway_socket}\"\n    # Fallback to env-var based endpoints\n    endpoints = {\n        \"openai\": os.environ.get(\"OPENAI_BASE_URL\", \"http://gateway:8080/v1\"),\n        \"anthropic\": os.environ.get(\"ANTHROPIC_BASE_URL\", \"http://gateway:8080/anthropic\"),\n        \"google\": os.environ.get(\"GOOGLE_BASE_URL\", \"http://gateway:8080/google\"),\n    }\n    return endpoints.get(provider, endpoints[\"openai\"])\n</code></pre>"},{"location":"api/gateway/client/#sage_sanctum.gateway.client.DirectProviderClient","title":"<code>DirectProviderClient</code>","text":"<p>               Bases: <code>GatewayClient</code></p> <p>Local development client using direct API keys.</p> <p>Requires SAGE_SANCTUM_ALLOW_DIRECT=1 for safety. Reads API keys from environment variables.</p> Source code in <code>src/sage_sanctum/gateway/client.py</code> <pre><code>class DirectProviderClient(GatewayClient):\n    \"\"\"Local development client using direct API keys.\n\n    Requires SAGE_SANCTUM_ALLOW_DIRECT=1 for safety.\n    Reads API keys from environment variables.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        if not os.environ.get(\"SAGE_SANCTUM_ALLOW_DIRECT\"):\n            raise ConfigurationError(\n                \"DirectProviderClient requires SAGE_SANCTUM_ALLOW_DIRECT=1. \"\n                \"This bypasses gateway security and should only be used for local development.\"\n            )\n\n    def get_credentials(self) -&gt; GatewayCredentials:\n        # In direct mode, we use API keys directly \u2014 no SPIFFE/TraT\n        return GatewayCredentials(spiffe_jwt=\"\", trat=\"\")\n\n    def get_endpoint(self, provider: str) -&gt; str:\n        \"\"\"Return the provider's native API endpoint.\"\"\"\n        endpoints = {\n            \"openai\": os.environ.get(\"OPENAI_BASE_URL\", \"https://api.openai.com/v1\"),\n            \"anthropic\": os.environ.get(\n                \"ANTHROPIC_BASE_URL\", \"https://api.anthropic.com\"\n            ),\n            \"google\": os.environ.get(\n                \"GOOGLE_BASE_URL\", \"https://generativelanguage.googleapis.com\"\n            ),\n        }\n        return endpoints.get(provider, endpoints[\"openai\"])\n\n    @property\n    def is_gateway_mode(self) -&gt; bool:\n        return False\n\n    def get_api_key(self, provider: str) -&gt; str:\n        \"\"\"Get the API key for a provider from environment.\n\n        Raises:\n            ConfigurationError: If the API key is not set.\n        \"\"\"\n        env_vars = {\n            \"openai\": \"OPENAI_API_KEY\",\n            \"anthropic\": \"ANTHROPIC_API_KEY\",\n            \"google\": \"GOOGLE_API_KEY\",\n        }\n        var_name = env_vars.get(provider, \"OPENAI_API_KEY\")\n        key = os.environ.get(var_name)\n        if not key:\n            raise ConfigurationError(\n                f\"API key not set for {provider}. Set {var_name} environment variable.\"\n            )\n        return key\n</code></pre>"},{"location":"api/gateway/client/#sage_sanctum.gateway.client.DirectProviderClient.get_endpoint","title":"<code>get_endpoint(provider: str) -&gt; str</code>","text":"<p>Return the provider's native API endpoint.</p> Source code in <code>src/sage_sanctum/gateway/client.py</code> <pre><code>def get_endpoint(self, provider: str) -&gt; str:\n    \"\"\"Return the provider's native API endpoint.\"\"\"\n    endpoints = {\n        \"openai\": os.environ.get(\"OPENAI_BASE_URL\", \"https://api.openai.com/v1\"),\n        \"anthropic\": os.environ.get(\n            \"ANTHROPIC_BASE_URL\", \"https://api.anthropic.com\"\n        ),\n        \"google\": os.environ.get(\n            \"GOOGLE_BASE_URL\", \"https://generativelanguage.googleapis.com\"\n        ),\n    }\n    return endpoints.get(provider, endpoints[\"openai\"])\n</code></pre>"},{"location":"api/gateway/client/#sage_sanctum.gateway.client.DirectProviderClient.get_api_key","title":"<code>get_api_key(provider: str) -&gt; str</code>","text":"<p>Get the API key for a provider from environment.</p> <p>Raises:</p> Type Description <code>ConfigurationError</code> <p>If the API key is not set.</p> Source code in <code>src/sage_sanctum/gateway/client.py</code> <pre><code>def get_api_key(self, provider: str) -&gt; str:\n    \"\"\"Get the API key for a provider from environment.\n\n    Raises:\n        ConfigurationError: If the API key is not set.\n    \"\"\"\n    env_vars = {\n        \"openai\": \"OPENAI_API_KEY\",\n        \"anthropic\": \"ANTHROPIC_API_KEY\",\n        \"google\": \"GOOGLE_API_KEY\",\n    }\n    var_name = env_vars.get(provider, \"OPENAI_API_KEY\")\n    key = os.environ.get(var_name)\n    if not key:\n        raise ConfigurationError(\n            f\"API key not set for {provider}. Set {var_name} environment variable.\"\n        )\n    return key\n</code></pre>"},{"location":"api/gateway/http/","title":"sage_sanctum.gateway.http","text":"<p>Low-level HTTP client for gateway communication over Unix socket or TCP.</p>"},{"location":"api/gateway/http/#sage_sanctum.gateway.http","title":"<code>sage_sanctum.gateway.http</code>","text":"<p>HTTP client with Unix socket and TCP support for gateway communication.</p>"},{"location":"api/gateway/http/#sage_sanctum.gateway.http.HttpResponse","title":"<code>HttpResponse</code>  <code>dataclass</code>","text":"<p>Simple HTTP response container.</p> <p>Attributes:</p> Name Type Description <code>status</code> <code>int</code> <p>HTTP status code (e.g. <code>200</code>, <code>429</code>, <code>502</code>).</p> <code>headers</code> <code>dict[str, str]</code> <p>Response headers (keys are lower-cased).</p> <code>data</code> <code>str</code> <p>Response body as a decoded string.</p> Source code in <code>src/sage_sanctum/gateway/http.py</code> <pre><code>@dataclass\nclass HttpResponse:\n    \"\"\"Simple HTTP response container.\n\n    Attributes:\n        status: HTTP status code (e.g. ``200``, ``429``, ``502``).\n        headers: Response headers (keys are lower-cased).\n        data: Response body as a decoded string.\n    \"\"\"\n\n    status: int\n    headers: dict[str, str]\n    data: str\n</code></pre>"},{"location":"api/gateway/http/#sage_sanctum.gateway.http.GatewayHttpClient","title":"<code>GatewayHttpClient</code>","text":"<p>HTTP client for gateway communication over Unix socket or TCP.</p> <p>In production, agents communicate with gateways via Unix sockets (AF_UNIX) because AF_INET is blocked by seccomp. For local development, TCP connections are also supported.</p> Source code in <code>src/sage_sanctum/gateway/http.py</code> <pre><code>class GatewayHttpClient:\n    \"\"\"HTTP client for gateway communication over Unix socket or TCP.\n\n    In production, agents communicate with gateways via Unix sockets\n    (AF_UNIX) because AF_INET is blocked by seccomp. For local development,\n    TCP connections are also supported.\n    \"\"\"\n\n    def __init__(\n        self,\n        socket_path: str | Path | None = None,\n        host: str | None = None,\n        port: int | None = None,\n        timeout: float = _DEFAULT_TIMEOUT,\n        max_retries: int = 3,\n        retry_backoff: float = 0.5,\n    ) -&gt; None:\n        \"\"\"Initialize the HTTP client.\n\n        Exactly one of ``socket_path`` or ``host`` must be provided.\n\n        Args:\n            socket_path: Path to a Unix domain socket (``AF_UNIX``).\n            host: TCP hostname for ``AF_INET`` connections.\n            port: TCP port number (required when ``host`` is set).\n            timeout: Socket timeout in seconds. Defaults to 120.\n            max_retries: Maximum number of retries on transient errors. Defaults to 3.\n            retry_backoff: Base backoff interval in seconds. Defaults to 0.5.\n\n        Raises:\n            GatewayError: If neither ``socket_path`` nor ``host`` is provided.\n        \"\"\"\n        self._socket_path = Path(socket_path) if socket_path else None\n        self._host = host\n        self._port = port\n        self._timeout = timeout\n        self._max_retries = max_retries\n        self._retry_backoff = retry_backoff\n\n        if not self._socket_path and not self._host:\n            raise GatewayError(\"Either socket_path or host must be provided\")\n\n    @property\n    def is_unix_socket(self) -&gt; bool:\n        \"\"\"Whether this client connects via Unix domain socket.\"\"\"\n        return self._socket_path is not None\n\n    def request(\n        self,\n        method: str,\n        path: str,\n        headers: dict[str, str] | None = None,\n        body: str | dict | None = None,\n    ) -&gt; HttpResponse:\n        \"\"\"Send an HTTP request to the gateway with automatic retries.\n\n        Retries on connection errors, timeouts, and status codes 429, 502, 503, 504.\n        Respects ``Retry-After`` header on 429 responses.\n\n        Args:\n            method: HTTP method (GET, POST, etc.)\n            path: Request path (e.g., '/v1/chat/completions')\n            headers: Additional HTTP headers\n            body: Request body (str or dict to be JSON-encoded)\n\n        Returns:\n            HttpResponse with status, headers, and body data.\n\n        Raises:\n            RateLimitError: On 429 after all retries exhausted.\n            GatewayUnavailableError: If the gateway is unreachable after retries.\n            GatewayError: On other communication errors.\n        \"\"\"\n        all_headers = {\"Host\": \"gateway.local\"}\n        if headers:\n            all_headers.update(headers)\n\n        body_bytes = b\"\"\n        if body is not None:\n            if isinstance(body, dict):\n                body_bytes = json.dumps(body).encode(\"utf-8\")\n                all_headers[\"Content-Type\"] = \"application/json\"\n            else:\n                body_bytes = body.encode(\"utf-8\")\n            all_headers[\"Content-Length\"] = str(len(body_bytes))\n\n        # Build raw HTTP request\n        request_line = f\"{method} {path} HTTP/1.1\\r\\n\"\n        header_lines = \"\".join(f\"{k}: {v}\\r\\n\" for k, v in all_headers.items())\n        raw_request = (request_line + header_lines + \"\\r\\n\").encode(\"utf-8\") + body_bytes\n\n        last_exc: Exception | None = None\n        for attempt in range(self._max_retries + 1):\n            try:\n                raw_response = self._send_raw(raw_request)\n                response = self._parse_response(raw_response)\n\n                # Check for retryable status codes\n                if response.status in _RETRYABLE_STATUS_CODES:\n                    if attempt &lt; self._max_retries:\n                        delay = self._retry_delay(attempt, response)\n                        logger.warning(\n                            \"gateway_retry\",\n                            status=response.status,\n                            delay=delay,\n                            attempt=attempt + 1,\n                            max_retries=self._max_retries,\n                        )\n                        time.sleep(delay)\n                        continue\n\n                    # Final attempt \u2014 raise appropriate error\n                    if response.status == 429:\n                        raise RateLimitError(\n                            f\"Rate limited (429) after {self._max_retries} retries: \"\n                            f\"{response.data}\"\n                        )\n\n                return response\n            except (RateLimitError, GatewayError, GatewayUnavailableError) as e:\n                if isinstance(e, RateLimitError):\n                    raise\n                last_exc = e\n                if attempt &lt; self._max_retries:\n                    delay = self._retry_delay(attempt)\n                    logger.warning(\n                        \"gateway_connection_retry\",\n                        error=str(e),\n                        delay=delay,\n                        attempt=attempt + 1,\n                        max_retries=self._max_retries,\n                    )\n                    time.sleep(delay)\n                    continue\n                raise\n            except Exception as e:\n                raise GatewayError(f\"Gateway request failed: {e}\") from e\n\n        # Should not reach here, but satisfy type checker\n        if last_exc:\n            raise last_exc\n        raise GatewayError(\"Gateway request failed after retries\")  # pragma: no cover\n\n    def _retry_delay(self, attempt: int, response: HttpResponse | None = None) -&gt; float:\n        \"\"\"Calculate retry delay with exponential backoff and jitter.\n\n        Respects ``Retry-After`` header from 429 responses.\n        \"\"\"\n        if response and response.status == 429:\n            retry_after = response.headers.get(\"retry-after\", \"\")\n            if retry_after:\n                try:\n                    return float(retry_after)\n                except ValueError:\n                    pass\n        return self._retry_backoff * (2 ** attempt) + random.random() * self._retry_backoff\n\n    def request_stream(\n        self,\n        method: str,\n        path: str,\n        headers: dict[str, str] | None = None,\n        body: str | dict | None = None,\n    ) -&gt; Iterator[bytes]:\n        \"\"\"Send an HTTP request and yield response lines as they arrive.\n\n        Used for SSE streaming. Yields raw lines (including SSE framing).\n        Does NOT retry \u2014 streaming requests should not be retried.\n\n        Args:\n            method: HTTP method.\n            path: Request path.\n            headers: Additional HTTP headers.\n            body: Request body.\n\n        Yields:\n            Raw bytes lines from the response body.\n\n        Raises:\n            GatewayUnavailableError: If the gateway is unreachable.\n            GatewayError: On communication errors or non-2xx status.\n        \"\"\"\n        all_headers = {\"Host\": \"gateway.local\"}\n        if headers:\n            all_headers.update(headers)\n\n        body_bytes = b\"\"\n        if body is not None:\n            if isinstance(body, dict):\n                body_bytes = json.dumps(body).encode(\"utf-8\")\n                all_headers[\"Content-Type\"] = \"application/json\"\n            else:\n                body_bytes = body.encode(\"utf-8\")\n            all_headers[\"Content-Length\"] = str(len(body_bytes))\n\n        request_line = f\"{method} {path} HTTP/1.1\\r\\n\"\n        header_lines = \"\".join(f\"{k}: {v}\\r\\n\" for k, v in all_headers.items())\n        raw_request = (request_line + header_lines + \"\\r\\n\").encode(\"utf-8\") + body_bytes\n\n        try:\n            yield from self._stream_raw(raw_request)\n        except (GatewayError, GatewayUnavailableError):\n            raise\n        except Exception as e:\n            raise GatewayError(f\"Gateway stream failed: {e}\") from e\n\n    def _stream_raw(self, data: bytes) -&gt; Iterator[bytes]:\n        \"\"\"Send request and yield response body lines as they arrive.\"\"\"\n        try:\n            if self._socket_path:\n                sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n                sock.settimeout(self._timeout)\n                sock.connect(str(self._socket_path))\n            else:\n                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                sock.settimeout(self._timeout)\n                sock.connect((self._host, self._port))\n        except (ConnectionRefusedError, FileNotFoundError, OSError) as e:\n            target = str(self._socket_path) if self._socket_path else f\"{self._host}:{self._port}\"\n            raise GatewayUnavailableError(\n                f\"Cannot connect to gateway at {target}: {e}\"\n            ) from e\n\n        try:\n            sock.sendall(data)\n\n            # Read until we have the full headers\n            buf = b\"\"\n            while b\"\\r\\n\\r\\n\" not in buf:\n                try:\n                    chunk = sock.recv(_BUFFER_SIZE)\n                    if not chunk:\n                        raise GatewayError(\"Connection closed before headers received\")\n                    buf += chunk\n                except TimeoutError:\n                    raise GatewayError(\n                        f\"Gateway response timed out after {self._timeout}s\"\n                    )\n\n            # Parse status from headers\n            sep_idx = buf.find(b\"\\r\\n\\r\\n\")\n            header_bytes = buf[:sep_idx]\n            remainder = buf[sep_idx + 4:]\n\n            header_text = header_bytes.decode(\"utf-8\", errors=\"replace\")\n            status_line = header_text.split(\"\\r\\n\", 1)[0]\n            status_parts = status_line.split(\" \", 2)\n            if len(status_parts) &lt; 2:\n                raise GatewayError(f\"Malformed status line: {status_line!r}\")\n            status = int(status_parts[1])\n\n            if status != 200:\n                # Read remaining body for error message\n                try:\n                    while True:\n                        chunk = sock.recv(_BUFFER_SIZE)\n                        if not chunk:\n                            break\n                        remainder += chunk\n                except (TimeoutError, OSError):\n                    pass\n                error_body = remainder.decode(\"utf-8\", errors=\"replace\")\n                if status == 429:\n                    raise RateLimitError(f\"Rate limited (429): {error_body}\")\n                raise GatewayError(\n                    f\"Gateway returned status {status}: {error_body}\"\n                )\n\n            # Yield body lines as they arrive\n            line_buf = remainder\n            while True:\n                # Process complete lines in buffer\n                while b\"\\n\" in line_buf:\n                    line, line_buf = line_buf.split(b\"\\n\", 1)\n                    yield line + b\"\\n\"\n\n                try:\n                    chunk = sock.recv(_BUFFER_SIZE)\n                    if not chunk:\n                        break\n                    line_buf += chunk\n                except TimeoutError:\n                    raise GatewayError(\n                        f\"Gateway stream timed out after {self._timeout}s\"\n                    )\n\n            # Yield any remaining data\n            if line_buf:\n                yield line_buf\n        finally:\n            sock.close()\n\n    def health_check(self) -&gt; bool:\n        \"\"\"Check gateway health via ``GET /health`` over the existing connection.\n\n        Returns:\n            ``True`` if the gateway responds with status 200, ``False`` otherwise.\n        \"\"\"\n        try:\n            response = self.request(\"GET\", \"/health\")\n            return response.status == 200\n        except (GatewayError, GatewayUnavailableError):\n            return False\n\n    def _send_raw(self, data: bytes) -&gt; bytes:\n        \"\"\"Send raw bytes over socket and read response.\"\"\"\n        try:\n            if self._socket_path:\n                sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n                sock.settimeout(self._timeout)\n                sock.connect(str(self._socket_path))\n            else:\n                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                sock.settimeout(self._timeout)\n                sock.connect((self._host, self._port))\n        except (ConnectionRefusedError, FileNotFoundError, OSError) as e:\n            target = str(self._socket_path) if self._socket_path else f\"{self._host}:{self._port}\"\n            raise GatewayUnavailableError(\n                f\"Cannot connect to gateway at {target}: {e}\"\n            ) from e\n\n        try:\n            sock.sendall(data)\n\n            # Read response\n            chunks = []\n            while True:\n                try:\n                    chunk = sock.recv(_BUFFER_SIZE)\n                    if not chunk:\n                        break\n                    chunks.append(chunk)\n                    # Check if we've received the full response\n                    response = b\"\".join(chunks)\n                    if self._is_response_complete(response):\n                        break\n                except TimeoutError:\n                    raise GatewayError(\n                        f\"Gateway response timed out after {self._timeout}s\"\n                    )\n            return b\"\".join(chunks)\n        finally:\n            sock.close()\n\n    def _is_response_complete(self, response: bytes) -&gt; bool:\n        \"\"\"Check if HTTP response is complete.\"\"\"\n        # Look for headers/body separator\n        separator = b\"\\r\\n\\r\\n\"\n        sep_idx = response.find(separator)\n        if sep_idx == -1:\n            return False\n\n        headers_part = response[:sep_idx].decode(\"utf-8\", errors=\"replace\")\n        body_start = sep_idx + len(separator)\n\n        # Check Content-Length\n        for line in headers_part.split(\"\\r\\n\"):\n            if line.lower().startswith(\"content-length:\"):\n                content_length = int(line.split(\":\", 1)[1].strip())\n                return len(response) &gt;= body_start + content_length\n\n        # Check for chunked transfer encoding end\n        if b\"transfer-encoding: chunked\" in response.lower():\n            return response.endswith(b\"0\\r\\n\\r\\n\")\n\n        # For responses without Content-Length (e.g., connection: close), we rely on EOF\n        return True\n\n    def _parse_response(self, raw: bytes) -&gt; HttpResponse:\n        \"\"\"Parse raw HTTP response bytes.\"\"\"\n        if not raw:\n            raise GatewayError(\"Empty response from gateway\")\n\n        # Split headers and body\n        separator = b\"\\r\\n\\r\\n\"\n        sep_idx = raw.find(separator)\n        if sep_idx == -1:\n            raise GatewayError(\"Malformed HTTP response: no header/body separator\")\n\n        header_bytes = raw[:sep_idx]\n        body_bytes = raw[sep_idx + len(separator):]\n\n        # Parse status line\n        header_text = header_bytes.decode(\"utf-8\", errors=\"replace\")\n        lines = header_text.split(\"\\r\\n\")\n        if not lines:\n            raise GatewayError(\"Malformed HTTP response: no status line\")\n\n        status_parts = lines[0].split(\" \", 2)\n        if len(status_parts) &lt; 2:\n            raise GatewayError(f\"Malformed status line: {lines[0]!r}\")\n        status = int(status_parts[1])\n\n        # Parse headers\n        headers = {}\n        for line in lines[1:]:\n            if \":\" in line:\n                key, value = line.split(\":\", 1)\n                headers[key.strip().lower()] = value.strip()\n\n        # Decode chunked transfer encoding if present\n        if headers.get(\"transfer-encoding\", \"\").lower() == \"chunked\":\n            body_bytes = self._decode_chunked(body_bytes)\n\n        body = body_bytes.decode(\"utf-8\", errors=\"replace\")\n\n        return HttpResponse(status=status, headers=headers, data=body)\n\n    @staticmethod\n    def _decode_chunked(data: bytes) -&gt; bytes:\n        \"\"\"Decode HTTP chunked transfer encoding.\"\"\"\n        decoded = bytearray()\n        pos = 0\n        while pos &lt; len(data):\n            # Find end of chunk size line\n            crlf = data.find(b\"\\r\\n\", pos)\n            if crlf == -1:\n                break\n            # Parse hex chunk size (ignore extensions after semicolon)\n            size_str = data[pos:crlf].split(b\";\")[0].strip()\n            if not size_str:\n                break\n            try:\n                chunk_size = int(size_str, 16)\n            except ValueError:\n                break\n            if chunk_size == 0:\n                break  # Terminal chunk\n            # Extract chunk data\n            chunk_start = crlf + 2\n            chunk_end = chunk_start + chunk_size\n            if chunk_end &gt; len(data):\n                # Incomplete chunk \u2014 take what we have\n                decoded.extend(data[chunk_start:])\n                break\n            decoded.extend(data[chunk_start:chunk_end])\n            # Skip trailing CRLF after chunk data\n            pos = chunk_end + 2\n        return bytes(decoded)\n</code></pre>"},{"location":"api/gateway/http/#sage_sanctum.gateway.http.GatewayHttpClient.is_unix_socket","title":"<code>is_unix_socket: bool</code>  <code>property</code>","text":"<p>Whether this client connects via Unix domain socket.</p>"},{"location":"api/gateway/http/#sage_sanctum.gateway.http.GatewayHttpClient.__init__","title":"<code>__init__(socket_path: str | Path | None = None, host: str | None = None, port: int | None = None, timeout: float = _DEFAULT_TIMEOUT, max_retries: int = 3, retry_backoff: float = 0.5) -&gt; None</code>","text":"<p>Initialize the HTTP client.</p> <p>Exactly one of <code>socket_path</code> or <code>host</code> must be provided.</p> <p>Parameters:</p> Name Type Description Default <code>socket_path</code> <code>str | Path | None</code> <p>Path to a Unix domain socket (<code>AF_UNIX</code>).</p> <code>None</code> <code>host</code> <code>str | None</code> <p>TCP hostname for <code>AF_INET</code> connections.</p> <code>None</code> <code>port</code> <code>int | None</code> <p>TCP port number (required when <code>host</code> is set).</p> <code>None</code> <code>timeout</code> <code>float</code> <p>Socket timeout in seconds. Defaults to 120.</p> <code>_DEFAULT_TIMEOUT</code> <code>max_retries</code> <code>int</code> <p>Maximum number of retries on transient errors. Defaults to 3.</p> <code>3</code> <code>retry_backoff</code> <code>float</code> <p>Base backoff interval in seconds. Defaults to 0.5.</p> <code>0.5</code> <p>Raises:</p> Type Description <code>GatewayError</code> <p>If neither <code>socket_path</code> nor <code>host</code> is provided.</p> Source code in <code>src/sage_sanctum/gateway/http.py</code> <pre><code>def __init__(\n    self,\n    socket_path: str | Path | None = None,\n    host: str | None = None,\n    port: int | None = None,\n    timeout: float = _DEFAULT_TIMEOUT,\n    max_retries: int = 3,\n    retry_backoff: float = 0.5,\n) -&gt; None:\n    \"\"\"Initialize the HTTP client.\n\n    Exactly one of ``socket_path`` or ``host`` must be provided.\n\n    Args:\n        socket_path: Path to a Unix domain socket (``AF_UNIX``).\n        host: TCP hostname for ``AF_INET`` connections.\n        port: TCP port number (required when ``host`` is set).\n        timeout: Socket timeout in seconds. Defaults to 120.\n        max_retries: Maximum number of retries on transient errors. Defaults to 3.\n        retry_backoff: Base backoff interval in seconds. Defaults to 0.5.\n\n    Raises:\n        GatewayError: If neither ``socket_path`` nor ``host`` is provided.\n    \"\"\"\n    self._socket_path = Path(socket_path) if socket_path else None\n    self._host = host\n    self._port = port\n    self._timeout = timeout\n    self._max_retries = max_retries\n    self._retry_backoff = retry_backoff\n\n    if not self._socket_path and not self._host:\n        raise GatewayError(\"Either socket_path or host must be provided\")\n</code></pre>"},{"location":"api/gateway/http/#sage_sanctum.gateway.http.GatewayHttpClient.request","title":"<code>request(method: str, path: str, headers: dict[str, str] | None = None, body: str | dict | None = None) -&gt; HttpResponse</code>","text":"<p>Send an HTTP request to the gateway with automatic retries.</p> <p>Retries on connection errors, timeouts, and status codes 429, 502, 503, 504. Respects <code>Retry-After</code> header on 429 responses.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>HTTP method (GET, POST, etc.)</p> required <code>path</code> <code>str</code> <p>Request path (e.g., '/v1/chat/completions')</p> required <code>headers</code> <code>dict[str, str] | None</code> <p>Additional HTTP headers</p> <code>None</code> <code>body</code> <code>str | dict | None</code> <p>Request body (str or dict to be JSON-encoded)</p> <code>None</code> <p>Returns:</p> Type Description <code>HttpResponse</code> <p>HttpResponse with status, headers, and body data.</p> <p>Raises:</p> Type Description <code>RateLimitError</code> <p>On 429 after all retries exhausted.</p> <code>GatewayUnavailableError</code> <p>If the gateway is unreachable after retries.</p> <code>GatewayError</code> <p>On other communication errors.</p> Source code in <code>src/sage_sanctum/gateway/http.py</code> <pre><code>def request(\n    self,\n    method: str,\n    path: str,\n    headers: dict[str, str] | None = None,\n    body: str | dict | None = None,\n) -&gt; HttpResponse:\n    \"\"\"Send an HTTP request to the gateway with automatic retries.\n\n    Retries on connection errors, timeouts, and status codes 429, 502, 503, 504.\n    Respects ``Retry-After`` header on 429 responses.\n\n    Args:\n        method: HTTP method (GET, POST, etc.)\n        path: Request path (e.g., '/v1/chat/completions')\n        headers: Additional HTTP headers\n        body: Request body (str or dict to be JSON-encoded)\n\n    Returns:\n        HttpResponse with status, headers, and body data.\n\n    Raises:\n        RateLimitError: On 429 after all retries exhausted.\n        GatewayUnavailableError: If the gateway is unreachable after retries.\n        GatewayError: On other communication errors.\n    \"\"\"\n    all_headers = {\"Host\": \"gateway.local\"}\n    if headers:\n        all_headers.update(headers)\n\n    body_bytes = b\"\"\n    if body is not None:\n        if isinstance(body, dict):\n            body_bytes = json.dumps(body).encode(\"utf-8\")\n            all_headers[\"Content-Type\"] = \"application/json\"\n        else:\n            body_bytes = body.encode(\"utf-8\")\n        all_headers[\"Content-Length\"] = str(len(body_bytes))\n\n    # Build raw HTTP request\n    request_line = f\"{method} {path} HTTP/1.1\\r\\n\"\n    header_lines = \"\".join(f\"{k}: {v}\\r\\n\" for k, v in all_headers.items())\n    raw_request = (request_line + header_lines + \"\\r\\n\").encode(\"utf-8\") + body_bytes\n\n    last_exc: Exception | None = None\n    for attempt in range(self._max_retries + 1):\n        try:\n            raw_response = self._send_raw(raw_request)\n            response = self._parse_response(raw_response)\n\n            # Check for retryable status codes\n            if response.status in _RETRYABLE_STATUS_CODES:\n                if attempt &lt; self._max_retries:\n                    delay = self._retry_delay(attempt, response)\n                    logger.warning(\n                        \"gateway_retry\",\n                        status=response.status,\n                        delay=delay,\n                        attempt=attempt + 1,\n                        max_retries=self._max_retries,\n                    )\n                    time.sleep(delay)\n                    continue\n\n                # Final attempt \u2014 raise appropriate error\n                if response.status == 429:\n                    raise RateLimitError(\n                        f\"Rate limited (429) after {self._max_retries} retries: \"\n                        f\"{response.data}\"\n                    )\n\n            return response\n        except (RateLimitError, GatewayError, GatewayUnavailableError) as e:\n            if isinstance(e, RateLimitError):\n                raise\n            last_exc = e\n            if attempt &lt; self._max_retries:\n                delay = self._retry_delay(attempt)\n                logger.warning(\n                    \"gateway_connection_retry\",\n                    error=str(e),\n                    delay=delay,\n                    attempt=attempt + 1,\n                    max_retries=self._max_retries,\n                )\n                time.sleep(delay)\n                continue\n            raise\n        except Exception as e:\n            raise GatewayError(f\"Gateway request failed: {e}\") from e\n\n    # Should not reach here, but satisfy type checker\n    if last_exc:\n        raise last_exc\n    raise GatewayError(\"Gateway request failed after retries\")  # pragma: no cover\n</code></pre>"},{"location":"api/gateway/http/#sage_sanctum.gateway.http.GatewayHttpClient.request_stream","title":"<code>request_stream(method: str, path: str, headers: dict[str, str] | None = None, body: str | dict | None = None) -&gt; Iterator[bytes]</code>","text":"<p>Send an HTTP request and yield response lines as they arrive.</p> <p>Used for SSE streaming. Yields raw lines (including SSE framing). Does NOT retry \u2014 streaming requests should not be retried.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>HTTP method.</p> required <code>path</code> <code>str</code> <p>Request path.</p> required <code>headers</code> <code>dict[str, str] | None</code> <p>Additional HTTP headers.</p> <code>None</code> <code>body</code> <code>str | dict | None</code> <p>Request body.</p> <code>None</code> <p>Yields:</p> Type Description <code>bytes</code> <p>Raw bytes lines from the response body.</p> <p>Raises:</p> Type Description <code>GatewayUnavailableError</code> <p>If the gateway is unreachable.</p> <code>GatewayError</code> <p>On communication errors or non-2xx status.</p> Source code in <code>src/sage_sanctum/gateway/http.py</code> <pre><code>def request_stream(\n    self,\n    method: str,\n    path: str,\n    headers: dict[str, str] | None = None,\n    body: str | dict | None = None,\n) -&gt; Iterator[bytes]:\n    \"\"\"Send an HTTP request and yield response lines as they arrive.\n\n    Used for SSE streaming. Yields raw lines (including SSE framing).\n    Does NOT retry \u2014 streaming requests should not be retried.\n\n    Args:\n        method: HTTP method.\n        path: Request path.\n        headers: Additional HTTP headers.\n        body: Request body.\n\n    Yields:\n        Raw bytes lines from the response body.\n\n    Raises:\n        GatewayUnavailableError: If the gateway is unreachable.\n        GatewayError: On communication errors or non-2xx status.\n    \"\"\"\n    all_headers = {\"Host\": \"gateway.local\"}\n    if headers:\n        all_headers.update(headers)\n\n    body_bytes = b\"\"\n    if body is not None:\n        if isinstance(body, dict):\n            body_bytes = json.dumps(body).encode(\"utf-8\")\n            all_headers[\"Content-Type\"] = \"application/json\"\n        else:\n            body_bytes = body.encode(\"utf-8\")\n        all_headers[\"Content-Length\"] = str(len(body_bytes))\n\n    request_line = f\"{method} {path} HTTP/1.1\\r\\n\"\n    header_lines = \"\".join(f\"{k}: {v}\\r\\n\" for k, v in all_headers.items())\n    raw_request = (request_line + header_lines + \"\\r\\n\").encode(\"utf-8\") + body_bytes\n\n    try:\n        yield from self._stream_raw(raw_request)\n    except (GatewayError, GatewayUnavailableError):\n        raise\n    except Exception as e:\n        raise GatewayError(f\"Gateway stream failed: {e}\") from e\n</code></pre>"},{"location":"api/gateway/http/#sage_sanctum.gateway.http.GatewayHttpClient.health_check","title":"<code>health_check() -&gt; bool</code>","text":"<p>Check gateway health via <code>GET /health</code> over the existing connection.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the gateway responds with status 200, <code>False</code> otherwise.</p> Source code in <code>src/sage_sanctum/gateway/http.py</code> <pre><code>def health_check(self) -&gt; bool:\n    \"\"\"Check gateway health via ``GET /health`` over the existing connection.\n\n    Returns:\n        ``True`` if the gateway responds with status 200, ``False`` otherwise.\n    \"\"\"\n    try:\n        response = self.request(\"GET\", \"/health\")\n        return response.status == 200\n    except (GatewayError, GatewayUnavailableError):\n        return False\n</code></pre>"},{"location":"api/io/","title":"sage_sanctum.io","text":"<p>Agent input and output types.</p>"},{"location":"api/io/#modules","title":"Modules","text":"Module Description <code>inputs</code> <code>AgentInput</code>, <code>RepositoryInput</code> <code>outputs</code> <code>AgentOutput</code>, <code>SarifOutput</code>, <code>Finding</code>, <code>Location</code>, <code>TokenUsage</code>"},{"location":"api/io/inputs/","title":"sage_sanctum.io.inputs","text":"<p>Agent input types including <code>RepositoryInput</code> for cloned repository analysis.</p>"},{"location":"api/io/inputs/#sage_sanctum.io.inputs","title":"<code>sage_sanctum.io.inputs</code>","text":"<p>Agent input types.</p>"},{"location":"api/io/inputs/#sage_sanctum.io.inputs.AgentInput","title":"<code>AgentInput</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for agent inputs.</p> Source code in <code>src/sage_sanctum/io/inputs.py</code> <pre><code>class AgentInput(ABC):\n    \"\"\"Base class for agent inputs.\"\"\"\n\n    @property\n    @abstractmethod\n    def io_type(self) -&gt; str:\n        \"\"\"Input type identifier.\"\"\"\n\n    @abstractmethod\n    def validate(self) -&gt; None:\n        \"\"\"Validate the input.\n\n        Raises:\n            InputValidationError: If the input is invalid.\n        \"\"\"\n</code></pre>"},{"location":"api/io/inputs/#sage_sanctum.io.inputs.AgentInput.io_type","title":"<code>io_type: str</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Input type identifier.</p>"},{"location":"api/io/inputs/#sage_sanctum.io.inputs.AgentInput.validate","title":"<code>validate() -&gt; None</code>  <code>abstractmethod</code>","text":"<p>Validate the input.</p> <p>Raises:</p> Type Description <code>InputValidationError</code> <p>If the input is invalid.</p> Source code in <code>src/sage_sanctum/io/inputs.py</code> <pre><code>@abstractmethod\ndef validate(self) -&gt; None:\n    \"\"\"Validate the input.\n\n    Raises:\n        InputValidationError: If the input is invalid.\n    \"\"\"\n</code></pre>"},{"location":"api/io/inputs/#sage_sanctum.io.inputs.RepositoryInput","title":"<code>RepositoryInput</code>  <code>dataclass</code>","text":"<p>               Bases: <code>AgentInput</code></p> <p>Input representing a cloned repository to analyze.</p> <p>Attributes:</p> Name Type Description <code>path</code> <code>Path</code> <p>Absolute path to the repository root</p> <code>ref</code> <code>str</code> <p>Git ref (branch, tag, commit) being analyzed</p> <code>url</code> <code>str</code> <p>Remote URL of the repository</p> Source code in <code>src/sage_sanctum/io/inputs.py</code> <pre><code>@dataclass\nclass RepositoryInput(AgentInput):\n    \"\"\"Input representing a cloned repository to analyze.\n\n    Attributes:\n        path: Absolute path to the repository root\n        ref: Git ref (branch, tag, commit) being analyzed\n        url: Remote URL of the repository\n    \"\"\"\n\n    path: Path\n    ref: str = \"\"\n    url: str = \"\"\n\n    @property\n    def io_type(self) -&gt; str:\n        return \"repository\"\n\n    def validate(self) -&gt; None:\n        \"\"\"Validate the repository input.\n\n        Raises:\n            InputValidationError: If the path doesn't exist or isn't a directory.\n            PathTraversalError: If the path contains traversal attempts.\n        \"\"\"\n        # Check for path traversal \u2014 inspect individual path components\n        # to avoid false positives on names like \"..foo\"\n        resolved = self.path.resolve()\n        if \"..\" in self.path.parts:\n            raise PathTraversalError(\n                f\"Path traversal detected in repository path: {self.path}\"\n            )\n\n        if not resolved.exists():\n            raise InputValidationError(\n                f\"Repository path does not exist: {resolved}\"\n            )\n\n        if not resolved.is_dir():\n            raise InputValidationError(\n                f\"Repository path is not a directory: {resolved}\"\n            )\n\n    def list_files(self, extensions: set[str] | None = None) -&gt; list[Path]:\n        \"\"\"List files in the repository.\n\n        Args:\n            extensions: Optional set of extensions to filter by (e.g., {'.py', '.js'})\n\n        Returns:\n            List of file paths relative to the repository root.\n        \"\"\"\n        files = []\n        for root, _, filenames in os.walk(self.path):\n            root_path = Path(root)\n            for name in filenames:\n                file_path = root_path / name\n                if extensions and file_path.suffix not in extensions:\n                    continue\n                try:\n                    files.append(file_path.relative_to(self.path))\n                except ValueError:\n                    continue\n        return sorted(files)\n\n    @classmethod\n    def from_environment(cls) -&gt; RepositoryInput:\n        \"\"\"Create from environment variables.\n\n        Expected env vars:\n        - REPO_PATH: Path to the repository\n        - REPO_REF: Git ref (optional)\n        - REPO_URL: Remote URL (optional)\n        \"\"\"\n        repo_path = os.environ.get(\"REPO_PATH\", \"\")\n        if not repo_path:\n            raise InputValidationError(\"REPO_PATH environment variable not set\")\n\n        return cls(\n            path=Path(repo_path),\n            ref=os.environ.get(\"REPO_REF\", \"\"),\n            url=os.environ.get(\"REPO_URL\", \"\"),\n        )\n</code></pre>"},{"location":"api/io/inputs/#sage_sanctum.io.inputs.RepositoryInput.validate","title":"<code>validate() -&gt; None</code>","text":"<p>Validate the repository input.</p> <p>Raises:</p> Type Description <code>InputValidationError</code> <p>If the path doesn't exist or isn't a directory.</p> <code>PathTraversalError</code> <p>If the path contains traversal attempts.</p> Source code in <code>src/sage_sanctum/io/inputs.py</code> <pre><code>def validate(self) -&gt; None:\n    \"\"\"Validate the repository input.\n\n    Raises:\n        InputValidationError: If the path doesn't exist or isn't a directory.\n        PathTraversalError: If the path contains traversal attempts.\n    \"\"\"\n    # Check for path traversal \u2014 inspect individual path components\n    # to avoid false positives on names like \"..foo\"\n    resolved = self.path.resolve()\n    if \"..\" in self.path.parts:\n        raise PathTraversalError(\n            f\"Path traversal detected in repository path: {self.path}\"\n        )\n\n    if not resolved.exists():\n        raise InputValidationError(\n            f\"Repository path does not exist: {resolved}\"\n        )\n\n    if not resolved.is_dir():\n        raise InputValidationError(\n            f\"Repository path is not a directory: {resolved}\"\n        )\n</code></pre>"},{"location":"api/io/inputs/#sage_sanctum.io.inputs.RepositoryInput.list_files","title":"<code>list_files(extensions: set[str] | None = None) -&gt; list[Path]</code>","text":"<p>List files in the repository.</p> <p>Parameters:</p> Name Type Description Default <code>extensions</code> <code>set[str] | None</code> <p>Optional set of extensions to filter by (e.g., {'.py', '.js'})</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Path]</code> <p>List of file paths relative to the repository root.</p> Source code in <code>src/sage_sanctum/io/inputs.py</code> <pre><code>def list_files(self, extensions: set[str] | None = None) -&gt; list[Path]:\n    \"\"\"List files in the repository.\n\n    Args:\n        extensions: Optional set of extensions to filter by (e.g., {'.py', '.js'})\n\n    Returns:\n        List of file paths relative to the repository root.\n    \"\"\"\n    files = []\n    for root, _, filenames in os.walk(self.path):\n        root_path = Path(root)\n        for name in filenames:\n            file_path = root_path / name\n            if extensions and file_path.suffix not in extensions:\n                continue\n            try:\n                files.append(file_path.relative_to(self.path))\n            except ValueError:\n                continue\n    return sorted(files)\n</code></pre>"},{"location":"api/io/inputs/#sage_sanctum.io.inputs.RepositoryInput.from_environment","title":"<code>from_environment() -&gt; RepositoryInput</code>  <code>classmethod</code>","text":"<p>Create from environment variables.</p> <p>Expected env vars: - REPO_PATH: Path to the repository - REPO_REF: Git ref (optional) - REPO_URL: Remote URL (optional)</p> Source code in <code>src/sage_sanctum/io/inputs.py</code> <pre><code>@classmethod\ndef from_environment(cls) -&gt; RepositoryInput:\n    \"\"\"Create from environment variables.\n\n    Expected env vars:\n    - REPO_PATH: Path to the repository\n    - REPO_REF: Git ref (optional)\n    - REPO_URL: Remote URL (optional)\n    \"\"\"\n    repo_path = os.environ.get(\"REPO_PATH\", \"\")\n    if not repo_path:\n        raise InputValidationError(\"REPO_PATH environment variable not set\")\n\n    return cls(\n        path=Path(repo_path),\n        ref=os.environ.get(\"REPO_REF\", \"\"),\n        url=os.environ.get(\"REPO_URL\", \"\"),\n    )\n</code></pre>"},{"location":"api/io/outputs/","title":"sage_sanctum.io.outputs","text":"<p>Agent output types including SARIF 2.1.0 formatted results.</p>"},{"location":"api/io/outputs/#sage_sanctum.io.outputs","title":"<code>sage_sanctum.io.outputs</code>","text":"<p>Agent output types including SARIF format.</p>"},{"location":"api/io/outputs/#sage_sanctum.io.outputs.AgentOutput","title":"<code>AgentOutput</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for agent outputs.</p> Source code in <code>src/sage_sanctum/io/outputs.py</code> <pre><code>class AgentOutput(ABC):\n    \"\"\"Base class for agent outputs.\"\"\"\n\n    @property\n    @abstractmethod\n    def io_type(self) -&gt; str:\n        \"\"\"Output type identifier.\"\"\"\n\n    @abstractmethod\n    def write(self, output_dir: Path) -&gt; list[str]:\n        \"\"\"Write output files to the output directory.\n\n        Returns:\n            List of filenames written.\n\n        Raises:\n            OutputWriteError: If writing fails.\n        \"\"\"\n\n    @abstractmethod\n    def to_dict(self) -&gt; dict:\n        \"\"\"Serialize output to a dictionary.\"\"\"\n</code></pre>"},{"location":"api/io/outputs/#sage_sanctum.io.outputs.AgentOutput.io_type","title":"<code>io_type: str</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Output type identifier.</p>"},{"location":"api/io/outputs/#sage_sanctum.io.outputs.AgentOutput.write","title":"<code>write(output_dir: Path) -&gt; list[str]</code>  <code>abstractmethod</code>","text":"<p>Write output files to the output directory.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of filenames written.</p> <p>Raises:</p> Type Description <code>OutputWriteError</code> <p>If writing fails.</p> Source code in <code>src/sage_sanctum/io/outputs.py</code> <pre><code>@abstractmethod\ndef write(self, output_dir: Path) -&gt; list[str]:\n    \"\"\"Write output files to the output directory.\n\n    Returns:\n        List of filenames written.\n\n    Raises:\n        OutputWriteError: If writing fails.\n    \"\"\"\n</code></pre>"},{"location":"api/io/outputs/#sage_sanctum.io.outputs.AgentOutput.to_dict","title":"<code>to_dict() -&gt; dict</code>  <code>abstractmethod</code>","text":"<p>Serialize output to a dictionary.</p> Source code in <code>src/sage_sanctum/io/outputs.py</code> <pre><code>@abstractmethod\ndef to_dict(self) -&gt; dict:\n    \"\"\"Serialize output to a dictionary.\"\"\"\n</code></pre>"},{"location":"api/io/outputs/#sage_sanctum.io.outputs.Location","title":"<code>Location</code>  <code>dataclass</code>","text":"<p>Source code location for a finding.</p> <p>Attributes:</p> Name Type Description <code>file</code> <code>str</code> <p>File path relative to the repository root.</p> <code>start_line</code> <code>int</code> <p>1-based starting line number.</p> <code>end_line</code> <code>int</code> <p>1-based ending line number (<code>0</code> if single-line).</p> <code>start_column</code> <code>int</code> <p>1-based starting column number (<code>0</code> if not specified).</p> <code>end_column</code> <code>int</code> <p>1-based ending column number (<code>0</code> if not specified).</p> Source code in <code>src/sage_sanctum/io/outputs.py</code> <pre><code>@dataclass(frozen=True)\nclass Location:\n    \"\"\"Source code location for a finding.\n\n    Attributes:\n        file: File path relative to the repository root.\n        start_line: 1-based starting line number.\n        end_line: 1-based ending line number (``0`` if single-line).\n        start_column: 1-based starting column number (``0`` if not specified).\n        end_column: 1-based ending column number (``0`` if not specified).\n    \"\"\"\n\n    file: str\n    start_line: int = 0\n    end_line: int = 0\n    start_column: int = 0\n    end_column: int = 0\n</code></pre>"},{"location":"api/io/outputs/#sage_sanctum.io.outputs.TokenUsage","title":"<code>TokenUsage</code>  <code>dataclass</code>","text":"<p>Token usage tracking for an LLM call.</p> <p>Attributes:</p> Name Type Description <code>model</code> <code>str</code> <p>Model identifier (e.g. <code>\"gpt-4o\"</code>).</p> <code>prompt_tokens</code> <code>int</code> <p>Number of tokens in the prompt.</p> <code>completion_tokens</code> <code>int</code> <p>Number of tokens in the completion.</p> <code>total_tokens</code> <code>int</code> <p>Total tokens consumed (prompt + completion).</p> Source code in <code>src/sage_sanctum/io/outputs.py</code> <pre><code>@dataclass(frozen=True)\nclass TokenUsage:\n    \"\"\"Token usage tracking for an LLM call.\n\n    Attributes:\n        model: Model identifier (e.g. ``\"gpt-4o\"``).\n        prompt_tokens: Number of tokens in the prompt.\n        completion_tokens: Number of tokens in the completion.\n        total_tokens: Total tokens consumed (prompt + completion).\n    \"\"\"\n\n    model: str\n    prompt_tokens: int = 0\n    completion_tokens: int = 0\n    total_tokens: int = 0\n</code></pre>"},{"location":"api/io/outputs/#sage_sanctum.io.outputs.Finding","title":"<code>Finding</code>  <code>dataclass</code>","text":"<p>A single security or code quality finding.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Rule identifier (e.g. <code>\"SQL-001\"</code>). Used as the SARIF <code>ruleId</code>.</p> <code>title</code> <code>str</code> <p>Short human-readable title.</p> <code>description</code> <code>str</code> <p>Detailed description of the finding.</p> <code>severity</code> <code>str</code> <p>Severity level \u2014 one of <code>\"critical\"</code>, <code>\"high\"</code>, <code>\"medium\"</code>, <code>\"low\"</code>, or <code>\"note\"</code>.</p> <code>location</code> <code>Location</code> <p>Source code location where the finding was identified.</p> <code>cwe</code> <code>str</code> <p>CWE identifier (e.g. <code>\"CWE-89\"</code>). Included as a SARIF tag.</p> <code>remediation</code> <code>str</code> <p>Suggested fix or mitigation.</p> <code>confidence</code> <code>str</code> <p>Confidence level \u2014 <code>\"high\"</code>, <code>\"medium\"</code>, or <code>\"low\"</code>.</p> <code>metadata</code> <code>dict</code> <p>Arbitrary key-value pairs for additional context.</p> Source code in <code>src/sage_sanctum/io/outputs.py</code> <pre><code>@dataclass\nclass Finding:\n    \"\"\"A single security or code quality finding.\n\n    Attributes:\n        id: Rule identifier (e.g. ``\"SQL-001\"``). Used as the SARIF ``ruleId``.\n        title: Short human-readable title.\n        description: Detailed description of the finding.\n        severity: Severity level \u2014 one of ``\"critical\"``, ``\"high\"``,\n            ``\"medium\"``, ``\"low\"``, or ``\"note\"``.\n        location: Source code location where the finding was identified.\n        cwe: CWE identifier (e.g. ``\"CWE-89\"``). Included as a SARIF tag.\n        remediation: Suggested fix or mitigation.\n        confidence: Confidence level \u2014 ``\"high\"``, ``\"medium\"``, or ``\"low\"``.\n        metadata: Arbitrary key-value pairs for additional context.\n    \"\"\"\n\n    id: str\n    title: str\n    description: str\n    severity: str  # critical, high, medium, low, note\n    location: Location\n    cwe: str = \"\"\n    remediation: str = \"\"\n    confidence: str = \"medium\"\n    metadata: dict = field(default_factory=dict)\n</code></pre>"},{"location":"api/io/outputs/#sage_sanctum.io.outputs.SarifOutput","title":"<code>SarifOutput</code>  <code>dataclass</code>","text":"<p>               Bases: <code>AgentOutput</code></p> <p>SARIF 2.1.0 formatted output.</p> <p>The standard format for static analysis results, compatible with GitHub Code Scanning and other SARIF consumers.</p> <p>Attributes:</p> Name Type Description <code>tool_name</code> <code>str</code> <p>Name of the tool that produced the findings.</p> <code>tool_version</code> <code>str</code> <p>Version of the tool.</p> <code>findings</code> <code>list[Finding]</code> <p>List of security or quality findings.</p> <code>token_usage</code> <code>list[TokenUsage]</code> <p>LLM token usage records for cost tracking.</p> Source code in <code>src/sage_sanctum/io/outputs.py</code> <pre><code>@dataclass\nclass SarifOutput(AgentOutput):\n    \"\"\"SARIF 2.1.0 formatted output.\n\n    The standard format for static analysis results, compatible with\n    GitHub Code Scanning and other SARIF consumers.\n\n    Attributes:\n        tool_name: Name of the tool that produced the findings.\n        tool_version: Version of the tool.\n        findings: List of security or quality findings.\n        token_usage: LLM token usage records for cost tracking.\n    \"\"\"\n\n    tool_name: str\n    tool_version: str\n    findings: list[Finding] = field(default_factory=list)\n    token_usage: list[TokenUsage] = field(default_factory=list)\n\n    @property\n    def io_type(self) -&gt; str:\n        return \"sarif\"\n\n    def write(self, output_dir: Path) -&gt; list[str]:\n        \"\"\"Write SARIF report to the output directory.\n\n        Creates the directory if it doesn't exist and writes\n        ``results.sarif`` with JSON-formatted SARIF 2.1.0 content.\n\n        Args:\n            output_dir: Directory to write the SARIF file into.\n\n        Returns:\n            List containing ``\"results.sarif\"``.\n\n        Raises:\n            OutputWriteError: If writing to disk fails.\n        \"\"\"\n        output_dir.mkdir(parents=True, exist_ok=True)\n        sarif_path = output_dir / \"results.sarif\"\n\n        try:\n            sarif_data = self._to_sarif()\n            sarif_path.write_text(json.dumps(sarif_data, indent=2))\n        except Exception as e:\n            raise OutputWriteError(f\"Failed to write SARIF: {e}\") from e\n\n        return [\"results.sarif\"]\n\n    def to_dict(self) -&gt; dict:\n        \"\"\"Serialize to a SARIF 2.1.0 dictionary.\"\"\"\n        return self._to_sarif()\n\n    def _to_sarif(self) -&gt; dict:\n        \"\"\"Convert to SARIF 2.1.0 format.\"\"\"\n        # Build rules from unique finding IDs\n        rules_map: dict[str, dict] = {}\n        results = []\n\n        severity_to_level = {\n            \"critical\": \"error\",\n            \"high\": \"error\",\n            \"medium\": \"warning\",\n            \"low\": \"note\",\n            \"note\": \"note\",\n        }\n\n        severity_to_score = {\n            \"critical\": 9.0,\n            \"high\": 7.0,\n            \"medium\": 4.0,\n            \"low\": 1.0,\n            \"note\": 0.0,\n        }\n\n        for finding in self.findings:\n            # Add rule if not seen\n            if finding.id not in rules_map:\n                rules_map[finding.id] = {\n                    \"id\": finding.id,\n                    \"name\": finding.title,\n                    \"shortDescription\": {\"text\": finding.title},\n                    \"fullDescription\": {\"text\": finding.description},\n                    \"properties\": {\n                        \"security-severity\": str(\n                            severity_to_score.get(finding.severity, 4.0)\n                        ),\n                    },\n                }\n                if finding.cwe:\n                    rules_map[finding.id][\"properties\"][\"tags\"] = [\n                        f\"CWE-{finding.cwe}\" if not finding.cwe.startswith(\"CWE-\") else finding.cwe,\n                        \"security\",\n                    ]\n\n            # Build result\n            result = {\n                \"ruleId\": finding.id,\n                \"level\": severity_to_level.get(finding.severity, \"warning\"),\n                \"message\": {\"text\": finding.description},\n                \"locations\": [\n                    {\n                        \"physicalLocation\": {\n                            \"artifactLocation\": {\"uri\": finding.location.file},\n                            \"region\": {\n                                \"startLine\": max(finding.location.start_line, 1),\n                            },\n                        }\n                    }\n                ],\n            }\n\n            if finding.location.end_line:\n                result[\"locations\"][0][\"physicalLocation\"][\"region\"][\"endLine\"] = (\n                    finding.location.end_line\n                )\n            if finding.location.start_column:\n                result[\"locations\"][0][\"physicalLocation\"][\"region\"][\"startColumn\"] = (\n                    finding.location.start_column\n                )\n            if finding.location.end_column:\n                result[\"locations\"][0][\"physicalLocation\"][\"region\"][\"endColumn\"] = (\n                    finding.location.end_column\n                )\n\n            if finding.remediation:\n                result[\"fixes\"] = [\n                    {\"description\": {\"text\": finding.remediation}}\n                ]\n\n            results.append(result)\n\n        return {\n            \"$schema\": \"https://raw.githubusercontent.com/oasis-tcs/sarif-spec/main/sarif-2.1/schema/sarif-schema-2.1.0.json\",\n            \"version\": \"2.1.0\",\n            \"runs\": [\n                {\n                    \"tool\": {\n                        \"driver\": {\n                            \"name\": self.tool_name,\n                            \"version\": self.tool_version,\n                            \"rules\": list(rules_map.values()),\n                        }\n                    },\n                    \"results\": results,\n                }\n            ],\n        }\n</code></pre>"},{"location":"api/io/outputs/#sage_sanctum.io.outputs.SarifOutput.write","title":"<code>write(output_dir: Path) -&gt; list[str]</code>","text":"<p>Write SARIF report to the output directory.</p> <p>Creates the directory if it doesn't exist and writes <code>results.sarif</code> with JSON-formatted SARIF 2.1.0 content.</p> <p>Parameters:</p> Name Type Description Default <code>output_dir</code> <code>Path</code> <p>Directory to write the SARIF file into.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List containing <code>\"results.sarif\"</code>.</p> <p>Raises:</p> Type Description <code>OutputWriteError</code> <p>If writing to disk fails.</p> Source code in <code>src/sage_sanctum/io/outputs.py</code> <pre><code>def write(self, output_dir: Path) -&gt; list[str]:\n    \"\"\"Write SARIF report to the output directory.\n\n    Creates the directory if it doesn't exist and writes\n    ``results.sarif`` with JSON-formatted SARIF 2.1.0 content.\n\n    Args:\n        output_dir: Directory to write the SARIF file into.\n\n    Returns:\n        List containing ``\"results.sarif\"``.\n\n    Raises:\n        OutputWriteError: If writing to disk fails.\n    \"\"\"\n    output_dir.mkdir(parents=True, exist_ok=True)\n    sarif_path = output_dir / \"results.sarif\"\n\n    try:\n        sarif_data = self._to_sarif()\n        sarif_path.write_text(json.dumps(sarif_data, indent=2))\n    except Exception as e:\n        raise OutputWriteError(f\"Failed to write SARIF: {e}\") from e\n\n    return [\"results.sarif\"]\n</code></pre>"},{"location":"api/io/outputs/#sage_sanctum.io.outputs.SarifOutput.to_dict","title":"<code>to_dict() -&gt; dict</code>","text":"<p>Serialize to a SARIF 2.1.0 dictionary.</p> Source code in <code>src/sage_sanctum/io/outputs.py</code> <pre><code>def to_dict(self) -&gt; dict:\n    \"\"\"Serialize to a SARIF 2.1.0 dictionary.\"\"\"\n    return self._to_sarif()\n</code></pre>"},{"location":"api/llm/","title":"sage_sanctum.llm","text":"<p>LLM model categories, references, selection, and gateway chat model.</p>"},{"location":"api/llm/#modules","title":"Modules","text":"Module Description <code>model_category</code> <code>ModelCategory</code> enum (TRIAGE, ANALYSIS, REASONING, EMBEDDINGS) <code>model_ref</code> <code>ModelRef</code> \u2014 canonical <code>provider:model</code> references <code>model_selector</code> <code>ModelSelector</code> and <code>StaticModelSelector</code> <code>gateway_chat</code> <code>GatewayChatModel</code> \u2014 LangChain chat model via gateway"},{"location":"api/llm/gateway_chat/","title":"sage_sanctum.llm.gateway_chat","text":"<p>LangChain chat model that routes through the Sage Sanctum LLM gateway.</p>"},{"location":"api/llm/gateway_chat/#sage_sanctum.llm.gateway_chat","title":"<code>sage_sanctum.llm.gateway_chat</code>","text":"<p>GatewayChatModel: LangChain BaseChatModel wrapping the LLM gateway.</p> <p>In gateway mode, injects SPIFFE JWT + TraT auth headers per request. In direct mode, creates a standard ChatLiteLLM with direct API keys.</p>"},{"location":"api/llm/gateway_chat/#sage_sanctum.llm.gateway_chat.GatewayChatModel","title":"<code>GatewayChatModel</code>","text":"<p>               Bases: <code>BaseChatModel</code></p> <p>LangChain chat model that routes through the Sage Sanctum LLM gateway.</p> <p>Injects SPIFFE JWT + TraT headers on every request. Communicates via Unix socket (production) or TCP (dev).</p> <p>Attributes:</p> Name Type Description <code>model_ref</code> <code>ModelRef</code> <p>Canonical model reference (provider + model name).</p> <code>gateway_client</code> <code>Any</code> <p>Gateway client providing credentials.</p> <code>http_client</code> <code>Any</code> <p>HTTP client for gateway communication.</p> <code>temperature</code> <code>float</code> <p>Sampling temperature. Defaults to <code>0.0</code> (deterministic).</p> <code>max_tokens</code> <code>int | None</code> <p>Maximum tokens to generate. <code>None</code> lets the provider decide.</p> <code>top_p</code> <code>float | None</code> <p>Nucleus sampling threshold. <code>None</code> lets the provider decide.</p> <code>seed</code> <code>int | None</code> <p>Random seed for deterministic generation. <code>None</code> for non-deterministic.</p> Source code in <code>src/sage_sanctum/llm/gateway_chat.py</code> <pre><code>class GatewayChatModel(BaseChatModel):\n    \"\"\"LangChain chat model that routes through the Sage Sanctum LLM gateway.\n\n    Injects SPIFFE JWT + TraT headers on every request. Communicates\n    via Unix socket (production) or TCP (dev).\n\n    Attributes:\n        model_ref: Canonical model reference (provider + model name).\n        gateway_client: Gateway client providing credentials.\n        http_client: HTTP client for gateway communication.\n        temperature: Sampling temperature. Defaults to ``0.0`` (deterministic).\n        max_tokens: Maximum tokens to generate. ``None`` lets the provider decide.\n        top_p: Nucleus sampling threshold. ``None`` lets the provider decide.\n        seed: Random seed for deterministic generation. ``None`` for non-deterministic.\n    \"\"\"\n\n    model_ref: ModelRef\n    gateway_client: Any  # GatewayClient - using Any to avoid pydantic issues\n    http_client: Any  # GatewayHttpClient\n    temperature: float = 0.0\n    max_tokens: int | None = None\n    top_p: float | None = None\n    seed: int | None = None\n\n    model_config = {\"arbitrary_types_allowed\": True}\n\n    @property\n    def _llm_type(self) -&gt; str:\n        return \"sage-sanctum-gateway\"\n\n    @property\n    def _identifying_params(self) -&gt; dict[str, Any]:\n        return {\n            \"model\": str(self.model_ref),\n            \"temperature\": self.temperature,\n        }\n\n    def with_structured_output(\n        self,\n        schema: type[BaseModel],\n        *,\n        include_raw: bool = False,\n        **kwargs: Any,\n    ) -&gt; Runnable[LanguageModelInput, Any]:\n        \"\"\"Return a Runnable that produces structured Pydantic output.\n\n        For OpenAI models, uses native JSON schema mode\n        (``response_format.type = \"json_schema\"``).  For other providers,\n        uses ``json_object`` mode and relies on the parser for validation.\n\n        Args:\n            schema: Pydantic model class to parse responses into.\n            include_raw: If ``True``, return a dict with ``raw``, ``parsed``,\n                and ``parsing_error`` keys.\n\n        Returns:\n            A LangChain ``Runnable`` that yields ``schema`` instances (or\n            raw+parsed dicts when *include_raw* is set).\n        \"\"\"\n        parser = PydanticOutputParser(pydantic_object=schema)\n\n        if self.model_ref.provider == \"openai\":\n            json_schema = schema.model_json_schema()\n            _strip_schema_extras(json_schema)\n            response_format = {\n                \"type\": \"json_schema\",\n                \"json_schema\": {\n                    \"name\": schema.__name__,\n                    \"schema\": json_schema,\n                    \"strict\": True,\n                },\n            }\n            llm = self.bind(response_format=response_format)\n        else:\n            llm = self.bind(response_format={\"type\": \"json_object\"})\n\n        if include_raw:\n            def _parse_with_raw(ai_message: AIMessage) -&gt; dict:\n                parsed = _safe_parse(parser, ai_message)\n                error = _safe_parse_error(parser, ai_message)\n                return {\"raw\": ai_message, \"parsed\": parsed, \"parsing_error\": error}\n\n            return llm | _parse_with_raw\n\n        return llm | parser\n\n    def _build_request_body(\n        self,\n        messages: list[BaseMessage],\n        stop: list[str] | None = None,\n        **kwargs: Any,\n    ) -&gt; dict[str, Any]:\n        \"\"\"Build the OpenAI-format request body.\"\"\"\n        message_dicts = _messages_to_dicts(messages)\n        request_body: dict[str, Any] = {\n            \"model\": self.model_ref.model,\n            \"messages\": message_dicts,\n            \"temperature\": self.temperature,\n        }\n        if self.max_tokens is not None:\n            request_body[\"max_tokens\"] = self.max_tokens\n        if self.top_p is not None:\n            request_body[\"top_p\"] = self.top_p\n        if self.seed is not None:\n            request_body[\"seed\"] = self.seed\n        if stop:\n            request_body[\"stop\"] = stop\n        # Forward response_format from bind() kwargs for structured output\n        if \"response_format\" in kwargs:\n            request_body[\"response_format\"] = kwargs[\"response_format\"]\n        # Forward tools from bind() kwargs\n        if \"tools\" in kwargs:\n            request_body[\"tools\"] = kwargs[\"tools\"]\n        return request_body\n\n    def _generate(\n        self,\n        messages: list[BaseMessage],\n        stop: list[str] | None = None,\n        run_manager: Any = None,\n        **kwargs: Any,\n    ) -&gt; ChatResult:\n        \"\"\"Send messages through the gateway and return a chat response.\n\n        Fetches fresh credentials, builds an OpenAI-format request, injects\n        authentication headers, and sends the request via the HTTP client.\n\n        Args:\n            messages: LangChain message objects to send.\n            stop: Optional stop sequences.\n            run_manager: LangChain callback manager (unused).\n\n        Returns:\n            ``ChatResult`` with the assistant's response.\n\n        Raises:\n            GatewayError: On HTTP errors or malformed responses.\n        \"\"\"\n        # Get fresh credentials\n        creds = self.gateway_client.get_credentials()\n\n        # Build request\n        request_body = self._build_request_body(messages, stop, **kwargs)\n\n        # Build headers with auth\n        headers = creds.auth_headers()\n        headers[\"X-Provider\"] = self.model_ref.provider\n\n        # Send to gateway\n        try:\n            response = self.http_client.request(\n                method=\"POST\",\n                path=\"/v1/chat/completions\",\n                headers=headers,\n                body=request_body,\n            )\n        except RateLimitError:\n            raise\n        except GatewayError:\n            raise\n        except Exception as e:\n            raise GatewayError(f\"Gateway request failed: {e}\") from e\n\n        if response.status == 429:\n            raise RateLimitError(\n                f\"Rate limited (429): {response.data}\"\n            )\n\n        if response.status != 200:\n            raise GatewayError(\n                f\"Gateway returned status {response.status}: {response.data}\"\n            )\n\n        # Parse OpenAI-format response\n        try:\n            data = json.loads(response.data)\n        except json.JSONDecodeError as e:\n            raise GatewayError(f\"Invalid JSON response from gateway: {e}\") from e\n\n        choices = data.get(\"choices\", [])\n        if not choices:\n            raise GatewayError(\"Gateway returned no choices\")\n\n        message_data = choices[0].get(\"message\", {})\n        content = message_data.get(\"content\", \"\")\n        usage = data.get(\"usage\", {})\n\n        # Build AIMessage with tool calls if present\n        ai_kwargs: dict[str, Any] = {\"content\": content}\n        raw_tool_calls = message_data.get(\"tool_calls\")\n        if raw_tool_calls:\n            ai_kwargs[\"tool_calls\"] = [\n                {\n                    \"id\": tc[\"id\"],\n                    \"name\": tc[\"function\"][\"name\"],\n                    \"args\": json.loads(tc[\"function\"][\"arguments\"])\n                    if isinstance(tc[\"function\"][\"arguments\"], str)\n                    else tc[\"function\"][\"arguments\"],\n                }\n                for tc in raw_tool_calls\n            ]\n\n        # Add usage_metadata for LangChain native usage tracking\n        if usage:\n            ai_kwargs[\"usage_metadata\"] = {\n                \"input_tokens\": usage.get(\"prompt_tokens\", 0),\n                \"output_tokens\": usage.get(\"completion_tokens\", 0),\n                \"total_tokens\": usage.get(\"total_tokens\", 0),\n            }\n\n        ai_message = AIMessage(**ai_kwargs)\n\n        return ChatResult(\n            generations=[\n                ChatGeneration(\n                    message=ai_message,\n                    generation_info={\n                        \"usage\": usage,\n                        \"model\": data.get(\"model\", str(self.model_ref)),\n                    },\n                )\n            ]\n        )\n\n    def _stream(\n        self,\n        messages: list[BaseMessage],\n        stop: list[str] | None = None,\n        run_manager: CallbackManagerForLLMRun | None = None,\n        **kwargs: Any,\n    ) -&gt; Iterator[ChatGenerationChunk]:\n        \"\"\"Stream chat completions from the gateway via SSE.\n\n        Sends a streaming request with ``\"stream\": true`` and yields\n        ``ChatGenerationChunk`` objects as SSE events arrive.\n\n        NOTE: Streaming quality depends on the proxy passing through SSE\n        events without buffering. If the proxy buffers, events will arrive\n        in batches rather than individually.\n\n        Args:\n            messages: LangChain message objects to send.\n            stop: Optional stop sequences.\n            run_manager: LangChain callback manager.\n\n        Yields:\n            ``ChatGenerationChunk`` for each SSE event.\n\n        Raises:\n            GatewayError: On HTTP errors or malformed responses.\n        \"\"\"\n        creds = self.gateway_client.get_credentials()\n        request_body = self._build_request_body(messages, stop, **kwargs)\n        request_body[\"stream\"] = True\n\n        headers = creds.auth_headers()\n        headers[\"X-Provider\"] = self.model_ref.provider\n\n        try:\n            line_iter = self.http_client.request_stream(\n                method=\"POST\",\n                path=\"/v1/chat/completions\",\n                headers=headers,\n                body=request_body,\n            )\n        except RateLimitError:\n            raise\n        except GatewayError:\n            raise\n        except Exception as e:\n            raise GatewayError(f\"Gateway stream failed: {e}\") from e\n\n        for raw_line in line_iter:\n            line = raw_line.decode(\"utf-8\", errors=\"replace\").strip()\n            if not line:\n                continue\n            if not line.startswith(\"data: \"):\n                continue\n            payload = line[len(\"data: \"):]\n            if payload == \"[DONE]\":\n                break\n            try:\n                event = json.loads(payload)\n            except json.JSONDecodeError:\n                continue\n\n            choices = event.get(\"choices\", [])\n            if not choices:\n                continue\n            delta = choices[0].get(\"delta\", {})\n            content = delta.get(\"content\", \"\")\n            if content:\n                chunk = ChatGenerationChunk(\n                    message=AIMessageChunk(content=content)\n                )\n                if run_manager:\n                    run_manager.on_llm_new_token(content, chunk=chunk)\n                yield chunk\n</code></pre>"},{"location":"api/llm/gateway_chat/#sage_sanctum.llm.gateway_chat.GatewayChatModel.with_structured_output","title":"<code>with_structured_output(schema: type[BaseModel], *, include_raw: bool = False, **kwargs: Any) -&gt; Runnable[LanguageModelInput, Any]</code>","text":"<p>Return a Runnable that produces structured Pydantic output.</p> <p>For OpenAI models, uses native JSON schema mode (<code>response_format.type = \"json_schema\"</code>).  For other providers, uses <code>json_object</code> mode and relies on the parser for validation.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>type[BaseModel]</code> <p>Pydantic model class to parse responses into.</p> required <code>include_raw</code> <code>bool</code> <p>If <code>True</code>, return a dict with <code>raw</code>, <code>parsed</code>, and <code>parsing_error</code> keys.</p> <code>False</code> <p>Returns:</p> Type Description <code>Runnable[LanguageModelInput, Any]</code> <p>A LangChain <code>Runnable</code> that yields <code>schema</code> instances (or</p> <code>Runnable[LanguageModelInput, Any]</code> <p>raw+parsed dicts when include_raw is set).</p> Source code in <code>src/sage_sanctum/llm/gateway_chat.py</code> <pre><code>def with_structured_output(\n    self,\n    schema: type[BaseModel],\n    *,\n    include_raw: bool = False,\n    **kwargs: Any,\n) -&gt; Runnable[LanguageModelInput, Any]:\n    \"\"\"Return a Runnable that produces structured Pydantic output.\n\n    For OpenAI models, uses native JSON schema mode\n    (``response_format.type = \"json_schema\"``).  For other providers,\n    uses ``json_object`` mode and relies on the parser for validation.\n\n    Args:\n        schema: Pydantic model class to parse responses into.\n        include_raw: If ``True``, return a dict with ``raw``, ``parsed``,\n            and ``parsing_error`` keys.\n\n    Returns:\n        A LangChain ``Runnable`` that yields ``schema`` instances (or\n        raw+parsed dicts when *include_raw* is set).\n    \"\"\"\n    parser = PydanticOutputParser(pydantic_object=schema)\n\n    if self.model_ref.provider == \"openai\":\n        json_schema = schema.model_json_schema()\n        _strip_schema_extras(json_schema)\n        response_format = {\n            \"type\": \"json_schema\",\n            \"json_schema\": {\n                \"name\": schema.__name__,\n                \"schema\": json_schema,\n                \"strict\": True,\n            },\n        }\n        llm = self.bind(response_format=response_format)\n    else:\n        llm = self.bind(response_format={\"type\": \"json_object\"})\n\n    if include_raw:\n        def _parse_with_raw(ai_message: AIMessage) -&gt; dict:\n            parsed = _safe_parse(parser, ai_message)\n            error = _safe_parse_error(parser, ai_message)\n            return {\"raw\": ai_message, \"parsed\": parsed, \"parsing_error\": error}\n\n        return llm | _parse_with_raw\n\n    return llm | parser\n</code></pre>"},{"location":"api/llm/gateway_chat/#sage_sanctum.llm.gateway_chat.create_llm_for_gateway","title":"<code>create_llm_for_gateway(model_ref: ModelRef, gateway_client: GatewayClient, temperature: float = 0.0) -&gt; BaseChatModel</code>","text":"<p>Create an LLM client appropriate for the current gateway mode.</p> <p>Parameters:</p> Name Type Description Default <code>model_ref</code> <code>ModelRef</code> <p>The model to use.</p> required <code>gateway_client</code> <code>GatewayClient</code> <p>Gateway client (determines gateway vs. direct mode).</p> required <code>temperature</code> <code>float</code> <p>Sampling temperature. Defaults to <code>0.0</code>.</p> <code>0.0</code> <p>Returns:</p> Type Description <code>BaseChatModel</code> <p><code>GatewayChatModel</code> when <code>gateway_client.is_gateway_mode</code> is <code>True</code>,</p> <code>BaseChatModel</code> <p><code>ChatLiteLLM</code> otherwise.</p> Source code in <code>src/sage_sanctum/llm/gateway_chat.py</code> <pre><code>def create_llm_for_gateway(\n    model_ref: ModelRef,\n    gateway_client: GatewayClient,\n    temperature: float = 0.0,\n) -&gt; BaseChatModel:\n    \"\"\"Create an LLM client appropriate for the current gateway mode.\n\n    Args:\n        model_ref: The model to use.\n        gateway_client: Gateway client (determines gateway vs. direct mode).\n        temperature: Sampling temperature. Defaults to ``0.0``.\n\n    Returns:\n        ``GatewayChatModel`` when ``gateway_client.is_gateway_mode`` is ``True``,\n        ``ChatLiteLLM`` otherwise.\n    \"\"\"\n    if gateway_client.is_gateway_mode:\n        # Determine connection method from endpoint\n        endpoint = gateway_client.get_endpoint(model_ref.provider)\n        if endpoint.startswith(\"unix://\"):\n            socket_path = endpoint[len(\"unix://\"):]\n            http_client = GatewayHttpClient(socket_path=socket_path)\n        else:\n            # Parse host:port from URL\n            from urllib.parse import urlparse\n\n            parsed = urlparse(endpoint)\n            http_client = GatewayHttpClient(\n                host=parsed.hostname or \"localhost\",\n                port=parsed.port or 8080,\n            )\n\n        return GatewayChatModel(\n            model_ref=model_ref,\n            gateway_client=gateway_client,\n            http_client=http_client,\n            temperature=temperature,\n        )\n    else:\n        # Direct mode \u2014 use ChatLiteLLM with API key\n        from ..gateway.client import DirectProviderClient\n\n        assert isinstance(gateway_client, DirectProviderClient)\n        api_key = gateway_client.get_api_key(model_ref.provider)\n\n        kwargs: dict[str, Any] = {\n            \"model\": model_ref.for_litellm,\n            \"temperature\": temperature,\n            \"api_key\": api_key,\n            \"streaming\": False,\n        }\n\n        endpoint = gateway_client.get_endpoint(model_ref.provider)\n        if not endpoint.startswith(\"https://api.\"):\n            kwargs[\"api_base\"] = endpoint\n\n        return ChatLiteLLM(**kwargs)\n</code></pre>"},{"location":"api/llm/model_category/","title":"sage_sanctum.llm.model_category","text":"<p>LLM usage categories for model selection.</p>"},{"location":"api/llm/model_category/#sage_sanctum.llm.model_category","title":"<code>sage_sanctum.llm.model_category</code>","text":"<p>Model categories for different agent tasks.</p>"},{"location":"api/llm/model_category/#sage_sanctum.llm.model_category.ModelCategory","title":"<code>ModelCategory</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Categories of LLM usage within an agent.</p> <p>Each category maps to a list of allowed models in the TraT's <code>tctx.allowed_models</code>. Use these when calling <code>AgentContext.create_llm_client()</code>.</p> <p>Attributes:</p> Name Type Description <code>TRIAGE</code> <p>Quick classification, routing, and filtering tasks. Typically uses a fast, inexpensive model (e.g. <code>gpt-4o-mini</code>).</p> <code>ANALYSIS</code> <p>Detailed code analysis and vulnerability detection. Typically uses a capable model (e.g. <code>gpt-4o</code>).</p> <code>REASONING</code> <p>Complex multi-step reasoning tasks. Typically uses a reasoning model (e.g. <code>o1</code>).</p> <code>EMBEDDINGS</code> <p>Embedding generation for similarity search. Typically uses an embedding model (e.g. <code>text-embedding-3-small</code>).</p> Source code in <code>src/sage_sanctum/llm/model_category.py</code> <pre><code>class ModelCategory(StrEnum):\n    \"\"\"Categories of LLM usage within an agent.\n\n    Each category maps to a list of allowed models in the TraT's\n    ``tctx.allowed_models``. Use these when calling\n    ``AgentContext.create_llm_client()``.\n\n    Attributes:\n        TRIAGE: Quick classification, routing, and filtering tasks.\n            Typically uses a fast, inexpensive model (e.g. ``gpt-4o-mini``).\n        ANALYSIS: Detailed code analysis and vulnerability detection.\n            Typically uses a capable model (e.g. ``gpt-4o``).\n        REASONING: Complex multi-step reasoning tasks.\n            Typically uses a reasoning model (e.g. ``o1``).\n        EMBEDDINGS: Embedding generation for similarity search.\n            Typically uses an embedding model (e.g. ``text-embedding-3-small``).\n    \"\"\"\n\n    TRIAGE = \"triage\"\n    ANALYSIS = \"analysis\"\n    REASONING = \"reasoning\"\n    EMBEDDINGS = \"embeddings\"\n</code></pre>"},{"location":"api/llm/model_ref/","title":"sage_sanctum.llm.model_ref","text":"<p>Canonical model references in <code>provider:model</code> format with auto-detection and LiteLLM formatting.</p>"},{"location":"api/llm/model_ref/#sage_sanctum.llm.model_ref","title":"<code>sage_sanctum.llm.model_ref</code>","text":"<p>ModelRef: Canonical model identifier in provider:model format.</p>"},{"location":"api/llm/model_ref/#sage_sanctum.llm.model_ref.ModelRef","title":"<code>ModelRef</code>  <code>dataclass</code>","text":"<p>Canonical reference to an LLM model.</p> <p>Format: <code>provider:model</code> (e.g. <code>\"openai:gpt-4o\"</code>, <code>\"anthropic:claude-3-5-sonnet-latest\"</code>).</p> <p>Immutable and hashable \u2014 safe to use as dict keys and in sets.</p> <p>Attributes:</p> Name Type Description <code>provider</code> <code>str</code> <p>Provider name (<code>\"openai\"</code>, <code>\"anthropic\"</code>, or <code>\"google\"</code>).</p> <code>model</code> <code>str</code> <p>Model name (e.g. <code>\"gpt-4o\"</code>, <code>\"claude-3-5-sonnet-latest\"</code>).</p> Example <pre><code>ref = ModelRef.parse(\"openai:gpt-4o\")\nref.provider    # \"openai\"\nref.model       # \"gpt-4o\"\nref.for_litellm # \"gpt-4o\"\nstr(ref)        # \"openai:gpt-4o\"\n</code></pre> Source code in <code>src/sage_sanctum/llm/model_ref.py</code> <pre><code>@dataclass(frozen=True)\nclass ModelRef:\n    \"\"\"Canonical reference to an LLM model.\n\n    Format: ``provider:model`` (e.g. ``\"openai:gpt-4o\"``,\n    ``\"anthropic:claude-3-5-sonnet-latest\"``).\n\n    Immutable and hashable \u2014 safe to use as dict keys and in sets.\n\n    Attributes:\n        provider: Provider name (``\"openai\"``, ``\"anthropic\"``, or ``\"google\"``).\n        model: Model name (e.g. ``\"gpt-4o\"``, ``\"claude-3-5-sonnet-latest\"``).\n\n    Example:\n        ```python\n        ref = ModelRef.parse(\"openai:gpt-4o\")\n        ref.provider    # \"openai\"\n        ref.model       # \"gpt-4o\"\n        ref.for_litellm # \"gpt-4o\"\n        str(ref)        # \"openai:gpt-4o\"\n        ```\n    \"\"\"\n\n    provider: str\n    model: str\n\n    @classmethod\n    def parse(cls, ref: str) -&gt; ModelRef:\n        \"\"\"Parse a model reference string.\n\n        Accepts two formats:\n\n        - ``\"provider:model\"`` \u2014 explicit provider.\n        - ``\"model\"`` \u2014 provider auto-detected from model name prefix\n          (``claude*`` \u2192 anthropic, ``gemini*`` \u2192 google, else openai).\n\n        Args:\n            ref: Model reference string to parse.\n\n        Returns:\n            Parsed ``ModelRef`` instance.\n\n        Raises:\n            ModelRefParseError: If the reference is empty or invalid.\n        \"\"\"\n        if not ref or not ref.strip():\n            raise ModelRefParseError(\"Model reference cannot be empty\")\n\n        ref = ref.strip()\n\n        if \":\" in ref:\n            parts = ref.split(\":\", 1)\n            provider = parts[0].strip().lower()\n            model = parts[1].strip()\n            if not provider:\n                raise ModelRefParseError(f\"Empty provider in model reference: {ref!r}\")\n            if not model:\n                raise ModelRefParseError(f\"Empty model in model reference: {ref!r}\")\n            return cls(provider=provider, model=model)\n\n        # Auto-detect provider from model name\n        provider = _detect_provider(ref)\n        return cls(provider=provider, model=ref)\n\n    @property\n    def for_litellm(self) -&gt; str:\n        \"\"\"Format the model name for LiteLLM routing.\n\n        LiteLLM requires provider prefixes for non-OpenAI models:\n\n        - ``\"anthropic/claude-3-5-sonnet\"`` \u2192 Anthropic routing\n        - ``\"gemini/gemini-2.0-flash\"`` \u2192 Google AI Studio routing\n        - ``\"gpt-4o\"`` \u2192 OpenAI (no prefix needed)\n\n        Returns:\n            Model string suitable for ``ChatLiteLLM(model=...)``.\n        \"\"\"\n        if self.provider == \"anthropic\":\n            if self.model.startswith(\"anthropic/\"):\n                return self.model\n            return f\"anthropic/{self.model}\"\n        if self.provider == \"google\":\n            if self.model.startswith(\"gemini/\"):\n                return self.model\n            return f\"gemini/{self.model}\"\n        return self.model\n\n    def __str__(self) -&gt; str:\n        return f\"{self.provider}:{self.model}\"\n\n    def __repr__(self) -&gt; str:\n        return f\"ModelRef(provider={self.provider!r}, model={self.model!r})\"\n</code></pre>"},{"location":"api/llm/model_ref/#sage_sanctum.llm.model_ref.ModelRef.for_litellm","title":"<code>for_litellm: str</code>  <code>property</code>","text":"<p>Format the model name for LiteLLM routing.</p> <p>LiteLLM requires provider prefixes for non-OpenAI models:</p> <ul> <li><code>\"anthropic/claude-3-5-sonnet\"</code> \u2192 Anthropic routing</li> <li><code>\"gemini/gemini-2.0-flash\"</code> \u2192 Google AI Studio routing</li> <li><code>\"gpt-4o\"</code> \u2192 OpenAI (no prefix needed)</li> </ul> <p>Returns:</p> Type Description <code>str</code> <p>Model string suitable for <code>ChatLiteLLM(model=...)</code>.</p>"},{"location":"api/llm/model_ref/#sage_sanctum.llm.model_ref.ModelRef.parse","title":"<code>parse(ref: str) -&gt; ModelRef</code>  <code>classmethod</code>","text":"<p>Parse a model reference string.</p> <p>Accepts two formats:</p> <ul> <li><code>\"provider:model\"</code> \u2014 explicit provider.</li> <li><code>\"model\"</code> \u2014 provider auto-detected from model name prefix   (<code>claude*</code> \u2192 anthropic, <code>gemini*</code> \u2192 google, else openai).</li> </ul> <p>Parameters:</p> Name Type Description Default <code>ref</code> <code>str</code> <p>Model reference string to parse.</p> required <p>Returns:</p> Type Description <code>ModelRef</code> <p>Parsed <code>ModelRef</code> instance.</p> <p>Raises:</p> Type Description <code>ModelRefParseError</code> <p>If the reference is empty or invalid.</p> Source code in <code>src/sage_sanctum/llm/model_ref.py</code> <pre><code>@classmethod\ndef parse(cls, ref: str) -&gt; ModelRef:\n    \"\"\"Parse a model reference string.\n\n    Accepts two formats:\n\n    - ``\"provider:model\"`` \u2014 explicit provider.\n    - ``\"model\"`` \u2014 provider auto-detected from model name prefix\n      (``claude*`` \u2192 anthropic, ``gemini*`` \u2192 google, else openai).\n\n    Args:\n        ref: Model reference string to parse.\n\n    Returns:\n        Parsed ``ModelRef`` instance.\n\n    Raises:\n        ModelRefParseError: If the reference is empty or invalid.\n    \"\"\"\n    if not ref or not ref.strip():\n        raise ModelRefParseError(\"Model reference cannot be empty\")\n\n    ref = ref.strip()\n\n    if \":\" in ref:\n        parts = ref.split(\":\", 1)\n        provider = parts[0].strip().lower()\n        model = parts[1].strip()\n        if not provider:\n            raise ModelRefParseError(f\"Empty provider in model reference: {ref!r}\")\n        if not model:\n            raise ModelRefParseError(f\"Empty model in model reference: {ref!r}\")\n        return cls(provider=provider, model=model)\n\n    # Auto-detect provider from model name\n    provider = _detect_provider(ref)\n    return cls(provider=provider, model=ref)\n</code></pre>"},{"location":"api/llm/model_selector/","title":"sage_sanctum.llm.model_selector","text":"<p>Model selection based on TraT allowlists.</p>"},{"location":"api/llm/model_selector/#sage_sanctum.llm.model_selector","title":"<code>sage_sanctum.llm.model_selector</code>","text":"<p>Model selection based on TraT allowed_models.</p>"},{"location":"api/llm/model_selector/#sage_sanctum.llm.model_selector.ModelSelector","title":"<code>ModelSelector</code>","text":"<p>Selects models based on TraT allowed_models configuration.</p> <p>The TraT's tctx.allowed_models contains lists of ModelRef strings per category. This selector returns the first (preferred) model for a given category.</p> Source code in <code>src/sage_sanctum/llm/model_selector.py</code> <pre><code>class ModelSelector:\n    \"\"\"Selects models based on TraT allowed_models configuration.\n\n    The TraT's tctx.allowed_models contains lists of ModelRef strings per category.\n    This selector returns the first (preferred) model for a given category.\n    \"\"\"\n\n    def __init__(self, allowed_models: dict[str, list[str]]) -&gt; None:\n        \"\"\"Initialize with a per-category model allowlist.\n\n        Args:\n            allowed_models: Dictionary mapping category names (e.g.\n                ``\"analysis\"``) to lists of ``provider:model`` strings.\n                Typically sourced from the TraT's ``tctx.allowed_models``.\n        \"\"\"\n        self._allowed: dict[str, list[ModelRef]] = {}\n        for category, refs in allowed_models.items():\n            self._allowed[category] = [ModelRef.parse(r) for r in refs]\n\n    def select(self, category: ModelCategory) -&gt; ModelRef:\n        \"\"\"Select the preferred model for the given category.\n\n        Returns the first model in the allowed list for the category.\n\n        Raises:\n            ModelNotAvailableError: If no models are configured for the category.\n        \"\"\"\n        models = self._allowed.get(category.value, [])\n        if not models:\n            raise ModelNotAvailableError(\n                f\"No models configured for category {category.value!r}\"\n            )\n        return models[0]\n\n    def select_all(self, category: ModelCategory) -&gt; list[ModelRef]:\n        \"\"\"Return all allowed models for the given category.\n\n        Args:\n            category: Model category to query.\n\n        Returns:\n            List of allowed ``ModelRef`` instances (may be empty).\n        \"\"\"\n        return list(self._allowed.get(category.value, []))\n\n    def is_allowed(self, model: ModelRef, category: ModelCategory) -&gt; bool:\n        \"\"\"Check if a specific model is allowed for a category.\n\n        Args:\n            model: The model to check.\n            category: The category to check against.\n\n        Returns:\n            ``True`` if the model is in the allowlist for the category.\n        \"\"\"\n        return model in self._allowed.get(category.value, [])\n\n    def validate_model(self, model: ModelRef, category: ModelCategory) -&gt; None:\n        \"\"\"Validate that a model is allowed for the category.\n\n        Raises:\n            ModelNotAuthorizedError: If the model is not in allowed_models.\n        \"\"\"\n        if not self.is_allowed(model, category):\n            raise ModelNotAuthorizedError(\n                f\"Model {model} not authorized for category {category.value!r}. \"\n                f\"Allowed: {self.select_all(category)}\"\n            )\n</code></pre>"},{"location":"api/llm/model_selector/#sage_sanctum.llm.model_selector.ModelSelector.__init__","title":"<code>__init__(allowed_models: dict[str, list[str]]) -&gt; None</code>","text":"<p>Initialize with a per-category model allowlist.</p> <p>Parameters:</p> Name Type Description Default <code>allowed_models</code> <code>dict[str, list[str]]</code> <p>Dictionary mapping category names (e.g. <code>\"analysis\"</code>) to lists of <code>provider:model</code> strings. Typically sourced from the TraT's <code>tctx.allowed_models</code>.</p> required Source code in <code>src/sage_sanctum/llm/model_selector.py</code> <pre><code>def __init__(self, allowed_models: dict[str, list[str]]) -&gt; None:\n    \"\"\"Initialize with a per-category model allowlist.\n\n    Args:\n        allowed_models: Dictionary mapping category names (e.g.\n            ``\"analysis\"``) to lists of ``provider:model`` strings.\n            Typically sourced from the TraT's ``tctx.allowed_models``.\n    \"\"\"\n    self._allowed: dict[str, list[ModelRef]] = {}\n    for category, refs in allowed_models.items():\n        self._allowed[category] = [ModelRef.parse(r) for r in refs]\n</code></pre>"},{"location":"api/llm/model_selector/#sage_sanctum.llm.model_selector.ModelSelector.select","title":"<code>select(category: ModelCategory) -&gt; ModelRef</code>","text":"<p>Select the preferred model for the given category.</p> <p>Returns the first model in the allowed list for the category.</p> <p>Raises:</p> Type Description <code>ModelNotAvailableError</code> <p>If no models are configured for the category.</p> Source code in <code>src/sage_sanctum/llm/model_selector.py</code> <pre><code>def select(self, category: ModelCategory) -&gt; ModelRef:\n    \"\"\"Select the preferred model for the given category.\n\n    Returns the first model in the allowed list for the category.\n\n    Raises:\n        ModelNotAvailableError: If no models are configured for the category.\n    \"\"\"\n    models = self._allowed.get(category.value, [])\n    if not models:\n        raise ModelNotAvailableError(\n            f\"No models configured for category {category.value!r}\"\n        )\n    return models[0]\n</code></pre>"},{"location":"api/llm/model_selector/#sage_sanctum.llm.model_selector.ModelSelector.select_all","title":"<code>select_all(category: ModelCategory) -&gt; list[ModelRef]</code>","text":"<p>Return all allowed models for the given category.</p> <p>Parameters:</p> Name Type Description Default <code>category</code> <code>ModelCategory</code> <p>Model category to query.</p> required <p>Returns:</p> Type Description <code>list[ModelRef]</code> <p>List of allowed <code>ModelRef</code> instances (may be empty).</p> Source code in <code>src/sage_sanctum/llm/model_selector.py</code> <pre><code>def select_all(self, category: ModelCategory) -&gt; list[ModelRef]:\n    \"\"\"Return all allowed models for the given category.\n\n    Args:\n        category: Model category to query.\n\n    Returns:\n        List of allowed ``ModelRef`` instances (may be empty).\n    \"\"\"\n    return list(self._allowed.get(category.value, []))\n</code></pre>"},{"location":"api/llm/model_selector/#sage_sanctum.llm.model_selector.ModelSelector.is_allowed","title":"<code>is_allowed(model: ModelRef, category: ModelCategory) -&gt; bool</code>","text":"<p>Check if a specific model is allowed for a category.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>ModelRef</code> <p>The model to check.</p> required <code>category</code> <code>ModelCategory</code> <p>The category to check against.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the model is in the allowlist for the category.</p> Source code in <code>src/sage_sanctum/llm/model_selector.py</code> <pre><code>def is_allowed(self, model: ModelRef, category: ModelCategory) -&gt; bool:\n    \"\"\"Check if a specific model is allowed for a category.\n\n    Args:\n        model: The model to check.\n        category: The category to check against.\n\n    Returns:\n        ``True`` if the model is in the allowlist for the category.\n    \"\"\"\n    return model in self._allowed.get(category.value, [])\n</code></pre>"},{"location":"api/llm/model_selector/#sage_sanctum.llm.model_selector.ModelSelector.validate_model","title":"<code>validate_model(model: ModelRef, category: ModelCategory) -&gt; None</code>","text":"<p>Validate that a model is allowed for the category.</p> <p>Raises:</p> Type Description <code>ModelNotAuthorizedError</code> <p>If the model is not in allowed_models.</p> Source code in <code>src/sage_sanctum/llm/model_selector.py</code> <pre><code>def validate_model(self, model: ModelRef, category: ModelCategory) -&gt; None:\n    \"\"\"Validate that a model is allowed for the category.\n\n    Raises:\n        ModelNotAuthorizedError: If the model is not in allowed_models.\n    \"\"\"\n    if not self.is_allowed(model, category):\n        raise ModelNotAuthorizedError(\n            f\"Model {model} not authorized for category {category.value!r}. \"\n            f\"Allowed: {self.select_all(category)}\"\n        )\n</code></pre>"},{"location":"api/llm/model_selector/#sage_sanctum.llm.model_selector.StaticModelSelector","title":"<code>StaticModelSelector</code>","text":"<p>               Bases: <code>ModelSelector</code></p> <p>Simple selector that returns the same model for all categories.</p> <p>Useful for local development where a single model is used.</p> Source code in <code>src/sage_sanctum/llm/model_selector.py</code> <pre><code>class StaticModelSelector(ModelSelector):\n    \"\"\"Simple selector that returns the same model for all categories.\n\n    Useful for local development where a single model is used.\n    \"\"\"\n\n    def __init__(self, model: str | ModelRef) -&gt; None:\n        \"\"\"Initialize with a single model used for all categories.\n\n        Args:\n            model: Model reference string or ``ModelRef`` instance.\n        \"\"\"\n        if isinstance(model, str):\n            model = ModelRef.parse(model)\n        self._model = model\n        # Build allowed_models with this model for all categories\n        ref_str = str(model)\n        super().__init__({\n            cat.value: [ref_str] for cat in ModelCategory\n        })\n\n    def select(self, category: ModelCategory) -&gt; ModelRef:\n        \"\"\"Always returns the static model, regardless of category.\"\"\"\n        return self._model\n</code></pre>"},{"location":"api/llm/model_selector/#sage_sanctum.llm.model_selector.StaticModelSelector.__init__","title":"<code>__init__(model: str | ModelRef) -&gt; None</code>","text":"<p>Initialize with a single model used for all categories.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str | ModelRef</code> <p>Model reference string or <code>ModelRef</code> instance.</p> required Source code in <code>src/sage_sanctum/llm/model_selector.py</code> <pre><code>def __init__(self, model: str | ModelRef) -&gt; None:\n    \"\"\"Initialize with a single model used for all categories.\n\n    Args:\n        model: Model reference string or ``ModelRef`` instance.\n    \"\"\"\n    if isinstance(model, str):\n        model = ModelRef.parse(model)\n    self._model = model\n    # Build allowed_models with this model for all categories\n    ref_str = str(model)\n    super().__init__({\n        cat.value: [ref_str] for cat in ModelCategory\n    })\n</code></pre>"},{"location":"api/llm/model_selector/#sage_sanctum.llm.model_selector.StaticModelSelector.select","title":"<code>select(category: ModelCategory) -&gt; ModelRef</code>","text":"<p>Always returns the static model, regardless of category.</p> Source code in <code>src/sage_sanctum/llm/model_selector.py</code> <pre><code>def select(self, category: ModelCategory) -&gt; ModelRef:\n    \"\"\"Always returns the static model, regardless of category.\"\"\"\n    return self._model\n</code></pre>"},{"location":"api/mcp/","title":"sage_sanctum.mcp","text":"<p>MCP (Model Context Protocol) tool client for invoking external tools via the MCP gateway.</p> <p>Not Yet Implemented</p> <p>The MCP module is a placeholder. The <code>invoke_tool</code> method raises <code>NotImplementedError</code> pending MCP gateway implementation.</p>"},{"location":"api/mcp/#modules","title":"Modules","text":"Module Description <code>client</code> <code>MCPGatewayClient</code> \u2014 MCP tool invocation (placeholder)"},{"location":"api/mcp/client/","title":"sage_sanctum.mcp.client","text":"<p>MCP gateway client for tool invocation (placeholder \u2014 not yet implemented).</p>"},{"location":"api/mcp/client/#sage_sanctum.mcp.client","title":"<code>sage_sanctum.mcp.client</code>","text":"<p>MCP Gateway Client stub \u2014 NOT YET AVAILABLE.</p> <p>This module is a placeholder for future MCP tool invocation via the MCP gateway socket. It is intentionally excluded from the public API (not exported from <code>sage_sanctum</code> or <code>sage_sanctum.mcp</code>).</p> <p>Do not depend on this interface; it will change when the MCP gateway is implemented.</p>"},{"location":"api/mcp/client/#sage_sanctum.mcp.client.MCPGatewayClient","title":"<code>MCPGatewayClient</code>","text":"<p>Client for invoking MCP tools via the MCP gateway.</p> <p>This is a placeholder implementation. The MCP gateway routes tool invocations to appropriate MCP servers with Topaz authorization.</p> Source code in <code>src/sage_sanctum/mcp/client.py</code> <pre><code>class MCPGatewayClient:\n    \"\"\"Client for invoking MCP tools via the MCP gateway.\n\n    This is a placeholder implementation. The MCP gateway routes tool\n    invocations to appropriate MCP servers with Topaz authorization.\n    \"\"\"\n\n    def __init__(self, socket_path: str | None = None) -&gt; None:\n        self._socket_path = socket_path\n\n    async def invoke_tool(\n        self,\n        server: str,\n        tool: str,\n        arguments: dict[str, Any] | None = None,\n    ) -&gt; dict[str, Any]:\n        \"\"\"Invoke an MCP tool via the gateway.\n\n        Args:\n            server: MCP server name (e.g., 'file_tools', 'git_tools')\n            tool: Tool name (e.g., 'file_read', 'git_log')\n            arguments: Tool arguments\n\n        Returns:\n            Tool result as a dictionary.\n\n        Raises:\n            NotImplementedError: MCP gateway integration pending.\n        \"\"\"\n        raise NotImplementedError(\n            \"MCP gateway integration is not yet implemented. \"\n            f\"Attempted to invoke {server}/{tool}\"\n        )\n</code></pre>"},{"location":"api/mcp/client/#sage_sanctum.mcp.client.MCPGatewayClient.invoke_tool","title":"<code>invoke_tool(server: str, tool: str, arguments: dict[str, Any] | None = None) -&gt; dict[str, Any]</code>  <code>async</code>","text":"<p>Invoke an MCP tool via the gateway.</p> <p>Parameters:</p> Name Type Description Default <code>server</code> <code>str</code> <p>MCP server name (e.g., 'file_tools', 'git_tools')</p> required <code>tool</code> <code>str</code> <p>Tool name (e.g., 'file_read', 'git_log')</p> required <code>arguments</code> <code>dict[str, Any] | None</code> <p>Tool arguments</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Tool result as a dictionary.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>MCP gateway integration pending.</p> Source code in <code>src/sage_sanctum/mcp/client.py</code> <pre><code>async def invoke_tool(\n    self,\n    server: str,\n    tool: str,\n    arguments: dict[str, Any] | None = None,\n) -&gt; dict[str, Any]:\n    \"\"\"Invoke an MCP tool via the gateway.\n\n    Args:\n        server: MCP server name (e.g., 'file_tools', 'git_tools')\n        tool: Tool name (e.g., 'file_read', 'git_log')\n        arguments: Tool arguments\n\n    Returns:\n        Tool result as a dictionary.\n\n    Raises:\n        NotImplementedError: MCP gateway integration pending.\n    \"\"\"\n    raise NotImplementedError(\n        \"MCP gateway integration is not yet implemented. \"\n        f\"Attempted to invoke {server}/{tool}\"\n    )\n</code></pre>"},{"location":"api/testing/","title":"sage_sanctum.testing","text":"<p>Mock implementations and pytest fixtures for unit testing agents.</p>"},{"location":"api/testing/#modules","title":"Modules","text":"Module Description <code>fixtures</code> Pytest fixtures: <code>mock_gateway</code>, <code>sample_trat</code>, <code>mock_context</code> <code>mocks</code> <code>MockGatewayClient</code>, <code>MockLLM</code>, <code>MockTratClient</code>"},{"location":"api/testing/fixtures/","title":"sage_sanctum.testing.fixtures","text":"<p>Ready-made pytest fixtures for agent testing.</p>"},{"location":"api/testing/fixtures/#sage_sanctum.testing.fixtures","title":"<code>sage_sanctum.testing.fixtures</code>","text":"<p>Pytest fixtures for testing Sage Sanctum agents.</p>"},{"location":"api/testing/fixtures/#sage_sanctum.testing.fixtures.mock_gateway","title":"<code>mock_gateway() -&gt; MockGatewayClient</code>","text":"<p>Pytest fixture providing a <code>MockGatewayClient</code> in direct mode.</p> <p>Returns:</p> Type Description <code>MockGatewayClient</code> <p>A <code>MockGatewayClient</code> with <code>is_gateway=False</code> and</p> <code>MockGatewayClient</code> <p>localhost endpoints.</p> Source code in <code>src/sage_sanctum/testing/fixtures.py</code> <pre><code>@pytest.fixture\ndef mock_gateway() -&gt; MockGatewayClient:\n    \"\"\"Pytest fixture providing a ``MockGatewayClient`` in direct mode.\n\n    Returns:\n        A ``MockGatewayClient`` with ``is_gateway=False`` and\n        localhost endpoints.\n    \"\"\"\n    return MockGatewayClient(is_gateway=False)\n</code></pre>"},{"location":"api/testing/fixtures/#sage_sanctum.testing.fixtures.sample_trat","title":"<code>sample_trat() -&gt; TransactionToken</code>","text":"<p>Pytest fixture providing a <code>TransactionToken</code> with standard models.</p> <p>Default allowlists: gpt-4o-mini (triage), gpt-4o + claude-3-5-sonnet (analysis), o1 (reasoning), text-embedding-3-small (embeddings).</p> <p>Returns:</p> Type Description <code>TransactionToken</code> <p>A non-expired <code>TransactionToken</code> with mock claims.</p> Source code in <code>src/sage_sanctum/testing/fixtures.py</code> <pre><code>@pytest.fixture\ndef sample_trat() -&gt; TransactionToken:\n    \"\"\"Pytest fixture providing a ``TransactionToken`` with standard models.\n\n    Default allowlists: gpt-4o-mini (triage), gpt-4o + claude-3-5-sonnet\n    (analysis), o1 (reasoning), text-embedding-3-small (embeddings).\n\n    Returns:\n        A non-expired ``TransactionToken`` with mock claims.\n    \"\"\"\n    client = MockTratClient()\n    return client.get_token()\n</code></pre>"},{"location":"api/testing/fixtures/#sage_sanctum.testing.fixtures.mock_context","title":"<code>mock_context(tmp_path: Path, mock_gateway: MockGatewayClient) -&gt; AgentContext</code>","text":"<p>Pytest fixture providing a fully configured <code>AgentContext</code>.</p> <p>Uses <code>tmp_path</code> for work/output directories, a <code>MockGatewayClient</code>, and a <code>StaticModelSelector</code> fixed on <code>gpt-4o</code>.</p> <p>Returns:</p> Type Description <code>AgentContext</code> <p>An <code>AgentContext</code> ready for agent instantiation in tests.</p> Source code in <code>src/sage_sanctum/testing/fixtures.py</code> <pre><code>@pytest.fixture\ndef mock_context(tmp_path: Path, mock_gateway: MockGatewayClient) -&gt; AgentContext:\n    \"\"\"Pytest fixture providing a fully configured ``AgentContext``.\n\n    Uses ``tmp_path`` for work/output directories, a ``MockGatewayClient``,\n    and a ``StaticModelSelector`` fixed on ``gpt-4o``.\n\n    Returns:\n        An ``AgentContext`` ready for agent instantiation in tests.\n    \"\"\"\n    return AgentContext(\n        run_id=\"test-run-123\",\n        org_id=\"test-org\",\n        work_dir=tmp_path / \"work\",\n        output_dir=tmp_path / \"output\",\n        gateway_client=mock_gateway,\n        model_selector=StaticModelSelector(\"gpt-4o\"),\n        logger=get_logger(\"test\"),\n    )\n</code></pre>"},{"location":"api/testing/mocks/","title":"sage_sanctum.testing.mocks","text":"<p>Mock implementations of gateway client, LLM, and Transaction Token client.</p>"},{"location":"api/testing/mocks/#sage_sanctum.testing.mocks","title":"<code>sage_sanctum.testing.mocks</code>","text":"<p>Mock implementations for testing Sage Sanctum agents.</p>"},{"location":"api/testing/mocks/#sage_sanctum.testing.mocks.MockGatewayClient","title":"<code>MockGatewayClient</code>","text":"<p>               Bases: <code>GatewayClient</code></p> <p>Mock gateway client for testing.</p> <p>Returns configurable credentials and endpoints without any real network or authentication dependencies.</p> <p>Parameters:</p> Name Type Description Default <code>is_gateway</code> <code>bool</code> <p>Whether to simulate gateway mode. Defaults to <code>False</code>.</p> <code>False</code> <code>endpoints</code> <code>dict[str, str] | None</code> <p>Provider \u2192 URL mapping. Defaults to localhost endpoints.</p> <code>None</code> <code>trat</code> <code>TransactionToken | None</code> <p>Optional <code>TransactionToken</code> to return from <code>get_trat()</code>.</p> <code>None</code> Example <pre><code>client = MockGatewayClient(is_gateway=True)\ncreds = client.get_credentials()\nassert creds.spiffe_jwt == \"mock-spiffe-jwt\"\n</code></pre> Source code in <code>src/sage_sanctum/testing/mocks.py</code> <pre><code>class MockGatewayClient(GatewayClient):\n    \"\"\"Mock gateway client for testing.\n\n    Returns configurable credentials and endpoints without any real\n    network or authentication dependencies.\n\n    Args:\n        is_gateway: Whether to simulate gateway mode. Defaults to ``False``.\n        endpoints: Provider \u2192 URL mapping. Defaults to localhost endpoints.\n        trat: Optional ``TransactionToken`` to return from ``get_trat()``.\n\n    Example:\n        ```python\n        client = MockGatewayClient(is_gateway=True)\n        creds = client.get_credentials()\n        assert creds.spiffe_jwt == \"mock-spiffe-jwt\"\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        is_gateway: bool = False,\n        endpoints: dict[str, str] | None = None,\n        trat: TransactionToken | None = None,\n    ) -&gt; None:\n        self._is_gateway = is_gateway\n        self._endpoints = endpoints or {\n            \"openai\": \"http://localhost:8080/v1\",\n            \"anthropic\": \"http://localhost:8080/anthropic\",\n            \"google\": \"http://localhost:8080/google\",\n        }\n        self._trat = trat\n\n    def get_credentials(self) -&gt; GatewayCredentials:\n        \"\"\"Return mock credentials (``\"mock-spiffe-jwt\"`` / ``\"mock-trat-jwt\"``).\"\"\"\n        return GatewayCredentials(\n            spiffe_jwt=\"mock-spiffe-jwt\",\n            trat=\"mock-trat-jwt\",\n        )\n\n    def get_endpoint(self, provider: str) -&gt; str:\n        \"\"\"Return the mock endpoint URL for a provider.\"\"\"\n        return self._endpoints.get(provider, \"http://localhost:8080/v1\")\n\n    @property\n    def is_gateway_mode(self) -&gt; bool:\n        \"\"\"Whether gateway mode is simulated.\"\"\"\n        return self._is_gateway\n\n    def get_trat(self) -&gt; TransactionToken | None:\n        \"\"\"Return the configured mock TraT, or ``None``.\"\"\"\n        return self._trat\n</code></pre>"},{"location":"api/testing/mocks/#sage_sanctum.testing.mocks.MockGatewayClient.is_gateway_mode","title":"<code>is_gateway_mode: bool</code>  <code>property</code>","text":"<p>Whether gateway mode is simulated.</p>"},{"location":"api/testing/mocks/#sage_sanctum.testing.mocks.MockGatewayClient.get_credentials","title":"<code>get_credentials() -&gt; GatewayCredentials</code>","text":"<p>Return mock credentials (<code>\"mock-spiffe-jwt\"</code> / <code>\"mock-trat-jwt\"</code>).</p> Source code in <code>src/sage_sanctum/testing/mocks.py</code> <pre><code>def get_credentials(self) -&gt; GatewayCredentials:\n    \"\"\"Return mock credentials (``\"mock-spiffe-jwt\"`` / ``\"mock-trat-jwt\"``).\"\"\"\n    return GatewayCredentials(\n        spiffe_jwt=\"mock-spiffe-jwt\",\n        trat=\"mock-trat-jwt\",\n    )\n</code></pre>"},{"location":"api/testing/mocks/#sage_sanctum.testing.mocks.MockGatewayClient.get_endpoint","title":"<code>get_endpoint(provider: str) -&gt; str</code>","text":"<p>Return the mock endpoint URL for a provider.</p> Source code in <code>src/sage_sanctum/testing/mocks.py</code> <pre><code>def get_endpoint(self, provider: str) -&gt; str:\n    \"\"\"Return the mock endpoint URL for a provider.\"\"\"\n    return self._endpoints.get(provider, \"http://localhost:8080/v1\")\n</code></pre>"},{"location":"api/testing/mocks/#sage_sanctum.testing.mocks.MockGatewayClient.get_trat","title":"<code>get_trat() -&gt; TransactionToken | None</code>","text":"<p>Return the configured mock TraT, or <code>None</code>.</p> Source code in <code>src/sage_sanctum/testing/mocks.py</code> <pre><code>def get_trat(self) -&gt; TransactionToken | None:\n    \"\"\"Return the configured mock TraT, or ``None``.\"\"\"\n    return self._trat\n</code></pre>"},{"location":"api/testing/mocks/#sage_sanctum.testing.mocks.MockLLM","title":"<code>MockLLM</code>","text":"<p>               Bases: <code>BaseChatModel</code></p> <p>Mock LangChain chat model for testing.</p> <p>Returns canned responses in order and records every call for assertion.</p> <p>Attributes:</p> Name Type Description <code>responses</code> <code>list[str]</code> <p>Ordered list of response strings to return. When exhausted, returns <code>\"Mock response\"</code>.</p> <code>calls</code> <code>list[list[BaseMessage]]</code> <p>List of message lists received \u2014 one entry per <code>invoke()</code> call.</p> Example <pre><code>llm = MockLLM(responses=[\"Finding: SQL injection\", \"No issues\"])\nr1 = llm.invoke([...])  # \"Finding: SQL injection\"\nr2 = llm.invoke([...])  # \"No issues\"\nassert len(llm.calls) == 2\n</code></pre> Source code in <code>src/sage_sanctum/testing/mocks.py</code> <pre><code>class MockLLM(BaseChatModel):\n    \"\"\"Mock LangChain chat model for testing.\n\n    Returns canned responses in order and records every call for assertion.\n\n    Attributes:\n        responses: Ordered list of response strings to return.\n            When exhausted, returns ``\"Mock response\"``.\n        calls: List of message lists received \u2014 one entry per ``invoke()`` call.\n\n    Example:\n        ```python\n        llm = MockLLM(responses=[\"Finding: SQL injection\", \"No issues\"])\n        r1 = llm.invoke([...])  # \"Finding: SQL injection\"\n        r2 = llm.invoke([...])  # \"No issues\"\n        assert len(llm.calls) == 2\n        ```\n    \"\"\"\n\n    responses: list[str] = []\n    calls: list[list[BaseMessage]] = []\n    _call_index: int = 0\n\n    model_config = {\"arbitrary_types_allowed\": True}\n\n    def __init__(self, responses: list[str] | None = None, **kwargs: Any):\n        \"\"\"Initialize the mock LLM.\n\n        Args:\n            responses: Canned responses to return in order. If ``None``,\n                every call returns ``\"Mock response\"``.\n        \"\"\"\n        super().__init__(**kwargs)\n        if responses:\n            self.responses = responses\n        self.calls = []\n        self._call_index = 0\n\n    @property\n    def _llm_type(self) -&gt; str:\n        return \"mock\"\n\n    def _generate(\n        self,\n        messages: list[BaseMessage],\n        stop: list[str] | None = None,\n        run_manager: Any = None,\n        **kwargs: Any,\n    ) -&gt; ChatResult:\n        \"\"\"Record the call and return the next canned response.\"\"\"\n        self.calls.append(messages)\n\n        if self._call_index &lt; len(self.responses):\n            content = self.responses[self._call_index]\n            self._call_index += 1\n        else:\n            content = \"Mock response\"\n\n        return ChatResult(\n            generations=[\n                ChatGeneration(\n                    message=AIMessage(content=content),\n                )\n            ]\n        )\n</code></pre>"},{"location":"api/testing/mocks/#sage_sanctum.testing.mocks.MockLLM.__init__","title":"<code>__init__(responses: list[str] | None = None, **kwargs: Any)</code>","text":"<p>Initialize the mock LLM.</p> <p>Parameters:</p> Name Type Description Default <code>responses</code> <code>list[str] | None</code> <p>Canned responses to return in order. If <code>None</code>, every call returns <code>\"Mock response\"</code>.</p> <code>None</code> Source code in <code>src/sage_sanctum/testing/mocks.py</code> <pre><code>def __init__(self, responses: list[str] | None = None, **kwargs: Any):\n    \"\"\"Initialize the mock LLM.\n\n    Args:\n        responses: Canned responses to return in order. If ``None``,\n            every call returns ``\"Mock response\"``.\n    \"\"\"\n    super().__init__(**kwargs)\n    if responses:\n        self.responses = responses\n    self.calls = []\n    self._call_index = 0\n</code></pre>"},{"location":"api/testing/mocks/#sage_sanctum.testing.mocks.MockTratClient","title":"<code>MockTratClient</code>","text":"<p>Mock Transaction Token client for testing.</p> <p>Returns a configurable <code>TransactionToken</code> without any file or sidecar dependencies. Ships with sensible defaults for common testing scenarios.</p> <p>Parameters:</p> Name Type Description Default <code>trat</code> <code>TransactionToken | None</code> <p>An explicit <code>TransactionToken</code> to return.</p> <code>None</code> <code>allowed_models</code> <code>AllowedModels | None</code> <p>Custom model allowlists. Ignored if <code>trat</code> is provided. Defaults to gpt-4o-mini (triage), gpt-4o + claude-3-5-sonnet (analysis), o1 (reasoning), text-embedding-3-small (embeddings).</p> <code>None</code> Source code in <code>src/sage_sanctum/testing/mocks.py</code> <pre><code>class MockTratClient:\n    \"\"\"Mock Transaction Token client for testing.\n\n    Returns a configurable ``TransactionToken`` without any file or\n    sidecar dependencies. Ships with sensible defaults for common\n    testing scenarios.\n\n    Args:\n        trat: An explicit ``TransactionToken`` to return.\n        allowed_models: Custom model allowlists. Ignored if ``trat`` is\n            provided. Defaults to gpt-4o-mini (triage), gpt-4o +\n            claude-3-5-sonnet (analysis), o1 (reasoning),\n            text-embedding-3-small (embeddings).\n    \"\"\"\n\n    def __init__(\n        self,\n        trat: TransactionToken | None = None,\n        allowed_models: AllowedModels | None = None,\n    ) -&gt; None:\n        if trat:\n            self._trat = trat\n        else:\n            self._trat = self._default_trat(allowed_models)\n\n    def get_token(self) -&gt; TransactionToken:\n        \"\"\"Return the mock Transaction Token.\"\"\"\n        return self._trat\n\n    def invalidate(self) -&gt; None:\n        \"\"\"No-op \u2014 mock tokens don't need cache invalidation.\"\"\"\n        pass\n\n    @staticmethod\n    def _default_trat(\n        allowed_models: AllowedModels | None = None,\n    ) -&gt; TransactionToken:\n        \"\"\"Create a default test TraT with preset models and metadata.\"\"\"\n        import time\n\n        if not allowed_models:\n            allowed_models = AllowedModels(\n                triage=[\"openai:gpt-4o-mini\"],\n                analysis=[\"openai:gpt-4o\", \"anthropic:claude-3-5-sonnet-latest\"],\n                reasoning=[\"openai:o1\"],\n                embeddings=[\"openai:text-embedding-3-small\"],\n            )\n\n        return TransactionToken(\n            raw=\"mock-trat-jwt\",\n            txn=\"run_test123\",\n            sub=\"github|org-12345\",\n            scope=\"scan.execute scan.upload\",\n            req_wl=\"spiffe://sage-sanctum.local/scanner/run_test123\",\n            iat=time.time(),\n            exp=time.time() + 300,  # 5 minutes from now\n            aud=\"sage-sanctum.local\",\n            iss=\"https://tts.sage-sanctum.local\",\n            tctx=TransactionContext(\n                run_id=\"run_test123\",\n                org_id=\"12345\",\n                repo_url=\"https://github.com/acme/repo\",\n                agent_type=\"sage-scanner\",\n                agent_mode=\"standard\",\n                allowed_models=allowed_models,\n                allowed_providers=[\"openai\", \"anthropic\"],\n            ),\n            rctx=RequesterContext(\n                trigger=\"pull_request\",\n                pr_number=42,\n                actor=\"dependabot[bot]\",\n            ),\n        )\n</code></pre>"},{"location":"api/testing/mocks/#sage_sanctum.testing.mocks.MockTratClient.get_token","title":"<code>get_token() -&gt; TransactionToken</code>","text":"<p>Return the mock Transaction Token.</p> Source code in <code>src/sage_sanctum/testing/mocks.py</code> <pre><code>def get_token(self) -&gt; TransactionToken:\n    \"\"\"Return the mock Transaction Token.\"\"\"\n    return self._trat\n</code></pre>"},{"location":"api/testing/mocks/#sage_sanctum.testing.mocks.MockTratClient.invalidate","title":"<code>invalidate() -&gt; None</code>","text":"<p>No-op \u2014 mock tokens don't need cache invalidation.</p> Source code in <code>src/sage_sanctum/testing/mocks.py</code> <pre><code>def invalidate(self) -&gt; None:\n    \"\"\"No-op \u2014 mock tokens don't need cache invalidation.\"\"\"\n    pass\n</code></pre>"},{"location":"api/testing/mocks/#sage_sanctum.testing.mocks.MockEmbeddings","title":"<code>MockEmbeddings</code>","text":"<p>               Bases: <code>Embeddings</code></p> <p>Mock LangChain embeddings for testing.</p> <p>Returns deterministic fixed-dimension vectors and records every call.</p> <p>Attributes:</p> Name Type Description <code>dimension</code> <p>Dimension of returned vectors. Defaults to <code>8</code>.</p> <code>calls</code> <code>list[list[str]]</code> <p>List of input lists received \u2014 one entry per call.</p> Example <pre><code>embeddings = MockEmbeddings(dimension=4)\nvecs = embeddings.embed_documents([\"hello\", \"world\"])\nassert len(vecs) == 2\nassert len(vecs[0]) == 4\nassert len(embeddings.calls) == 1\n</code></pre> Source code in <code>src/sage_sanctum/testing/mocks.py</code> <pre><code>class MockEmbeddings(Embeddings):\n    \"\"\"Mock LangChain embeddings for testing.\n\n    Returns deterministic fixed-dimension vectors and records every call.\n\n    Attributes:\n        dimension: Dimension of returned vectors. Defaults to ``8``.\n        calls: List of input lists received \u2014 one entry per call.\n\n    Example:\n        ```python\n        embeddings = MockEmbeddings(dimension=4)\n        vecs = embeddings.embed_documents([\"hello\", \"world\"])\n        assert len(vecs) == 2\n        assert len(vecs[0]) == 4\n        assert len(embeddings.calls) == 1\n        ```\n    \"\"\"\n\n    def __init__(self, dimension: int = 8) -&gt; None:\n        self.dimension = dimension\n        self.calls: list[list[str]] = []\n\n    def embed_documents(self, texts: list[str]) -&gt; list[list[float]]:\n        \"\"\"Return deterministic vectors (hash-based) for each text.\"\"\"\n        self.calls.append(texts)\n        return [self._deterministic_vector(t) for t in texts]\n\n    def embed_query(self, text: str) -&gt; list[float]:\n        \"\"\"Return a deterministic vector for a single query.\"\"\"\n        self.calls.append([text])\n        return self._deterministic_vector(text)\n\n    def _deterministic_vector(self, text: str) -&gt; list[float]:\n        \"\"\"Generate a reproducible unit-length vector from text.\"\"\"\n        h = hash(text)\n        raw = [float((h &gt;&gt; (i * 8)) &amp; 0xFF) / 255.0 for i in range(self.dimension)]\n        # Normalize to unit length\n        magnitude = sum(x * x for x in raw) ** 0.5 or 1.0\n        return [x / magnitude for x in raw]\n</code></pre>"},{"location":"api/testing/mocks/#sage_sanctum.testing.mocks.MockEmbeddings.embed_documents","title":"<code>embed_documents(texts: list[str]) -&gt; list[list[float]]</code>","text":"<p>Return deterministic vectors (hash-based) for each text.</p> Source code in <code>src/sage_sanctum/testing/mocks.py</code> <pre><code>def embed_documents(self, texts: list[str]) -&gt; list[list[float]]:\n    \"\"\"Return deterministic vectors (hash-based) for each text.\"\"\"\n    self.calls.append(texts)\n    return [self._deterministic_vector(t) for t in texts]\n</code></pre>"},{"location":"api/testing/mocks/#sage_sanctum.testing.mocks.MockEmbeddings.embed_query","title":"<code>embed_query(text: str) -&gt; list[float]</code>","text":"<p>Return a deterministic vector for a single query.</p> Source code in <code>src/sage_sanctum/testing/mocks.py</code> <pre><code>def embed_query(self, text: str) -&gt; list[float]:\n    \"\"\"Return a deterministic vector for a single query.\"\"\"\n    self.calls.append([text])\n    return self._deterministic_vector(text)\n</code></pre>"},{"location":"concepts/agents/","title":"Agents","text":""},{"location":"concepts/agents/#sagesanctumagent","title":"SageSanctumAgent","text":"<p><code>SageSanctumAgent</code> is the abstract base class for all agents. It is generic on the input type. Every agent must implement three members:</p> <pre><code>from sage_sanctum import SageSanctumAgent, AgentResult\nfrom sage_sanctum.io.inputs import RepositoryInput\n\n\nclass MyAgent(SageSanctumAgent[RepositoryInput]):\n    @property\n    def name(self) -&gt; str:\n        return \"my-agent\"\n\n    @property\n    def version(self) -&gt; str:\n        return \"1.0.0\"\n\n    async def run(self, agent_input: RepositoryInput) -&gt; AgentResult:\n        # agent_input.path is type-safe \u2014 no cast needed\n        ...\n</code></pre> Member Type Description <code>name</code> <code>property</code> Agent identifier (used in SARIF output) <code>version</code> <code>property</code> Semantic version string <code>run</code> <code>async method</code> Main execution \u2014 receives input, returns result <p>The agent receives an <code>AgentContext</code> via <code>self.context</code>, which provides access to LLM clients, model selection, the gateway, and output writing.</p> <p>Generic input type</p> <p>Specifying the type parameter (e.g., <code>SageSanctumAgent[RepositoryInput]</code>) gives you type-safe access to input fields in <code>run()</code> without needing <code>isinstance</code> checks. If omitted, the input type defaults to <code>AgentInput</code>.</p>"},{"location":"concepts/agents/#agentresult","title":"AgentResult","text":"<p>The <code>run</code> method returns an <code>AgentResult</code>:</p> <pre><code>@dataclass\nclass AgentResult:\n    output: AgentOutput | None = None  # SARIF or other output\n    exit_code: int = 0                 # Process exit code\n    error: str = \"\"                    # Error message\n    duration_seconds: float = 0.0      # Execution time\n    metadata: dict[str, Any] = {}      # Additional metadata\n</code></pre>"},{"location":"concepts/agents/#agentrunner","title":"AgentRunner","text":"<p><code>AgentRunner</code> handles the full agent lifecycle so you don't have to:</p> <pre><code>if __name__ == \"__main__\":\n    import sys\n    sys.exit(AgentRunner(MyAgent).run())\n</code></pre>"},{"location":"concepts/agents/#lifecycle","title":"Lifecycle","text":"<pre><code>graph TD\n    A[Install signal handlers] --&gt; B[Initialize AgentContext]\n    B --&gt; C[Create agent instance]\n    C --&gt; D[Load agent input]\n    D --&gt; E[Execute agent.run]\n    E --&gt; F{Success?}\n    F --&gt;|Yes| G[Write output to disk]\n    F --&gt;|No| H[Map error to exit code]\n    G --&gt; I[Return exit code 0]\n    H --&gt; I2[Return error exit code]</code></pre> <ol> <li>Signal handlers \u2014 SIGTERM and SIGINT trigger graceful shutdown</li> <li>Context initialization \u2014 <code>AgentContext.from_environment()</code> reads all config from environment variables</li> <li>Agent creation \u2014 Your agent class is instantiated with the context</li> <li>Input loading \u2014 <code>context.load_input()</code> reads the repository input</li> <li>Execution \u2014 Your <code>run</code> method is called</li> <li>Output \u2014 If the result contains output, it's written to the output directory</li> <li>Exit code \u2014 <code>SageSanctumError</code> subclasses map to specific exit codes (see Error Handling)</li> </ol>"},{"location":"concepts/agents/#error-mapping","title":"Error Mapping","text":"<p>If <code>run</code> raises a <code>SageSanctumError</code>, the runner maps it to the error's <code>exit_code</code>. Any other exception maps to exit code <code>1</code>. This means the orchestrator can distinguish between authentication failures (10-19), authorization failures (20-29), gateway errors (30-39), and so on.</p>"},{"location":"concepts/agents/#external-llm-agents","title":"External LLM Agents","text":"<p>Not all agents use the SDK's built-in LLM clients. Some wrap external tools like the Claude Agent SDK or other CLI tools that manage their own LLM communication. For these agents, set <code>requires_gateway = False</code>:</p> <pre><code>from sage_sanctum import SageSanctumAgent, AgentResult\nfrom sage_sanctum.io.inputs import RepositoryInput\n\n\nclass ClaudeCodeAgent(SageSanctumAgent[RepositoryInput]):\n    requires_gateway = False  # skip SPIFFE/TraT/gateway setup\n\n    @property\n    def name(self) -&gt; str:\n        return \"claude-code-scanner\"\n\n    @property\n    def version(self) -&gt; str:\n        return \"0.1.0\"\n\n    async def run(self, agent_input: RepositoryInput) -&gt; AgentResult:\n        # self.context.gateway_client is None\n        # self.context still provides load_input(), write_output(),\n        # run_id, org_id, work_dir, output_dir\n        ...\n</code></pre> <p>When <code>requires_gateway = False</code>:</p> <ul> <li>The runner uses <code>AgentContext.for_external_llm()</code> instead of <code>AgentContext.from_environment()</code></li> <li>No SPIFFE JWT, Transaction Token, or gateway client is initialized</li> <li><code>create_llm_client()</code> and <code>create_embeddings_client()</code> will raise <code>ConfigurationError</code> if called</li> <li><code>check_gateway_health()</code> returns <code>False</code></li> <li>Input loading and output writing work normally</li> </ul>"},{"location":"concepts/agents/#graceful-shutdown","title":"Graceful Shutdown","text":"<p>External agents often run long-lived subprocesses. The base class provides a shutdown event so agents can cooperatively cancel when SIGTERM is received:</p> <pre><code>import asyncio\nfrom sage_sanctum import SageSanctumAgent, AgentResult\nfrom sage_sanctum.io.inputs import RepositoryInput\n\n\nclass MyExternalAgent(SageSanctumAgent[RepositoryInput]):\n    requires_gateway = False\n\n    # ... name, version ...\n\n    async def run(self, agent_input: RepositoryInput) -&gt; AgentResult:\n        proc = await asyncio.create_subprocess_exec(\n            \"my-tool\", str(agent_input.path),\n        )\n\n        # Race subprocess against shutdown signal\n        proc_wait = asyncio.create_task(proc.wait())\n        shutdown_wait = asyncio.create_task(self.wait_for_shutdown())\n\n        done, pending = await asyncio.wait(\n            {proc_wait, shutdown_wait},\n            return_when=asyncio.FIRST_COMPLETED,\n        )\n        for task in pending:\n            task.cancel()\n\n        if shutdown_wait in done:\n            proc.terminate()\n            await proc.wait()\n            return AgentResult(exit_code=130)\n\n        # Process completed normally\n        ...\n</code></pre> Member Description <code>shutdown_requested</code> <code>bool</code> property -- <code>True</code> after SIGTERM/SIGINT <code>wait_for_shutdown()</code> Coroutine -- blocks until shutdown is signaled"},{"location":"concepts/architecture/","title":"Architecture","text":"<p>Sage Sanctum runs agents in hardened, isolated containers with no direct network access. The SDK mediates all external communication through authenticated gateways.</p>"},{"location":"concepts/architecture/#security-model","title":"Security Model","text":"<pre><code>graph TB\n    subgraph \"Agent Pod (seccomp: no AF_INET)\"\n        Agent[Agent Code]\n        SDK[Sage Sanctum SDK]\n        Agent --&gt; SDK\n    end\n\n    subgraph \"Sidecar Services\"\n        Auth[Auth Sidecar]\n        GW[Gateway Sidecar]\n    end\n\n    SDK --&gt;|\"Unix Socket\"| Auth\n    SDK --&gt;|\"Unix Socket\"| GW\n\n    Auth --&gt;|\"SPIFFE JWT\"| SDK\n    Auth --&gt;|\"TraT\"| SDK\n\n    subgraph \"Central Services\"\n        CGW[Central LLM Gateway]\n    end\n\n    GW --&gt;|\"Forward\"| CGW\n\n    subgraph \"External Services\"\n        OpenAI[OpenAI API]\n        Anthropic[Anthropic API]\n        Google[Google AI API]\n    end\n\n    CGW --&gt; OpenAI\n    CGW --&gt; Anthropic\n    CGW --&gt; Google</code></pre>"},{"location":"concepts/architecture/#network-isolation","title":"Network Isolation","text":"<p>Agent pods run with a seccomp profile that blocks <code>AF_INET</code> socket creation. Agents cannot make direct network calls. All communication flows through Unix domain sockets to sidecar services, which forward to the central gateway.</p>"},{"location":"concepts/architecture/#identity-spiffe","title":"Identity: SPIFFE","text":"<p>Each agent receives a SPIFFE JWT SVID (Service Verification Identity Document) that proves its identity. The JWT is mounted into the container and automatically refreshed.</p>"},{"location":"concepts/architecture/#authorization-transaction-tokens-trat","title":"Authorization: Transaction Tokens (TraT)","text":"<p>Transaction Tokens (IETF draft) carry the complete authorization context for a run:</p> <ul> <li>Which models the agent may use (per category)</li> <li>Which providers are allowed</li> <li>Which MCP tools are permitted</li> <li>Audit metadata (trigger, actor, PR number)</li> </ul>"},{"location":"concepts/architecture/#gateway","title":"Gateway","text":"<p>The gateway sidecar in the pod is a thin forwarder that accepts requests over a Unix domain socket and passes them to the central LLM gateway. The central gateway validates credentials, enforces policies, and proxies requests to LLM providers. It:</p> <ol> <li>Verifies the SPIFFE JWT signature</li> <li>Validates the TraT claims and expiry</li> <li>Checks the requested model against the allowlist</li> <li>Injects provider credentials (API keys)</li> <li>Forwards the request to the provider</li> <li>Returns the response to the agent</li> </ol>"},{"location":"concepts/architecture/#data-flow","title":"Data Flow","text":"<pre><code>sequenceDiagram\n    participant Agent\n    participant SDK\n    participant Auth as Auth Sidecar\n    participant SC as Gateway Sidecar\n    participant GW as Central Gateway\n    participant LLM as LLM Provider\n\n    Agent-&gt;&gt;SDK: create_llm_client(ANALYSIS)\n    SDK-&gt;&gt;Auth: GET /trat (Unix socket)\n    Auth--&gt;&gt;SDK: Transaction Token\n    SDK-&gt;&gt;SDK: Select model from TraT allowlist\n\n    Agent-&gt;&gt;SDK: llm.invoke(messages)\n    SDK-&gt;&gt;Auth: Read SPIFFE JWT\n    SDK-&gt;&gt;SC: POST /v1/chat/completions&lt;br/&gt;+ Authorization: Bearer {jwt}&lt;br/&gt;+ Txn-Token: {trat}\n    SC-&gt;&gt;GW: Forward request\n    GW-&gt;&gt;GW: Verify JWT + TraT\n    GW-&gt;&gt;GW: Inject provider credentials\n    GW-&gt;&gt;LLM: Forward request\n    LLM--&gt;&gt;GW: Response\n    GW--&gt;&gt;SC: Response\n    SC--&gt;&gt;SDK: Response\n    SDK--&gt;&gt;Agent: ChatResult</code></pre>"},{"location":"concepts/architecture/#three-modes-of-operation","title":"Three Modes of Operation","text":""},{"location":"concepts/architecture/#gateway-mode-production","title":"Gateway Mode (Production)","text":"<p>In production, agents use SPIFFE + TraT via Unix sockets. This is the default when <code>SPIFFE_JWT_PATH</code> and related environment variables are set.</p>"},{"location":"concepts/architecture/#direct-mode-local-development","title":"Direct Mode (Local Development)","text":"<p>For local development, set <code>SAGE_SANCTUM_ALLOW_DIRECT=1</code> to bypass the gateway and call LLM providers directly with API keys from environment variables. See the Configuration guide.</p> <p>Warning</p> <p>Direct mode disables all gateway security checks. Never use it in production.</p>"},{"location":"concepts/architecture/#external-llm-mode","title":"External LLM Mode","text":"<p>For agents that wrap external tools (like Claude Code) which manage their own LLM communication. The SDK handles only I/O and lifecycle; the external tool talks to the gateway independently via an auth-injecting bridge.</p> <pre><code>Scanner Pod\n\u251c\u2500\u2500 Python Agent (SageSanctumAgent, requires_gateway=False)\n\u2502   \u2514\u2500\u2500 Claude Agent SDK (async subprocess)\n\u2502       \u2514\u2500\u2500 ANTHROPIC_BASE_URL=http://127.0.0.1:8082\n\u251c\u2500\u2500 bridge.py (auth-injecting HTTP proxy: reads JWT + TraT, injects headers)\n\u2502   \u2514\u2500\u2500 Forwards to UDS: /run/sage/llm.sock\n\u251c\u2500\u2500 LLM Gateway sidecar (forwarder mode, zero-logic)\n\u2502   \u2514\u2500\u2500 Forwards to central gateway\n\u2514\u2500\u2500 Central LLM Gateway (validates auth, DLP, BYOK key injection)\n</code></pre> <p>See the Claude Code Integration guide for a full walkthrough.</p>"},{"location":"concepts/authentication/","title":"Authentication","text":"<p>Sage Sanctum uses a two-layer authentication model: SPIFFE for identity and Transaction Tokens for authorization.</p>"},{"location":"concepts/authentication/#spiffe-identity","title":"SPIFFE (Identity)","text":"<p>SPIFFE (Secure Production Identity Framework for Everyone) provides each agent with a cryptographic identity via JWT SVIDs.</p>"},{"location":"concepts/authentication/#how-it-works","title":"How It Works","text":"<ol> <li>The platform mounts a SPIFFE JWT file into the agent container</li> <li>The SDK reads the JWT via <code>JWTSource</code></li> <li>On each gateway call, the JWT is sent as a <code>Bearer</code> token in the <code>Authorization</code> header</li> <li>The gateway verifies the JWT signature against the SPIFFE trust bundle</li> </ol> <pre><code>from sage_sanctum.auth.spiffe import JWTSource\n\njwt_source = JWTSource(\"/run/secrets/spiffe/jwt\")\ntoken = jwt_source.get_token()  # Cached, auto-refreshes before expiry\n</code></pre>"},{"location":"concepts/authentication/#token-caching","title":"Token Caching","text":"<p><code>JWTSource</code> caches the JWT in memory and refreshes it 5 minutes before expiry (<code>_REFRESH_BUFFER_SECONDS = 300</code>). This avoids unnecessary file reads while ensuring tokens don't expire mid-request.</p>"},{"location":"concepts/authentication/#transaction-tokens-authorization","title":"Transaction Tokens (Authorization)","text":"<p>Transaction Tokens (TraT) are an IETF draft standard for carrying authorization context across service boundaries.</p>"},{"location":"concepts/authentication/#structure","title":"Structure","text":"<p>A TraT contains:</p> Claim Description <code>txn</code> Transaction ID <code>sub</code> Subject (agent SPIFFE ID) <code>scope</code> Authorized scopes <code>iat</code> / <code>exp</code> Issued at / expiration <code>tctx</code> Transaction context (models, providers, tools) <code>rctx</code> Requester context (trigger, actor, PR number)"},{"location":"concepts/authentication/#transaction-context-tctx","title":"Transaction Context (tctx)","text":"<p>The <code>tctx</code> claim carries the run's authorization parameters:</p> <pre><code>token.tctx.allowed_models   # AllowedModels(triage=[...], analysis=[...], ...)\ntoken.tctx.allowed_providers  # [\"openai\", \"anthropic\"]\ntoken.tctx.allowed_tools      # {\"mcp-server\": [\"tool1\", \"tool2\"]}\ntoken.tctx.run_id             # \"run-abc123\"\ntoken.tctx.org_id             # \"org-xyz\"\ntoken.tctx.repo_url           # \"https://github.com/org/repo\"\n</code></pre>"},{"location":"concepts/authentication/#requester-context-rctx","title":"Requester Context (rctx)","text":"<p>The <code>rctx</code> claim carries audit metadata about what triggered the run:</p> <pre><code>token.rctx.trigger     # \"pull_request\"\ntoken.rctx.pr_number   # 42\ntoken.rctx.actor       # \"dependabot[bot]\"\ntoken.rctx.source_ip   # \"192.168.1.1\"\n</code></pre>"},{"location":"concepts/authentication/#acquiring-tokens","title":"Acquiring Tokens","text":"<p>The <code>TransactionTokenClient</code> reads TraTs from either a file or the auth sidecar:</p> <pre><code>from sage_sanctum.auth.trat import TransactionTokenClient\n\n# From file\nclient = TransactionTokenClient(trat_file=\"/run/secrets/trat\")\n\n# From auth sidecar\nclient = TransactionTokenClient(sidecar_socket=\"/run/sockets/auth.sock\")\n\ntoken = client.get_token()  # Cached, checks expiry\n</code></pre>"},{"location":"concepts/authentication/#gatewaycredentials","title":"GatewayCredentials","text":"<p><code>GatewayCredentials</code> bundles the SPIFFE JWT and TraT together for gateway requests:</p> <pre><code>from sage_sanctum.auth.credentials import GatewayCredentials\n\ncreds = gateway_client.get_credentials()\nheaders = creds.auth_headers()\n# {\"Authorization\": \"Bearer &lt;jwt&gt;\", \"Txn-Token\": \"&lt;trat&gt;\"}\n</code></pre> <p>Note</p> <p>You rarely interact with authentication directly. <code>AgentContext.create_llm_client()</code> handles credential injection automatically.</p>"},{"location":"concepts/context/","title":"Context","text":"<p><code>AgentContext</code> is the central runtime object that every agent receives. It provides access to LLM clients, model selection, input loading, and output writing.</p>"},{"location":"concepts/context/#initialization-modes","title":"Initialization Modes","text":""},{"location":"concepts/context/#from-environment-production","title":"From Environment (Production)","text":"<pre><code>context = AgentContext.from_environment()\n</code></pre> <p>Reads all configuration from environment variables. Used by <code>AgentRunner</code> automatically.</p>"},{"location":"concepts/context/#from-environment-async","title":"From Environment Async","text":"<pre><code>context = await AgentContext.from_environment_async()\n</code></pre> <p>Async variant for use in async initialization flows.</p>"},{"location":"concepts/context/#for-local-development","title":"For Local Development","text":"<pre><code>context = AgentContext.for_local_development(\n    work_dir=\"/tmp/work\",\n    output_dir=\"/tmp/output\",\n    model=\"openai:gpt-4o\",\n)\n</code></pre> <p>Creates a context that calls LLM providers directly (no gateway). Requires <code>SAGE_SANCTUM_ALLOW_DIRECT=1</code>.</p>"},{"location":"concepts/context/#for-external-llm-agents","title":"For External LLM Agents","text":"<pre><code>context = AgentContext.for_external_llm()\n</code></pre> <p>Creates a minimal context for agents that manage their own LLM access (e.g., wrapping Claude Code). Only reads <code>RUN_ID</code>, <code>ORG_ID</code>, <code>WORK_DIR</code>, and <code>OUTPUT_PATH</code> from the environment. Skips all SPIFFE, TraT, and gateway setup.</p> <p>The resulting context has <code>gateway_client=None</code> and <code>model_selector=None</code>. Calling <code>create_llm_client()</code> or <code>create_embeddings_client()</code> will raise <code>ConfigurationError</code>. Input loading and output writing work normally.</p> <p>Note</p> <p>You don't need to call this factory directly. Set <code>requires_gateway = False</code> on your agent class and the <code>AgentRunner</code> will use it automatically. See External LLM Agents.</p>"},{"location":"concepts/context/#fields","title":"Fields","text":"Field Type Description <code>run_id</code> <code>str</code> Unique run identifier <code>org_id</code> <code>str</code> Organization identifier <code>work_dir</code> <code>Path</code> Working directory for temporary files <code>output_dir</code> <code>Path</code> Directory where output is written <code>gateway_client</code> <code>GatewayClient | None</code> Client for LLM gateway access (None for external-LLM agents) <code>model_selector</code> <code>ModelSelector | None</code> Resolves model categories to concrete models (None for external-LLM agents) <code>logger</code> <code>logging.Logger</code> Logger instance for the agent"},{"location":"concepts/context/#key-methods","title":"Key Methods","text":""},{"location":"concepts/context/#create_llm_client","title":"create_llm_client","text":"<pre><code>llm = context.create_llm_client(ModelCategory.ANALYSIS)\nresponse = llm.invoke([...])\n</code></pre> <p>Returns a LangChain <code>BaseChatModel</code> configured for the given category. In gateway mode, this routes through the LLM gateway with SPIFFE + TraT headers. In direct mode, it uses LiteLLM with API keys.</p>"},{"location":"concepts/context/#load_input","title":"load_input","text":"<pre><code>repo_input = context.load_input()\n</code></pre> <p>Loads agent input from the <code>REPO_PATH</code> environment variable. Returns a <code>RepositoryInput</code> with the path to the cloned repository.</p>"},{"location":"concepts/context/#write_output","title":"write_output","text":"<pre><code>files = context.write_output(sarif_output)\n</code></pre> <p>Writes agent output to the output directory. Returns a list of filenames written.</p>"},{"location":"concepts/context/#environment-variables","title":"Environment Variables","text":"<p>The context reads the following environment variables during initialization:</p> Variable Required Default Description <code>RUN_ID</code> Yes \u2014 Run identifier <code>ORG_ID</code> Yes \u2014 Organization identifier <code>WORK_DIR</code> No <code>/work</code> Working directory <code>OUTPUT_PATH</code> No <code>/output</code> Output directory <code>SPIFFE_JWT_PATH</code> No \u2014 Path to SPIFFE JWT file <code>TRAT_FILE</code> No \u2014 Path to TraT file <code>AUTH_SIDECAR_SOCKET</code> No \u2014 Auth sidecar Unix socket <code>LLM_GATEWAY_SOCKET</code> No \u2014 LLM gateway Unix socket <code>SAGE_SANCTUM_ALLOW_DIRECT</code> No \u2014 Set to <code>1</code> for direct mode <code>SAGE_MODEL</code> / <code>OPENAI_MODEL</code> No \u2014 Model override <p>See the Configuration guide for the full reference.</p>"},{"location":"concepts/io/","title":"Input &amp; Output","text":""},{"location":"concepts/io/#input","title":"Input","text":""},{"location":"concepts/io/#repositoryinput","title":"RepositoryInput","text":"<p>Agents receive a <code>RepositoryInput</code> representing a cloned repository to analyze:</p> <pre><code>from sage_sanctum.io.inputs import RepositoryInput\n\nrepo = context.load_input()\n\nrepo.path       # Path(\"/work/repo\") \u2014 absolute path to repo root\nrepo.ref        # \"main\" \u2014 git ref\nrepo.url        # \"https://github.com/org/repo\"\n</code></pre>"},{"location":"concepts/io/#listing-files","title":"Listing Files","text":"<pre><code># All files\nall_files = repo.list_files()\n\n# Only Python files\npy_files = repo.list_files(extensions={\".py\"})\n\n# Only JavaScript and TypeScript\njs_files = repo.list_files(extensions={\".js\", \".ts\"})\n</code></pre>"},{"location":"concepts/io/#validation","title":"Validation","text":"<p><code>RepositoryInput.validate()</code> checks that:</p> <ul> <li>The path exists</li> <li>The path is a directory</li> <li>The path doesn't contain path traversal (<code>..</code>)</li> </ul> <p>This is called automatically when loading input.</p>"},{"location":"concepts/io/#environment-variables","title":"Environment Variables","text":"Variable Description <code>REPO_PATH</code> Absolute path to the cloned repository <code>REPO_REF</code> Git ref (branch, tag, commit hash) <code>REPO_URL</code> Remote repository URL"},{"location":"concepts/io/#output","title":"Output","text":""},{"location":"concepts/io/#sarifoutput","title":"SarifOutput","text":"<p>The primary output format is SARIF 2.1.0, the standard for GitHub Code Scanning results.</p> <pre><code>from sage_sanctum.io.outputs import SarifOutput, Finding, Location, TokenUsage\n\noutput = SarifOutput(\n    tool_name=\"my-agent\",\n    tool_version=\"1.0.0\",\n    findings=[\n        Finding(\n            id=\"SQL-001\",\n            title=\"SQL Injection\",\n            description=\"User input passed directly to SQL query\",\n            severity=\"high\",\n            location=Location(\n                file=\"src/db.py\",\n                start_line=42,\n                end_line=42,\n                start_column=5,\n                end_column=38,\n            ),\n            cwe=\"CWE-89\",\n            remediation=\"Use parameterized queries\",\n            confidence=\"high\",\n        ),\n    ],\n    token_usage=[\n        TokenUsage(\n            model=\"gpt-4o\",\n            prompt_tokens=1500,\n            completion_tokens=300,\n            total_tokens=1800,\n        ),\n    ],\n)\n</code></pre>"},{"location":"concepts/io/#finding","title":"Finding","text":"<p>Each finding represents a single issue discovered by the agent:</p> Field Type Description <code>id</code> <code>str</code> Unique finding identifier (e.g., <code>\"SQL-001\"</code>) <code>title</code> <code>str</code> Short title <code>description</code> <code>str</code> Detailed description <code>severity</code> <code>str</code> <code>\"critical\"</code>, <code>\"high\"</code>, <code>\"medium\"</code>, <code>\"low\"</code>, or <code>\"note\"</code> <code>location</code> <code>Location</code> Source code location <code>cwe</code> <code>str</code> CWE reference (e.g., <code>\"CWE-89\"</code>) <code>remediation</code> <code>str</code> Fix suggestion <code>confidence</code> <code>str</code> <code>\"high\"</code>, <code>\"medium\"</code>, or <code>\"low\"</code> <code>metadata</code> <code>dict</code> Additional data"},{"location":"concepts/io/#location","title":"Location","text":"<pre><code>Location(\n    file=\"src/db.py\",\n    start_line=42,\n    end_line=45,\n    start_column=5,\n    end_column=20,\n)\n</code></pre>"},{"location":"concepts/io/#severity-mapping","title":"Severity Mapping","text":"<p>SARIF uses a different severity model. The SDK maps automatically:</p> SDK Severity SARIF Level Security Score <code>critical</code> <code>error</code> 9.0 <code>high</code> <code>error</code> 7.0 <code>medium</code> <code>warning</code> 4.0 <code>low</code> <code>note</code> 1.0 <code>note</code> <code>note</code> 0.0"},{"location":"concepts/io/#writing-output","title":"Writing Output","text":"<p>Output is written automatically by <code>AgentRunner</code>, or you can write manually:</p> <pre><code>files = context.write_output(sarif_output)\n# [\"results.sarif\"]\n</code></pre>"},{"location":"concepts/io/#agentresult","title":"AgentResult","text":"<p>The <code>run</code> method wraps output in an <code>AgentResult</code>:</p> <pre><code>return AgentResult(\n    output=sarif_output,\n    exit_code=0,\n    metadata={\"files_analyzed\": 42},\n)\n</code></pre>"},{"location":"concepts/model-selection/","title":"Model Selection","text":"<p>The SDK provides a structured approach to model selection through categories, references, and selectors.</p>"},{"location":"concepts/model-selection/#modelcategory","title":"ModelCategory","text":"<p>Agents categorize their LLM usage into four categories:</p> Category Value Typical Use <code>TRIAGE</code> <code>\"triage\"</code> Quick classification, routing, filtering <code>ANALYSIS</code> <code>\"analysis\"</code> Detailed code analysis, vulnerability detection <code>REASONING</code> <code>\"reasoning\"</code> Complex multi-step reasoning <code>EMBEDDINGS</code> <code>\"embeddings\"</code> Embedding generation for similarity search <pre><code>from sage_sanctum.llm.model_category import ModelCategory\n\nllm = context.create_llm_client(ModelCategory.ANALYSIS)\n</code></pre> <p>Each category maps to an allowlist of models defined in the Transaction Token. This lets platform operators control cost and capability per use case.</p>"},{"location":"concepts/model-selection/#modelref","title":"ModelRef","text":"<p>A <code>ModelRef</code> is a canonical reference to a specific model in <code>provider:model</code> format:</p> <pre><code>from sage_sanctum.llm.model_ref import ModelRef\n\nref = ModelRef.parse(\"openai:gpt-4o\")\nref = ModelRef.parse(\"anthropic:claude-3-5-sonnet-latest\")\nref = ModelRef.parse(\"google:gemini-2.0-flash\")\n</code></pre>"},{"location":"concepts/model-selection/#auto-detection","title":"Auto-Detection","text":"<p>If you omit the provider prefix, the SDK infers it from the model name:</p> <pre><code>ModelRef.parse(\"gpt-4o\")           # \u2192 openai:gpt-4o\nModelRef.parse(\"claude-3-5-sonnet-latest\")  # \u2192 anthropic:claude-3-5-sonnet-latest\nModelRef.parse(\"gemini-2.0-flash\")  # \u2192 google:gemini-2.0-flash\n</code></pre>"},{"location":"concepts/model-selection/#litellm-formatting","title":"LiteLLM Formatting","text":"<p><code>ModelRef</code> handles the provider-specific formatting required by LiteLLM:</p> <pre><code>ref = ModelRef.parse(\"openai:gpt-4o\")\nref.for_litellm  # \"gpt-4o\"\n\nref = ModelRef.parse(\"anthropic:claude-3-5-sonnet-latest\")\nref.for_litellm  # \"anthropic/claude-3-5-sonnet-latest\"\n\nref = ModelRef.parse(\"google:gemini-2.0-flash\")\nref.for_litellm  # \"gemini/gemini-2.0-flash\"\n</code></pre>"},{"location":"concepts/model-selection/#modelselector","title":"ModelSelector","text":"<p><code>ModelSelector</code> resolves categories to concrete models based on the TraT allowlist:</p> <pre><code>from sage_sanctum.llm.model_selector import ModelSelector\n\nselector = ModelSelector(allowed_models={\n    \"triage\": [\"openai:gpt-4o-mini\"],\n    \"analysis\": [\"openai:gpt-4o\", \"anthropic:claude-3-5-sonnet-latest\"],\n    \"reasoning\": [\"openai:o1\"],\n    \"embeddings\": [\"openai:text-embedding-3-small\"],\n})\n\nmodel = selector.select(ModelCategory.ANALYSIS)\n# Returns first allowed model: openai:gpt-4o\n\nall_models = selector.select_all(ModelCategory.ANALYSIS)\n# Returns all allowed: [openai:gpt-4o, anthropic:claude-3-5-sonnet-latest]\n\nselector.is_allowed(ModelRef.parse(\"openai:gpt-4o\"), ModelCategory.ANALYSIS)\n# True\n</code></pre>"},{"location":"concepts/model-selection/#staticmodelselector","title":"StaticModelSelector","text":"<p>For local development, <code>StaticModelSelector</code> returns the same model for every category:</p> <pre><code>from sage_sanctum.llm.model_selector import StaticModelSelector\n\nselector = StaticModelSelector(\"openai:gpt-4o\")\nselector.select(ModelCategory.TRIAGE)      # openai:gpt-4o\nselector.select(ModelCategory.REASONING)   # openai:gpt-4o\n</code></pre> <p>This is what <code>AgentContext.for_local_development()</code> uses internally.</p>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.11 or later</li> <li>pip (or any PEP 517 compatible installer)</li> </ul>"},{"location":"getting-started/installation/#install-from-pypi","title":"Install from PyPI","text":"<pre><code>pip install sage-sanctum-sdk\n</code></pre>"},{"location":"getting-started/installation/#install-from-source","title":"Install from Source","text":"<pre><code>git clone https://github.com/SapphireBeehiveStudios/sage-sanctum-sdk.git\ncd sage-sanctum-sdk\npip install -e .\n</code></pre>"},{"location":"getting-started/installation/#install-with-development-dependencies","title":"Install with Development Dependencies","text":"<pre><code>pip install -e \".[dev]\"\n</code></pre> <p>This adds <code>pytest</code>, <code>pytest-asyncio</code>, and <code>pytest-cov</code> for running the test suite.</p>"},{"location":"getting-started/installation/#dependencies","title":"Dependencies","text":"<p>The SDK installs the following dependencies automatically:</p> Package Purpose <code>pydantic&gt;=2.0.0</code> Data validation and settings <code>urllib3&gt;=2.0.0</code> HTTP client utilities <code>litellm&gt;=1.30.0</code> Multi-provider LLM routing <code>langchain-core&gt;=0.3.0</code> LLM abstraction layer <code>langchain-litellm&gt;=0.2.0</code> LiteLLM integration for LangChain"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<pre><code>import sage_sanctum\nprint(sage_sanctum.__version__)\n# 0.1.1\n</code></pre> <p>You can also verify all key imports work:</p> <pre><code>from sage_sanctum import (\n    AgentContext,\n    AgentRunner,\n    SageSanctumAgent,\n    AgentResult,\n    ModelCategory,\n    SarifOutput,\n    Finding,\n    Location,\n)\nprint(\"All imports successful\")\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<p>Head to the Quickstart to build your first agent.</p>"},{"location":"getting-started/quickstart/","title":"Quickstart","text":"<p>This guide walks you through building a simple security analysis agent from scratch.</p>"},{"location":"getting-started/quickstart/#1-create-your-agent","title":"1. Create Your Agent","text":"<p>Every agent extends <code>SageSanctumAgent</code> and implements three things: a <code>name</code>, a <code>version</code>, and a <code>run</code> method.</p> <pre><code># my_agent.py\nfrom sage_sanctum import SageSanctumAgent, AgentResult, AgentRunner\nfrom sage_sanctum.io.inputs import AgentInput, RepositoryInput\nfrom sage_sanctum.io.outputs import SarifOutput, Finding, Location\nfrom sage_sanctum.llm.model_category import ModelCategory\n\n\nclass MySecurityAgent(SageSanctumAgent):\n    @property\n    def name(self) -&gt; str:\n        return \"my-security-agent\"\n\n    @property\n    def version(self) -&gt; str:\n        return \"0.1.0\"\n\n    async def run(self, agent_input: AgentInput) -&gt; AgentResult:\n        # agent_input is a RepositoryInput with a path to the cloned repo\n        repo = agent_input\n        assert isinstance(repo, RepositoryInput)\n\n        # Create an LLM client for the analysis category\n        llm = self.context.create_llm_client(ModelCategory.ANALYSIS)\n\n        # List Python files in the repository\n        py_files = repo.list_files(extensions={\".py\"})\n\n        findings = []\n        for py_file in py_files[:5]:  # Analyze first 5 files\n            code = py_file.read_text()\n            response = llm.invoke([\n                {\"role\": \"system\", \"content\": \"You are a security auditor. Find vulnerabilities.\"},\n                {\"role\": \"user\", \"content\": f\"Review this code:\\n\\n{code}\"},\n            ])\n\n            # Parse findings from the LLM response...\n            # (simplified for this example)\n\n        return AgentResult(\n            output=SarifOutput(\n                tool_name=self.name,\n                tool_version=self.version,\n                findings=findings,\n            ),\n            exit_code=0,\n        )\n</code></pre>"},{"location":"getting-started/quickstart/#2-add-an-entry-point","title":"2. Add an Entry Point","text":"<p>The <code>AgentRunner</code> manages the full lifecycle \u2014 context initialization, signal handling, input loading, and output writing.</p> <pre><code>if __name__ == \"__main__\":\n    import sys\n    sys.exit(AgentRunner(MySecurityAgent).run())\n</code></pre>"},{"location":"getting-started/quickstart/#3-run-locally","title":"3. Run Locally","text":"<p>For local development, set the <code>SAGE_SANCTUM_ALLOW_DIRECT</code> flag and provide API keys directly:</p> <pre><code>export SAGE_SANCTUM_ALLOW_DIRECT=1\nexport RUN_ID=local-test-001\nexport ORG_ID=my-org\nexport REPO_PATH=/path/to/repo\nexport OPENAI_API_KEY=sk-...\n\npython my_agent.py\n</code></pre> <p>Or use the convenience helper:</p> <pre><code>from sage_sanctum import AgentContext\n\ncontext = AgentContext.for_local_development(\n    work_dir=\"/tmp/work\",\n    output_dir=\"/tmp/output\",\n    model=\"openai:gpt-4o\",\n)\n</code></pre>"},{"location":"getting-started/quickstart/#4-understand-the-output","title":"4. Understand the Output","text":"<p>The agent writes SARIF output to the output directory. SARIF (Static Analysis Results Interchange Format) is the standard format for GitHub Code Scanning:</p> <pre><code>{\n  \"$schema\": \"https://raw.githubusercontent.com/oasis-tcs/sarif-spec/main/sarif-2.1/schema/sarif-schema-2.1.0.json\",\n  \"version\": \"2.1.0\",\n  \"runs\": [{\n    \"tool\": {\n      \"driver\": {\n        \"name\": \"my-security-agent\",\n        \"version\": \"0.1.0\",\n        \"rules\": [...]\n      }\n    },\n    \"results\": [...]\n  }]\n}\n</code></pre>"},{"location":"getting-started/quickstart/#5-write-tests","title":"5. Write Tests","text":"<p>Use the SDK's built-in testing utilities:</p> <pre><code>import pytest\nfrom sage_sanctum.testing.mocks import MockGatewayClient, MockLLM\nfrom sage_sanctum.testing.fixtures import mock_context\n\nfrom my_agent import MySecurityAgent\n\n\n@pytest.fixture\ndef agent(mock_context):\n    return MySecurityAgent(mock_context)\n\n\nasync def test_agent_run(agent, tmp_path):\n    # Create a test repo with a vulnerable file\n    test_file = tmp_path / \"example.py\"\n    test_file.write_text(\"import subprocess\\nsubprocess.call(user_input)\")\n\n    from sage_sanctum.io.inputs import RepositoryInput\n    repo_input = RepositoryInput(path=tmp_path)\n\n    result = await agent.run(repo_input)\n    assert result.exit_code == 0\n    assert result.output is not None\n</code></pre>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Architecture \u2014 Understand the security model</li> <li>Agents \u2014 Deep dive into agent lifecycle</li> <li>Configuration \u2014 All environment variables</li> <li>Testing \u2014 Full testing guide</li> </ul>"},{"location":"guides/claude-code/","title":"Claude Code Integration","text":"<p>This guide covers building a Sage Sanctum agent that uses Claude Code (via the Claude Agent SDK) as its LLM engine, routing all traffic through the Sage Sanctum gateway for authentication and policy enforcement.</p>"},{"location":"guides/claude-code/#architecture","title":"Architecture","text":"<pre><code>Scanner Pod (scan-run namespace)\n+-- Init Containers\n|   +-- fetch-jwt   -&gt; /var/run/spiffe/jwt   (SPIRE agent)\n|   +-- write-trat  -&gt; /run/sage/trat.jwt    (Orchestrator-issued TraT)\n|\n+-- scanner container\n|   +-- Python Agent (SageSanctumAgent, requires_gateway=False)\n|   |   +-- Claude Agent SDK (query() async generator)\n|   |   |   +-- claude CLI subprocess\n|   |   |       +-- ANTHROPIC_BASE_URL=http://127.0.0.1:8082\n|   |   +-- MCP tool: report_finding (in-process, structured output)\n|   |\n|   +-- bridge.py (auth-injecting HTTP proxy)\n|       +-- Listens: 127.0.0.1:8082 (TCP, loopback only)\n|       +-- Reads JWT + TraT from files per request\n|       +-- Injects Authorization: Bearer &lt;jwt&gt;\n|       +-- Injects Txn-Token: &lt;trat&gt;\n|       +-- Forwards to UDS: /run/sage/llm.sock\n|\n+-- llm-gateway sidecar (forwarder mode)\n    +-- Listens: /run/sage/llm.sock (UDS)\n    +-- Zero-logic reverse proxy, forwards all headers unchanged\n    +-- No secrets, no config\n            |\n            | TCP (ClusterIP)\n            v\nCentral LLM Gateway (scan-infra namespace, full mode)\n    +-- Validates Authorization (SPIFFE JWT) + Txn-Token (TraT)\n    +-- DLP scanning\n    +-- BYOK key injection (adds real provider API key)\n    +-- Request translation\n    +-- Forwards to upstream provider (Anthropic API)\n</code></pre> <p>Claude Code doesn't natively support SPIFFE/TraT authentication, so an auth-injecting HTTP proxy (<code>bridge.py</code>) runs inside the scanner container to bridge the gap. It reads JWT and TraT from files (mounted by init containers), injects them as headers on every request, and forwards to the forwarder sidecar over UDS. The forwarder is zero-logic \u2014 all intelligence (auth validation, DLP, BYOK key injection) lives at the central gateway.</p>"},{"location":"guides/claude-code/#prerequisites","title":"Prerequisites","text":"<pre><code>pip install sage-sanctum-sdk claude-agent-sdk\n</code></pre>"},{"location":"guides/claude-code/#agent-implementation","title":"Agent Implementation","text":"<pre><code>import asyncio\nimport os\n\nfrom claude_agent_sdk import (\n    ClaudeAgentOptions,\n    create_sdk_mcp_server,\n    query,\n    tool,\n)\n\nfrom sage_sanctum import AgentResult, SageSanctumAgent\nfrom sage_sanctum.errors import ExternalToolError\nfrom sage_sanctum.io.inputs import RepositoryInput\nfrom sage_sanctum.io.outputs import Finding, Location, SarifOutput\n\nSCAN_PROMPT = \"\"\"\\\nYou are a security scanner. Analyze this repository for vulnerabilities.\n\nFor each vulnerability you find, call the report_finding tool with structured\ndata. Be thorough: check for injection flaws, auth bypass, secrets in code,\npath traversal, SSRF, insecure deserialization, and other OWASP Top 10 issues.\n\nWhen finished scanning, provide a brief summary of what you found.\n\"\"\"\n\nBRIDGE_PORT = 8082\n\n\nclass ClaudeCodeAgent(SageSanctumAgent[RepositoryInput]):\n    requires_gateway = False\n\n    @property\n    def name(self) -&gt; str:\n        return \"claude-code-scanner\"\n\n    @property\n    def version(self) -&gt; str:\n        return \"0.1.0\"\n\n    async def run(self, agent_input: RepositoryInput) -&gt; AgentResult:\n        findings: list[Finding] = []\n\n        # --- Define MCP tool for structured finding collection ---\n\n        @tool(\n            name=\"report_finding\",\n            description=\"Report a security vulnerability found during analysis\",\n            input_schema={\n                \"type\": \"object\",\n                \"properties\": {\n                    \"id\": {\n                        \"type\": \"string\",\n                        \"description\": \"Rule ID e.g. SQL-001\",\n                    },\n                    \"title\": {\"type\": \"string\"},\n                    \"description\": {\"type\": \"string\"},\n                    \"severity\": {\n                        \"type\": \"string\",\n                        \"enum\": [\n                            \"critical\", \"high\", \"medium\", \"low\", \"note\",\n                        ],\n                    },\n                    \"file\": {\n                        \"type\": \"string\",\n                        \"description\": \"Path relative to repo root\",\n                    },\n                    \"start_line\": {\"type\": \"integer\"},\n                    \"cwe\": {\n                        \"type\": \"string\",\n                        \"description\": \"e.g. CWE-89\",\n                    },\n                    \"remediation\": {\"type\": \"string\"},\n                },\n                \"required\": [\n                    \"id\", \"title\", \"description\",\n                    \"severity\", \"file\", \"start_line\",\n                ],\n            },\n        )\n        async def handle_finding(args):\n            findings.append(\n                Finding(\n                    id=args[\"id\"],\n                    title=args[\"title\"],\n                    description=args[\"description\"],\n                    severity=args[\"severity\"],\n                    location=Location(\n                        file=args[\"file\"],\n                        start_line=args[\"start_line\"],\n                    ),\n                    cwe=args.get(\"cwe\", \"\"),\n                    remediation=args.get(\"remediation\", \"\"),\n                )\n            )\n            return {\n                \"content\": [\n                    {\"type\": \"text\", \"text\": f\"Recorded {args['id']}\"}\n                ]\n            }\n\n        mcp_server = create_sdk_mcp_server([handle_finding])\n\n        # --- Run Claude via Agent SDK ---\n        # bridge.py is started separately (by entrypoint or supervisor)\n        # and listens on 127.0.0.1:BRIDGE_PORT\n\n        cost = 0.0\n        async for message in query(\n            prompt=SCAN_PROMPT,\n            options=ClaudeAgentOptions(\n                cwd=str(agent_input.path),\n                max_turns=30,\n                model=\"claude-sonnet-4-5-20250929\",\n                permission_mode=\"bypassPermissions\",\n                mcp_servers={\"scanner\": mcp_server},\n                env={\n                    \"ANTHROPIC_BASE_URL\": (\n                        f\"http://127.0.0.1:{BRIDGE_PORT}\"\n                    ),\n                    \"ANTHROPIC_API_KEY\": \"gateway-injected\",\n                },\n            ),\n        ):\n            if message.type == \"result\":\n                cost = getattr(message, \"cost_usd\", 0.0)\n\n        return AgentResult(\n            output=SarifOutput(\n                tool_name=self.name,\n                tool_version=self.version,\n                findings=findings,\n            ),\n            exit_code=0,\n            metadata={\"cost_usd\": cost},\n        )\n</code></pre>"},{"location":"guides/claude-code/#the-auth-bridge","title":"The Auth Bridge","text":"<p>Claude Code sends requests to <code>http://127.0.0.1:8082</code> with a placeholder <code>x-api-key</code>. The bridge (<code>bridge.py</code>) is a Python asyncio TCP server that:</p> <ol> <li>Listens on <code>127.0.0.1:8082</code> (loopback only \u2014 seccomp blocks non-loopback AF_INET)</li> <li>Parses each incoming HTTP request</li> <li>Strips existing <code>Authorization:</code> and <code>Txn-Token:</code> headers (defense in depth)</li> <li>Reads fresh SPIFFE JWT from <code>/var/run/spiffe/jwt</code> and TraT from <code>/run/sage/trat.jwt</code> (handles token rotation during long scans)</li> <li>Injects <code>Authorization: Bearer &lt;jwt&gt;</code> and <code>Txn-Token: &lt;trat&gt;</code> headers</li> <li>Forwards the modified request to the forwarder sidecar via Unix domain socket at <code>/run/sage/llm.sock</code></li> <li>Pipes the response back to Claude Code (supports both JSON and streaming SSE)</li> <li>Returns HTTP 502 if the UDS connection fails</li> </ol> <pre><code>Claude Code\n  -&gt; http://127.0.0.1:8082 (x-api-key: gateway-injected)\n  -&gt; bridge.py (strips x-api-key, injects JWT + TraT)\n  -&gt; /run/sage/llm.sock (UDS)\n  -&gt; forwarder sidecar (passes all headers unchanged)\n  -&gt; central gateway (validates JWT + TraT, injects BYOK API key)\n  -&gt; api.anthropic.com\n</code></pre>"},{"location":"guides/claude-code/#comparison-with-standard-sage-auth","title":"Comparison with Standard SAGE Auth","text":"Aspect SAGE Scanner Claude Scanner Auth injection SDK (<code>GatewayCredentials.auth_headers()</code>) <code>bridge.py</code> (HTTP proxy) Token reading SDK reads files at startup + refresh Bridge re-reads files per request LLM endpoint <code>OPENAI_BASE_URL</code> via UDS <code>ANTHROPIC_BASE_URL</code> via TCP to bridge API format OpenAI-compatible (translated by gateway) Native Anthropic (passthrough) Extra hop None (SDK -&gt; UDS -&gt; forwarder) bridge.py (SDK -&gt; TCP -&gt; bridge -&gt; UDS -&gt; forwarder)"},{"location":"guides/claude-code/#token-lifecycle","title":"Token Lifecycle","text":""},{"location":"guides/claude-code/#spiffe-jwt","title":"SPIFFE JWT","text":"<p>The <code>fetch-jwt</code> init container calls the SPIRE agent (mounted via CSI driver) and obtains a JWT for the scanner's per-run identity:</p> <pre><code>spiffe://sage-sanctum.local/scanner/{run_id}\n</code></pre> <p>Written to <code>/var/run/spiffe/jwt</code>. The bridge re-reads this file on every request to handle rotation.</p>"},{"location":"guides/claude-code/#transaction-token-trat","title":"Transaction Token (TraT)","text":"<p>The orchestrator's TTS (Transaction Token Service) issues a TraT when creating the scanner job. The <code>write-trat</code> init container writes it to <code>/run/sage/trat.jwt</code> with <code>umask 077</code>. The bridge re-reads this file on every request.</p>"},{"location":"guides/claude-code/#entrypoint","title":"Entrypoint","text":"<pre><code># __main__.py\nfrom sage_sanctum import AgentRunner\nfrom .agent import ClaudeCodeAgent\n\nif __name__ == \"__main__\":\n    exit(AgentRunner(ClaudeCodeAgent).run())\n</code></pre>"},{"location":"guides/claude-code/#dockerfile","title":"Dockerfile","text":"<pre><code>FROM python:3.12-slim\n\nRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends git &amp;&amp; \\\n    rm -rf /var/lib/apt/lists/*\n\n# PyPI wheel bundles the claude CLI binary\nRUN pip install --no-cache-dir claude-agent-sdk\n\nCOPY . /app\nRUN pip install --no-cache-dir /app\n\nRUN mkdir -p /work /output /repo &amp;&amp; useradd -r -m scanner\nUSER scanner\n\nENV CLAUDE_CODE_ACCEPT_TOS=1 \\\n    DISABLE_AUTOUPDATER=1 \\\n    CLAUDE_CODE_DISABLE_NONESSENTIAL_TRAFFIC=1\n\nENTRYPOINT [\"python\", \"-m\", \"my_scanner\"]\n</code></pre>"},{"location":"guides/claude-code/#running","title":"Running","text":""},{"location":"guides/claude-code/#production","title":"Production","text":"<p>The orchestrator creates the scanner pod with init containers, forwarder sidecar, and the repo mounted:</p> <pre><code>docker run --rm \\\n  --security-opt seccomp=seccomp-claude-scanner.json \\\n  -e RUN_ID=scan-42 \\\n  -e ORG_ID=acme \\\n  -e REPO_PATH=/repo \\\n  -e OUTPUT_PATH=/output \\\n  -v /path/to/repo:/repo:ro \\\n  -v /tmp/output:/output \\\n  my-scanner:latest\n\n# SARIF output at /tmp/output/results.sarif\n</code></pre> <p>Note</p> <p>In production, the pod spec includes init containers (<code>fetch-jwt</code>, <code>write-trat</code>), the forwarder sidecar, and volume mounts for JWT/TraT files and the gateway UDS.</p>"},{"location":"guides/claude-code/#local-development","title":"Local Development","text":"<p>For local testing without the gateway, use direct mode with your own API key:</p> <pre><code>export SAGE_SANCTUM_ALLOW_DIRECT=1\nexport RUN_ID=local-test\nexport ORG_ID=dev\nexport REPO_PATH=/path/to/repo\nexport ANTHROPIC_API_KEY=sk-ant-...\n\npython -m my_scanner\n</code></pre> <p>Note</p> <p>In direct/local mode the bridge is not needed. Adjust the agent to set <code>ANTHROPIC_BASE_URL</code> and <code>ANTHROPIC_API_KEY</code> directly from environment when <code>LLM_GATEWAY_SOCKET</code> is not set.</p>"},{"location":"guides/claude-code/#mcp-tools-instead-of-json-parsing","title":"MCP Tools Instead of JSON Parsing","text":"<p>Rather than asking Claude to produce a JSON array and parsing free text, the agent defines a <code>report_finding</code> MCP tool. Claude calls it with typed arguments for each vulnerability found. This is dramatically more reliable than text parsing.</p>"},{"location":"guides/claude-code/#security-controls","title":"Security Controls","text":"Control Detail Seccomp <code>seccomp-claude-scanner.json</code> \u2014 allows AF_INET for bridge loopback, AF_UNIX for UDS, blocks AF_INET6 and raw sockets NetworkPolicy Scanner pods can only reach the central gateway in <code>scan-infra</code> namespace Read-only rootfs All containers use <code>readOnlyRootFilesystem: true</code> No privilege escalation <code>allowPrivilegeEscalation: false</code>, all capabilities dropped"},{"location":"guides/claude-code/#central-gateway-requirements","title":"Central Gateway Requirements","text":"<p>For this pattern the central gateway must:</p> Requirement Reason Validate SPIFFE JWT Verify scanner identity against SPIRE trust domain Validate TraT Verify transaction authorization against orchestrator signing key Route <code>/v1/messages</code> to Anthropic Claude Code does not send <code>X-Provider</code> header BYOK key injection Inject real provider API key after auth validation Support SSE streaming Claude Code streams responses by default Timeout &gt;= max turn duration Long-running analysis may take minutes per turn"},{"location":"guides/claude-code/#forwarder-vs-full-mode","title":"Forwarder vs Full Mode","text":"<p>The sidecar runs in forwarder mode \u2014 a zero-logic reverse proxy (~100 LOC) that passes all headers unchanged:</p> <ul> <li>Zero secrets (no API keys)</li> <li>Zero config volumes</li> <li>64Mi memory request / 128Mi limit</li> <li>No middleware chain</li> </ul> <p>All intelligence (auth validation, DLP, BYOK key injection, request translation) lives at the central LLM gateway in the <code>scan-infra</code> namespace running in full mode.</p>"},{"location":"guides/configuration/","title":"Configuration","text":"<p>All SDK configuration is done through environment variables. No config files are needed.</p>"},{"location":"guides/configuration/#core-variables","title":"Core Variables","text":"Variable Required Default Description <code>RUN_ID</code> Yes \u2014 Unique identifier for this agent run <code>ORG_ID</code> Yes \u2014 Organization identifier <code>WORK_DIR</code> No <code>/work</code> Working directory for temporary files <code>OUTPUT_PATH</code> No <code>/output</code> Directory where agent output is written"},{"location":"guides/configuration/#repository-input","title":"Repository Input","text":"Variable Required Default Description <code>REPO_PATH</code> Yes \u2014 Path to the cloned repository <code>REPO_REF</code> No <code>\"\"</code> Git ref (branch, tag, commit) <code>REPO_URL</code> No <code>\"\"</code> Remote repository URL"},{"location":"guides/configuration/#authentication-production","title":"Authentication (Production)","text":"Variable Required Default Description <code>SPIFFE_JWT_PATH</code> No \u2014 Path to SPIFFE JWT SVID file <code>TRAT_FILE</code> No \u2014 Path to Transaction Token file <code>AUTH_SIDECAR_SOCKET</code> No \u2014 Unix socket path for auth sidecar <code>LLM_GATEWAY_SOCKET</code> No \u2014 Unix socket path for LLM gateway"},{"location":"guides/configuration/#local-development","title":"Local Development","text":"Variable Required Default Description <code>SAGE_SANCTUM_ALLOW_DIRECT</code> No \u2014 Set to <code>1</code> to enable direct provider access <code>SAGE_MODEL</code> No \u2014 Override model for all categories <code>OPENAI_MODEL</code> No \u2014 Override model (fallback if <code>SAGE_MODEL</code> not set)"},{"location":"guides/configuration/#provider-api-keys-direct-mode-only","title":"Provider API Keys (Direct Mode Only)","text":"Variable Provider <code>OPENAI_API_KEY</code> OpenAI <code>ANTHROPIC_API_KEY</code> Anthropic <code>GOOGLE_API_KEY</code> Google AI"},{"location":"guides/configuration/#example-production","title":"Example: Production","text":"<p>In production, the Sage Sanctum platform sets all environment variables automatically. Your agent doesn't need to configure anything.</p> <pre><code># Set by the platform \u2014 you don't need to set these\nRUN_ID=run-abc123\nORG_ID=org-xyz\nREPO_PATH=/work/repo\nSPIFFE_JWT_PATH=/run/secrets/spiffe/jwt\nTRAT_FILE=/run/secrets/trat\nLLM_GATEWAY_SOCKET=/run/sockets/gateway.sock\nOUTPUT_PATH=/output\n</code></pre>"},{"location":"guides/configuration/#example-local-development","title":"Example: Local Development","text":"<pre><code>export SAGE_SANCTUM_ALLOW_DIRECT=1\nexport RUN_ID=local-test\nexport ORG_ID=dev\nexport REPO_PATH=/path/to/repo\nexport OPENAI_API_KEY=sk-...\n\npython my_agent.py\n</code></pre>"},{"location":"guides/configuration/#example-local-with-anthropic","title":"Example: Local with Anthropic","text":"<pre><code>export SAGE_SANCTUM_ALLOW_DIRECT=1\nexport RUN_ID=local-test\nexport ORG_ID=dev\nexport REPO_PATH=/path/to/repo\nexport SAGE_MODEL=anthropic:claude-3-5-sonnet-latest\nexport ANTHROPIC_API_KEY=sk-ant-...\n\npython my_agent.py\n</code></pre>"},{"location":"guides/error-handling/","title":"Error Handling","text":""},{"location":"guides/error-handling/#error-hierarchy","title":"Error Hierarchy","text":"<p>All SDK errors extend <code>SageSanctumError</code>, which carries an <code>exit_code</code> for process-level signaling:</p> <pre><code>SageSanctumError (1)\n\u251c\u2500\u2500 AuthError (10)\n\u2502   \u251c\u2500\u2500 SpiffeAuthError (11)\n\u2502   \u251c\u2500\u2500 TraTAcquisitionError (12)\n\u2502   \u2514\u2500\u2500 TraTExpiredError (13)\n\u251c\u2500\u2500 ForbiddenError (20)\n\u2502   \u251c\u2500\u2500 ModelNotAuthorizedError (21)\n\u2502   \u2514\u2500\u2500 ScopeNotAuthorizedError (22)\n\u251c\u2500\u2500 GatewayError (30)\n\u2502   \u251c\u2500\u2500 RateLimitError (31)\n\u2502   \u2514\u2500\u2500 GatewayUnavailableError (32)\n\u251c\u2500\u2500 ValidationError (40)\n\u2502   \u251c\u2500\u2500 InputValidationError (41)\n\u2502   \u251c\u2500\u2500 PathTraversalError (42)\n\u2502   \u2514\u2500\u2500 ConfigurationError (43)\n\u251c\u2500\u2500 OutputError (50)\n\u2502   \u251c\u2500\u2500 OutputWriteError (51)\n\u2502   \u2514\u2500\u2500 SarifValidationError (52)\n\u251c\u2500\u2500 ModelError (60)\n\u2502   \u251c\u2500\u2500 ModelNotAvailableError (61)\n\u2502   \u2514\u2500\u2500 ModelRefParseError (62)\n\u2514\u2500\u2500 ExternalToolError (70)\n    \u251c\u2500\u2500 SubprocessError (71)\n    \u251c\u2500\u2500 SubprocessTimeoutError (72)\n    \u2514\u2500\u2500 OutputParseError (73)\n</code></pre>"},{"location":"guides/error-handling/#exit-codes","title":"Exit Codes","text":"<p>The <code>AgentRunner</code> maps exceptions to exit codes automatically:</p> Range Category Meaning 0 Success Agent completed successfully 1 General Unhandled exception 10-19 Authentication Identity or token errors 20-29 Authorization Permission denied 30-39 Gateway LLM gateway errors 40-49 Validation Input or config errors 50-59 Output Output writing errors 60-69 Model Model selection errors 70-79 External Tool Subprocess or external tool errors"},{"location":"guides/error-handling/#catching-errors","title":"Catching Errors","text":""},{"location":"guides/error-handling/#catch-specific-errors","title":"Catch Specific Errors","text":"<pre><code>from sage_sanctum.errors import RateLimitError, ModelNotAvailableError\n\ntry:\n    response = llm.invoke(messages)\nexcept RateLimitError:\n    # Back off and retry\n    ...\nexcept ModelNotAvailableError as e:\n    # Fall back to a different model\n    ...\n</code></pre>"},{"location":"guides/error-handling/#catch-by-category","title":"Catch by Category","text":"<pre><code>from sage_sanctum.errors import GatewayError, AuthError\n\ntry:\n    response = llm.invoke(messages)\nexcept AuthError:\n    # Any authentication issue\n    ...\nexcept GatewayError:\n    # Any gateway issue (rate limit, unavailable, etc.)\n    ...\n</code></pre>"},{"location":"guides/error-handling/#let-the-runner-handle-it","title":"Let the Runner Handle It","text":"<p>In most cases, you can let exceptions propagate. The <code>AgentRunner</code> catches all <code>SageSanctumError</code> subclasses and maps them to the correct exit code:</p> <pre><code>async def run(self, agent_input: AgentInput) -&gt; AgentResult:\n    # If this raises ModelNotAvailableError, the runner\n    # returns exit code 61 automatically\n    llm = self.context.create_llm_client(ModelCategory.ANALYSIS)\n    ...\n</code></pre>"},{"location":"guides/error-handling/#custom-exit-codes","title":"Custom Exit Codes","text":"<p>You can set a custom exit code when raising an error:</p> <pre><code>raise SageSanctumError(\"Custom error\", exit_code=99)\n</code></pre> <p>Or return it in the result:</p> <pre><code>return AgentResult(exit_code=2, error=\"Partial failure\")\n</code></pre>"},{"location":"guides/error-handling/#external-tool-errors","title":"External Tool Errors","text":"<p>When agents wrap external tools (e.g., Claude Code CLI), use the <code>ExternalToolError</code> family to report failures:</p> <pre><code>from sage_sanctum.errors import SubprocessError, SubprocessTimeoutError, OutputParseError\n\n# Subprocess failed\nraise SubprocessError(\n    \"Claude Code exited with error\",\n    returncode=1,\n    stderr=\"Error: model not found\",\n)\n\n# Subprocess timed out\nraise SubprocessTimeoutError(\"Claude Code exceeded 600s time limit\")\n\n# Could not parse tool output\nraise OutputParseError(\"Failed to extract findings JSON from Claude Code output\")\n</code></pre> <p><code>SubprocessError</code> carries additional attributes:</p> Attribute Type Description <code>returncode</code> <code>int</code> The subprocess exit code (default: <code>1</code>) <code>stderr</code> <code>str</code> Captured stderr output"},{"location":"guides/examples/","title":"Examples","text":""},{"location":"guides/examples/#multi-model-agent","title":"Multi-Model Agent","text":"<p>Use different model categories for different stages of analysis:</p> <pre><code>from sage_sanctum import SageSanctumAgent, AgentResult\nfrom sage_sanctum.io.inputs import RepositoryInput\nfrom sage_sanctum.io.outputs import SarifOutput, Finding, Location\nfrom sage_sanctum.llm.model_category import ModelCategory\n\n\nclass MultiModelAgent(SageSanctumAgent[RepositoryInput]):\n    @property\n    def name(self) -&gt; str:\n        return \"multi-model-agent\"\n\n    @property\n    def version(self) -&gt; str:\n        return \"1.0.0\"\n\n    async def run(self, agent_input: RepositoryInput) -&gt; AgentResult:\n        repo = agent_input\n\n        # Stage 1: Triage \u2014 fast, cheap model to identify interesting files\n        triage_llm = self.context.create_llm_client(ModelCategory.TRIAGE)\n        py_files = repo.list_files(extensions={\".py\"})\n        interesting_files = []\n\n        for f in py_files:\n            code = f.read_text()\n            resp = triage_llm.invoke([\n                {\"role\": \"user\", \"content\": f\"Does this file handle user input? Answer YES or NO.\\n\\n{code}\"},\n            ])\n            if \"YES\" in resp.content:\n                interesting_files.append(f)\n\n        # Stage 2: Analysis \u2014 thorough review of flagged files\n        analysis_llm = self.context.create_llm_client(ModelCategory.ANALYSIS)\n        findings = []\n\n        for f in interesting_files:\n            code = f.read_text()\n            resp = analysis_llm.invoke([\n                {\"role\": \"system\", \"content\": \"Find security vulnerabilities. Return JSON.\"},\n                {\"role\": \"user\", \"content\": code},\n            ])\n            # Parse findings from response...\n\n        return AgentResult(\n            output=SarifOutput(\n                tool_name=self.name,\n                tool_version=self.version,\n                findings=findings,\n            ),\n            exit_code=0,\n        )\n</code></pre>"},{"location":"guides/examples/#local-development-setup","title":"Local Development Setup","text":"<p>Run your agent locally without the Sage Sanctum platform:</p> <pre><code>import asyncio\nfrom sage_sanctum import AgentContext\nfrom sage_sanctum.io.inputs import RepositoryInput\nfrom my_agent import MyAgent\n\n\nasync def main():\n    context = AgentContext.for_local_development(\n        work_dir=\"/tmp/work\",\n        output_dir=\"/tmp/output\",\n        model=\"openai:gpt-4o\",\n    )\n\n    agent = MyAgent(context)\n    repo = RepositoryInput(path=\"/path/to/repo\")\n\n    result = await agent.run(repo)\n    print(f\"Exit code: {result.exit_code}\")\n    print(f\"Findings: {len(result.output.findings)}\")\n\n    # Write output\n    files = context.write_output(result.output)\n    print(f\"Written: {files}\")\n\n\nasyncio.run(main())\n</code></pre>"},{"location":"guides/examples/#sarif-output-with-full-detail","title":"SARIF Output with Full Detail","text":"<p>Create findings with complete location and metadata:</p> <pre><code>from sage_sanctum.io.outputs import SarifOutput, Finding, Location, TokenUsage\n\noutput = SarifOutput(\n    tool_name=\"vuln-scanner\",\n    tool_version=\"2.0.0\",\n    findings=[\n        Finding(\n            id=\"SQLI-001\",\n            title=\"SQL Injection via string formatting\",\n            description=(\n                \"User-controlled input is passed directly into an SQL query \"\n                \"using f-string formatting. An attacker could modify the query \"\n                \"to extract or modify data.\"\n            ),\n            severity=\"critical\",\n            location=Location(\n                file=\"src/database/queries.py\",\n                start_line=42,\n                end_line=45,\n                start_column=12,\n                end_column=58,\n            ),\n            cwe=\"CWE-89\",\n            remediation=\"Use parameterized queries with cursor.execute(sql, params).\",\n            confidence=\"high\",\n            metadata={\"owasp\": \"A03:2021\"},\n        ),\n        Finding(\n            id=\"XSS-001\",\n            title=\"Reflected XSS in template rendering\",\n            description=\"User input rendered without escaping in Jinja2 template.\",\n            severity=\"high\",\n            location=Location(\n                file=\"src/web/views.py\",\n                start_line=88,\n                end_line=88,\n            ),\n            cwe=\"CWE-79\",\n            remediation=\"Use {{ value | e }} or enable autoescape.\",\n            confidence=\"medium\",\n        ),\n    ],\n    token_usage=[\n        TokenUsage(model=\"gpt-4o\", prompt_tokens=5000, completion_tokens=1200, total_tokens=6200),\n        TokenUsage(model=\"gpt-4o-mini\", prompt_tokens=800, completion_tokens=50, total_tokens=850),\n    ],\n)\n\n# Write to disk\nsarif_dict = output.to_dict()\nfiles = output.write(\"/tmp/output\")\n</code></pre>"},{"location":"guides/examples/#custom-agent-input-validation","title":"Custom Agent Input Validation","text":"<p>Add custom validation to your agent:</p> <pre><code>from sage_sanctum import SageSanctumAgent, AgentResult\nfrom sage_sanctum.io.inputs import RepositoryInput\nfrom sage_sanctum.errors import InputValidationError\n\n\nclass StrictAgent(SageSanctumAgent[RepositoryInput]):\n    @property\n    def name(self) -&gt; str:\n        return \"strict-agent\"\n\n    @property\n    def version(self) -&gt; str:\n        return \"1.0.0\"\n\n    async def run(self, agent_input: RepositoryInput) -&gt; AgentResult:\n        repo = agent_input\n\n        py_files = repo.list_files(extensions={\".py\"})\n        if not py_files:\n            raise InputValidationError(\"Repository contains no Python files\")\n\n        if len(py_files) &gt; 1000:\n            raise InputValidationError(\n                f\"Repository too large: {len(py_files)} Python files (max 1000)\"\n            )\n\n        # Proceed with analysis...\n        return AgentResult(exit_code=0)\n</code></pre>"},{"location":"guides/testing/","title":"Testing","text":"<p>The SDK provides mock implementations for unit testing agents without real credentials or network access.</p>"},{"location":"guides/testing/#setup","title":"Setup","text":"<p>Install the development dependencies:</p> <pre><code>pip install -e \".[dev]\"\n</code></pre>"},{"location":"guides/testing/#mock-classes","title":"Mock Classes","text":""},{"location":"guides/testing/#mockgatewayclient","title":"MockGatewayClient","text":"<p>Drop-in replacement for <code>SpiffeGatewayClient</code> that returns dummy credentials:</p> <pre><code>from sage_sanctum.testing.mocks import MockGatewayClient\n\nclient = MockGatewayClient()\ncreds = client.get_credentials()\n# GatewayCredentials(spiffe_jwt=\"mock-jwt\", trat=\"mock-trat\")\n\nclient.is_gateway_mode  # False (default)\n</code></pre> <p>Configure gateway behavior:</p> <pre><code>client = MockGatewayClient(\n    is_gateway=True,\n    endpoints={\"openai\": \"http://localhost:8080\"},\n)\n</code></pre>"},{"location":"guides/testing/#mockllm","title":"MockLLM","text":"<p>Mock LangChain chat model that returns canned responses and tracks calls:</p> <pre><code>from sage_sanctum.testing.mocks import MockLLM\n\nllm = MockLLM(responses=[\n    \"This code has a SQL injection vulnerability.\",\n    \"No issues found in this file.\",\n])\n\nresponse = llm.invoke([...])  # Returns first response\nresponse = llm.invoke([...])  # Returns second response\n\n# Inspect what was sent\nassert len(llm.calls) == 2\nassert \"SQL\" in llm.calls[0][0].content  # Check first call's messages\n</code></pre>"},{"location":"guides/testing/#mocktratclient","title":"MockTratClient","text":"<p>Mock Transaction Token client with configurable model allowlists:</p> <pre><code>from sage_sanctum.testing.mocks import MockTratClient\nfrom sage_sanctum.auth.trat import AllowedModels\n\nclient = MockTratClient(allowed_models=AllowedModels(\n    triage=[\"openai:gpt-4o-mini\"],\n    analysis=[\"openai:gpt-4o\"],\n    reasoning=[\"openai:o1\"],\n    embeddings=[\"openai:text-embedding-3-small\"],\n))\n\ntoken = client.get_token()\ntoken.tctx.allowed_models.analysis  # [\"openai:gpt-4o\"]\n</code></pre>"},{"location":"guides/testing/#pytest-fixtures","title":"Pytest Fixtures","text":"<p>The SDK provides ready-made pytest fixtures:</p> <pre><code># In your conftest.py or test file\nfrom sage_sanctum.testing.fixtures import mock_gateway, sample_trat, mock_context\n</code></pre>"},{"location":"guides/testing/#mock_gateway","title":"mock_gateway","text":"<p>Returns a <code>MockGatewayClient</code> instance:</p> <pre><code>def test_something(mock_gateway):\n    creds = mock_gateway.get_credentials()\n    assert creds.spiffe_jwt == \"mock-jwt\"\n</code></pre>"},{"location":"guides/testing/#sample_trat","title":"sample_trat","text":"<p>Returns a <code>TransactionToken</code> with standard model allowlists:</p> <pre><code>def test_trat(sample_trat):\n    assert \"openai:gpt-4o\" in sample_trat.tctx.allowed_models.analysis\n</code></pre>"},{"location":"guides/testing/#mock_context","title":"mock_context","text":"<p>Returns a fully configured <code>AgentContext</code> with mocked gateway and static model selector:</p> <pre><code>async def test_agent(mock_context):\n    agent = MyAgent(mock_context)\n    # mock_context.create_llm_client() works but returns a mock-configured client\n</code></pre>"},{"location":"guides/testing/#testing-an-agent-end-to-end","title":"Testing an Agent End-to-End","text":"<pre><code>import pytest\nfrom sage_sanctum.testing.fixtures import mock_context\nfrom sage_sanctum.io.inputs import RepositoryInput\nfrom my_agent import MyAgent\n\n\n@pytest.fixture\ndef agent(mock_context):\n    return MyAgent(mock_context)\n\n\n@pytest.fixture\ndef repo(tmp_path):\n    # Create a minimal test repository\n    (tmp_path / \"app.py\").write_text(\"print('hello')\")\n    (tmp_path / \"utils.py\").write_text(\"def add(a, b): return a + b\")\n    return RepositoryInput(path=tmp_path)\n\n\nasync def test_agent_produces_sarif(agent, repo):\n    result = await agent.run(repo)\n\n    assert result.exit_code == 0\n    assert result.output is not None\n    assert result.output.io_type == \"sarif\"\n\n\nasync def test_agent_handles_empty_repo(agent, tmp_path):\n    empty_repo = RepositoryInput(path=tmp_path)\n    result = await agent.run(empty_repo)\n\n    assert result.exit_code == 0\n    assert len(result.output.findings) == 0\n</code></pre>"},{"location":"guides/testing/#testing-error-scenarios","title":"Testing Error Scenarios","text":"<pre><code>from sage_sanctum.errors import ModelNotAvailableError\n\n\nasync def test_agent_handles_model_error(agent, repo, monkeypatch):\n    def fail(*args, **kwargs):\n        raise ModelNotAvailableError(\"gpt-4o unavailable\")\n\n    monkeypatch.setattr(agent.context, \"create_llm_client\", fail)\n\n    with pytest.raises(ModelNotAvailableError):\n        await agent.run(repo)\n</code></pre>"}]}